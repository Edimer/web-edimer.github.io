{
  "hash": "80813f46cef193fb4dc14acfcdef2c8c",
  "result": {
    "markdown": "---\ntitle: \"Árbol de clasificación con R\"\nauthor: \"Edimer (Sidereus)\"\ndate: \"07-18-2020\"\ndescription: \"Ejemplo de árboles de decisión en machine learning supervisado para clasificación. Uso de las bibliotecas rpart, rpart.plot y caret en perfilamiento de riesgo crediticio.\"\ncategories:\n  - R\n  - Tree Decision\n  - ML\nimage: \"img1.png \"\nlang: es\ncss: estilo.css\nformat: \n  html:\n    toc: true\n    toc-title: \"Tabla de contenido\"\n    smooth-scroll: true\n    code-fold: true\n    df-print: paged\n    toc-location: left\n    number-depth: 4\n    code-copy: true\n    highlight-style: github\n    code-tools: \n      source: true \n    code-link: true \n---\n\n\n\n\n<center>\n<img src = \"www/img2.png\" />\n</center>\n\n# Contenido\n\n**1.** Información general (requisitos previos, bibliotecas, etc).   \n**2.** Análisis inicial de los datos. Como el objetivo principal del documento es entrenar un modelo de *árbol de decisión* con R, el análisis inicial incluye sólo una parte exploratoria y algunas pruebas estadísticas.   \n**3.** Entrenamiento de modelo por defecto con `rpart`.   \n**4.** Ajuste de hiperparámetros con la biblioteca `caret`. La métrica para evaluar el desempeño predictivo de los modelos es el [área bajo la curva ROC.](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)     \n**5.** Material complementario.   \n**6.** Recursos de información. \n\n# Requisitos previos\n\n- Instalar las bibliotecas [`rpart`](https://cran.r-project.org/web/packages/rpart/rpart.pdf) y [rpart.plot](https://cran.r-project.org/web/packages/rpart.plot/rpart.plot.pdf) para entrenar y gráficar modelos basados en árboles.\n- Instalar la biblioteca [`caret`.](http://topepo.github.io/caret/index.html)\n- [Descargar datos para ejemplo](https://www.openml.org/d/31) desde la página [openML](https://www.openml.org/). La base de datos proporciona información de personas perfiladas con riesgo crediticio *bueno* o *malo*.\n- **Bibliotecas complementarias:** para visualizaciones **`ggplot2`**, **`jcolors`** y **`hrbrthemes`**, para manejo de datos **`dplyr`**  y  para métricas de error y/o precisión **`Metrics`** y **`pROC`**.\n\n# Bibliotecas\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(jcolors)\nlibrary(hrbrthemes)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(caret)\nlibrary(Metrics)\nlibrary(pROC)\n```\n:::\n\n\n# Descripción de variables\n\n- Además de la variable respuesta *class*, se cuenta con las siguientes 20 variables.\n\n<center>\n<img src = \"www/img1.png\" /> \n</center>\n\n# Datos\n\n- Se importan los datos y se aplica la función `mutate_if()` para eliminar las comillas simples (*''*) que están presentes en las variables tipo texto (`character`). A continuación sólo se muestran 5 variables (columnas) con 10 observaciones. La variable **`class`** es nuestro *target* o *variable respuesta*.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata <- data.table::fread(file = \"data/dataset_31_credit-g.csv\") %>% \n  mutate_if(is.character, funs(gsub(\"'\", \"\", .)))\nhead(data[1:10, c(1, 5, 10, 15, 21)], n = 10L) # Imprimiendo sólo 5 columnas\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"checking_status\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"credit_amount\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"other_parties\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"housing\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"class\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"<0\",\"2\":\"1169\",\"3\":\"none\",\"4\":\"own\",\"5\":\"good\"},{\"1\":\"0<=X<200\",\"2\":\"5951\",\"3\":\"none\",\"4\":\"own\",\"5\":\"bad\"},{\"1\":\"no checking\",\"2\":\"2096\",\"3\":\"none\",\"4\":\"own\",\"5\":\"good\"},{\"1\":\"<0\",\"2\":\"7882\",\"3\":\"guarantor\",\"4\":\"for free\",\"5\":\"good\"},{\"1\":\"<0\",\"2\":\"4870\",\"3\":\"none\",\"4\":\"for free\",\"5\":\"bad\"},{\"1\":\"no checking\",\"2\":\"9055\",\"3\":\"none\",\"4\":\"for free\",\"5\":\"good\"},{\"1\":\"no checking\",\"2\":\"2835\",\"3\":\"none\",\"4\":\"own\",\"5\":\"good\"},{\"1\":\"0<=X<200\",\"2\":\"6948\",\"3\":\"none\",\"4\":\"rent\",\"5\":\"good\"},{\"1\":\"no checking\",\"2\":\"3059\",\"3\":\"none\",\"4\":\"own\",\"5\":\"good\"},{\"1\":\"0<=X<200\",\"2\":\"5234\",\"3\":\"none\",\"4\":\"own\",\"5\":\"bad\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n- **Dimensión de la base de datos:**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1000   21\n```\n:::\n:::\n\n\n# Distribución de variable respuesta\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata %>% \n  ggplot(mapping = aes(x = class, fill = class)) +\n  geom_bar(color = \"black\") + \n  scale_fill_manual(values = c(\"#5A5156\", \"#F6222E\")) +\n  theme_ipsum() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Exploratorio\n\n- **Distribución de edad por variable objetivo:** se puede apreciar que la edad promedio de los clasificados como *\"buenos\"* es más alta, además, los clasificados como *\"malos\"* en su mayoría son personas entre 20 y 30 años de edad.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata %>% \n  ggplot(mapping = aes(x = class, y = age, fill = class)) +\n  geom_violin() +\n  geom_boxplot(color = \"#E4E1E3\", width = 0.1, show.legend = FALSE)  +\n  stat_summary(fun.y = mean, color = \"#E4E1E3\", pch = 17) +\n  scale_fill_manual(values = c(\"#5A5156\", \"#F6222E\")) +\n  theme_ipsum() +\n  theme(legend.position = \"none\") +\n  labs(caption = \"El triángulo representa el promedio.\")\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=672}\n:::\n:::\n\n- **Propósitos de crédito más frecuentes:** la distribución de personas clasificadas como *buenas* o *malas* cuando el propósito es vehículo, discrepa bastante entre la opción de **nuevo** o **usado**. En vehículos usados la gran mayoría son clasificados como \"buenos\", sin embargo, cuando se trata de vehículos nuevos, la distribución es similar, lo que permite inferir que es más probable que una persona se comporte como mal pagador en créditos para vehículo nuevo respecto a créditos para vehículos usados. También se podría intuir que cuando se trata de créditos para educación es igual de probable que la persona sea clasificada como \"bueno\" o \"malo\".\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata %>% \n  group_by(class, purpose) %>% \n  count() %>% \n  ggplot(mapping = aes(x = reorder(purpose, n), y = n, fill = class)) +\n  geom_col(color = \"#E4E1E3\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"#5A5156\", \"#F6222E\")) +\n  labs(x = \"Purpose\") +\n  theme_ipsum() +\n  theme(legend.position = \"top\",\n        axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Inferencia\n\n- **Análisis de varianza:** en vista de la discrepancia que se observa en la distribución de las edades para personas clasificadas como \"buenas\" o \"malas\", realizo el [análisis de varianza](https://es.wikipedia.org/wiki/An%C3%A1lisis_de_la_varianza) para contrastar si dichas diferencias son estadísticamente significativas. **Nota:** aunque nuestra variable respuesta es *class*, en este caso actúa como \"predictora\" o fuente de variación.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmyAnova <- aov(age ~ class, data = data)\nsummary(myAnova)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq F value  Pr(>F)   \nclass         1   1074  1073.5   8.357 0.00393 **\nResiduals   998 128198   128.5                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n- El resultado de la prueba muestra que existe evidencia estadísticamente significativa (*p=0.00393*) para considerar que la variación de la edad entre ambos grupos es diferente.\n\n# Árboles de decisión\n\n<center>\n<img src = \"www/img3.png\" />\n</center>\n\n## Generalidades\n\n<center>\n<img src = \"www/img4.png\" />\n</center>\n\n- Los árboles de decisión se pueden utilizar para problemas de regresión y clasificación.\n- Se pueden definir como una estructura jerárquica que busca particionar el espacio de características e identificar subconjuntos representativos. Desde la parte superior a inferior cada árbol tiene *nodo raíz*, *nodos de decisión o internos* y *nodos hojas o terminales*, los dos primeros  se generan con base en reglas  binarias. Mayor grado de pureza es la recompensa que busca el algoritmo al particionar el espacio inicial en subregiones, en ese orden de ideas el objetivo siempre será particionar los datos en nodos que sean lo más puros posible, sin embargo, matemáticamente es más fácil medir la **impureza** de una región específica, proporcionando una idea de qué tan heterogéneas son las clases en ese nodo; una métrica de uso común en problemas de clasificación para medir la impureza es el **índice GINI**, donde valores bajos indican mayor grado de pureza. Además del índice GINI también es posible utilizar otras métricas como la **ganancia de información** o la **entropía**.\n- **Ventajas:**\n    - Fácil de interpretar (sujeto a la profundidad).\n    - No requieren estandarización o normalización de variables predictoras numéricas.\n    - Permiten manipular variables categóricas sin necesidad de aplicar codificaciones tipo *one-hot* o *variables dummy*.\n    - Requieren poco preprocesamiento de datos.\n    - Permiten valores ausentes (`NA`).\n    - Permite relaciones no lineales.\n- **Desventajas:**\n    - Si no se controla adecuadamente la profundidad del árbol existe alta probabilidad de incurrir en [*sobreajuste (overfitting)*.](https://es.wikipedia.org/wiki/Sobreajuste)\n    - Alta varianza, pequeños cambios en los datos pueden arrojar resultados muy diferentes.\n- **Hiperparámetros:** aunque ejecutar la función `rpart()` con valores predeterminados puede ser una buena estrategia para iniciar, siempre estaremos interesados en ajustar determinados parámetros que nos permitan obtener mejor rendimiento predictivo. La función `rpart.control()` permite controlar manualmente otras opciones. Dentro los hiperparámetros más importantes en árboles de decisión están los siguientes: \n    - Mínimo número de observaciones para generar una partición. En la biblioteca `rpart` lleva el nombre de `minsplit` y su valor por defecto es 20.\n    - Máxima profundiad del árbol. En la biblioteca `rpart` lleva el nombre de `maxdepth` y su valor predeterminado es 30. Este parámetro es de alta relevancia para evitar el sobreajuste.\n    - Parámetro de complejidad. En la biblioteca `rpart` lleva el nombre de `cp` y su valor por defecto es 0.01. Este parámetro sirve al propósito de penalizar y contolar el tamaño del árbol, valores bajos indican árboles de mayor complejidad, es decir, mayor número de divisiones. La función `rpart()` internamente ejecuta [validación cruzada](https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada) 10 veces para estimar el valor óptimo de **cp**, es posible acceder a dicho resultado a través de la función `plotcp()` que permitirá facilmente determinar el valor adecuado para este parámetro. Cuando se tiene el valor óptimo de **cp** será posible \"podar\" el árbol para que el modelo sea optimizado, dicho resultado es posible a través de la función `prune()`.\n\n## Train - Test\n\n- Para entrenar el modelo inicialmente fracciono los datos en *train* y *test* con proporciones de 70 y 30%, respectivamente. Este proceso aunque es posible hacerlo manualmente con la función `sample()`, la función `createDataPartition()` del paquete `caret` agiliza el procedimiento. Para garantizar replicabilidad en los resultados se agrega la semilla.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1992)\nidx <- createDataPartition(y = data$class, times = 1, p = 0.70, list = FALSE)\ndataTrain <- data[idx, ]\ndataTest <- data[-idx, ]\n```\n:::\n\n\n## `rpart` *default*\n\n- **Ajuste del modelo:** en este caso se utilizan todas las variables predictoras para entrenar el modelo. Al imprimir el objeto que contiene el modelo  podemos observar el conjunto de reglas que dan como resultado la estructura final del árbol. El método igualado a **`method = \"class\"`** indica que es un problema de clasificación, si fuese un problema de regresión el argumento tomaría el valor de  **`method = \"anova\"`**, aunque también permite otras opciones (consulte `?rpart` o `help(\"rpart\")`).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodArbol0 <- rpart(class ~ ., data = dataTrain, method = \"class\")\nmodArbol0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nn= 700 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 700 210 good (0.3000000 0.7000000)  \n    2) checking_status=<0,0<=X<200 385 168 good (0.4363636 0.5636364)  \n      4) credit_history=all paid,no credits/all paid 51  14 bad (0.7254902 0.2745098)  \n        8) savings_status=<100,100<=X<500 42   8 bad (0.8095238 0.1904762) *\n        9) savings_status=500<=X<1000,no known savings 9   3 good (0.3333333 0.6666667) *\n      5) credit_history=critical/other existing credit,delayed previously,existing paid 334 131 good (0.3922156 0.6077844)  \n       10) duration>=27.5 77  30 bad (0.6103896 0.3896104)  \n         20) purpose=domestic appliance,education,furniture/equipment,new car 39  10 bad (0.7435897 0.2564103) *\n         21) purpose=business,other,radio/tv,repairs,used car 38  18 good (0.4736842 0.5263158)  \n           42) checking_status=<0 19   7 bad (0.6315789 0.3684211) *\n           43) checking_status=0<=X<200 19   6 good (0.3157895 0.6842105) *\n       11) duration< 27.5 257  84 good (0.3268482 0.6731518)  \n         22) purpose=domestic appliance,education,new car,retraining 83  41 good (0.4939759 0.5060241)  \n           44) age< 35.5 42  13 bad (0.6904762 0.3095238)  \n             88) credit_amount< 1392 20   1 bad (0.9500000 0.0500000) *\n             89) credit_amount>=1392 22  10 good (0.4545455 0.5454545)  \n              178) property_magnitude=life insurance,real estate 13   4 bad (0.6923077 0.3076923) *\n              179) property_magnitude=car,no known property 9   1 good (0.1111111 0.8888889) *\n           45) age>=35.5 41  12 good (0.2926829 0.7073171) *\n         23) purpose=business,furniture/equipment,other,radio/tv,repairs,used car 174  43 good (0.2471264 0.7528736) *\n    3) checking_status=>=200,no checking 315  42 good (0.1333333 0.8666667) *\n```\n:::\n:::\n\n\n- **Gráfico del modelo:** la variable más importante y que da origen al nodo raíz es **`checking_status`**, que hace referencia al estado de la cuenta corriente. El historial crediticio, la duración del tiempo para pagar el crédito, el estado de la cuenta de ahorros y el propósito del crédito, también son factores determinantes. No tener suficiente capital en cualquiera de las dos cuentas, tener mal historial crediticio y además solicitar períodos de pago de alta duración, pueden ser características no deseables a la hora de solicitar un crédito.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrpart.plot(modArbol0)\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=864}\n:::\n:::\n\n\n- **Matriz de confusión:** el modelo por *default* tiene precisión promedio de 0.7167, con dificultades para clasificar de forma correcta los \"malos\", es decir, que tiene baja especificidad.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredichos_mod0 <- predict(object = modArbol0, newdata = dataTest, type = \"class\")\nconfusionMatrix(data = predichos_mod0, reference = as.factor(dataTest$class),\n                positive = \"good\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction bad good\n      bad   31   26\n      good  59  184\n                                        \n               Accuracy : 0.7167        \n                 95% CI : (0.662, 0.767)\n    No Information Rate : 0.7           \n    P-Value [Acc > NIR] : 0.2873596     \n                                        \n                  Kappa : 0.2465        \n                                        \n Mcnemar's Test P-Value : 0.0005187     \n                                        \n            Sensitivity : 0.8762        \n            Specificity : 0.3444        \n         Pos Pred Value : 0.7572        \n         Neg Pred Value : 0.5439        \n             Prevalence : 0.7000        \n         Detection Rate : 0.6133        \n   Detection Prevalence : 0.8100        \n      Balanced Accuracy : 0.6103        \n                                        \n       'Positive' Class : good          \n                                        \n```\n:::\n:::\n\n\n- **Área bajo la curva:**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Probabilidades predichas para la clase \"good\"\npred0 <- as.data.frame(predict(object = modArbol0,\n                               newdata = dataTest, type = \"prob\"))$good\n\n# Transformando respuesta a entero. A la clase \"good\" le agrego 1 y \n# a la clase \"bad\" le agrego 0.\ntarget <- as.integer(as.factor(dataTest$class)) - 1\n\n# AUC\nMetrics::auc(actual = target, predicted = pred0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7034392\n```\n:::\n:::\n\n\n- **Curva ROC:** la función con la que obtengo el siguiente gráfico puede ser encontrada en [mi Github.](https://github.com/web-edimer/web-edimer.github.io/blob/master/_posts/TreeD_R/functions/myROC.R)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Cargando función\nsource(\"functions/myROC.R\")\n\n# Ver función myROC() al final en material complementario    \nmyROC(predichos = pred0, reales = target)\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n- **Parámetro de complejidad (CP):**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplotcp(modArbol0)\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n- **\"Podando\" el árbol:** se elige el valor de cp = 0.025 por mostrar mejores resultados (bajo error).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodArbol0_prune <- prune(tree = modArbol0, cp = 0.025)\nmodArbol0_prune\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nn= 700 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 700 210 good (0.3000000 0.7000000)  \n   2) checking_status=<0,0<=X<200 385 168 good (0.4363636 0.5636364)  \n     4) credit_history=all paid,no credits/all paid 51  14 bad (0.7254902 0.2745098) *\n     5) credit_history=critical/other existing credit,delayed previously,existing paid 334 131 good (0.3922156 0.6077844)  \n      10) duration>=27.5 77  30 bad (0.6103896 0.3896104) *\n      11) duration< 27.5 257  84 good (0.3268482 0.6731518)  \n        22) purpose=domestic appliance,education,new car,retraining 83  41 good (0.4939759 0.5060241)  \n          44) age< 35.5 42  13 bad (0.6904762 0.3095238) *\n          45) age>=35.5 41  12 good (0.2926829 0.7073171) *\n        23) purpose=business,furniture/equipment,other,radio/tv,repairs,used car 174  43 good (0.2471264 0.7528736) *\n   3) checking_status=>=200,no checking 315  42 good (0.1333333 0.8666667) *\n```\n:::\n:::\n\n- **Gráfico de árbol con \"poda\":**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrpart.plot(modArbol0_prune)\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n- **Matriz de confusión árbol con \"poda\":** respecto al árbol sin podar, la diferencia en precisión es muy pequeña (<0.01), sin embargo, la especificidad se aumenta de 0.3444 a 0.4556 con la \"poda\", aunque la sensitividad haya reducido de 0.8762 a 0.8381.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredichos_mod0_prune <- predict(object = modArbol0_prune, newdata = dataTest, type = \"class\")\nconfusionMatrix(data = predichos_mod0_prune, reference = as.factor(dataTest$class),\n                positive = \"good\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction bad good\n      bad   41   34\n      good  49  176\n                                         \n               Accuracy : 0.7233         \n                 95% CI : (0.669, 0.7732)\n    No Information Rate : 0.7            \n    P-Value [Acc > NIR] : 0.2072         \n                                         \n                  Kappa : 0.3083         \n                                         \n Mcnemar's Test P-Value : 0.1244         \n                                         \n            Sensitivity : 0.8381         \n            Specificity : 0.4556         \n         Pos Pred Value : 0.7822         \n         Neg Pred Value : 0.5467         \n             Prevalence : 0.7000         \n         Detection Rate : 0.5867         \n   Detection Prevalence : 0.7500         \n      Balanced Accuracy : 0.6468         \n                                         \n       'Positive' Class : good           \n                                         \n```\n:::\n:::\n\n- **Área bajo la curva de árbol con \"poda\":**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Probabilidades predichas para la clase \"good\"\npred0_prune <- as.data.frame(predict(object = modArbol0_prune,\n                                     newdata = dataTest, type = \"prob\"))$good\n\n# AUC\nMetrics::auc(actual = target, predicted = pred0_prune)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7203175\n```\n:::\n:::\n\n\n- **Curva ROC:**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Ver función myROC() al final en material complementario    \nmyROC(predichos = pred0_prune, reales = target)\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Tuning con caret\n\n- A diferencia de los parámetros que se \"aprenden\" duarante el entrenamiento del modelo, los hipeparámetros se definen previo al ajuste del mismo. \n- El ajuste de [hiperparámetros](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) se constituye como parte fundamental de la optimización del modelo.\n- La biblioteca [`caret`](http://topepo.github.io/caret/index.html) proporciona un marco de trabajo unificado para entrenar y validar modelos de machine learning. En este caso, con `caret` podremos ajustar dos de los tres hiperparámetros mencionados anteriormente, el parámetro de complejidad y la profundidad del árbol. Las funciones **`trainControl()`** y **`train`** de la biblioteca `caret` facilitan el proceso.\n    - **`trainControl()`:** permite establecer la estrategia de validación, por ejemplo validación cruzada *k-fold*, validación cruzada repetida, bootstrapping, entre otras. Desde esta misma función también es posible determinar el método de búsqueda de hiperparámetros, que puede ser *aleatoria* o *cuadrícula (grid)*. En este caso particular utilizo *validación cruzada con repeticiones*, con k = 5 y 3 repeticiones. El argumento `summaryFunction = twoClassSummary` permite computar las métricas necesarias (sensitividad y especificidad) para obtener ROC.  Busque  más ayuda con `help(\"trainControl\")`.\n    - **`train()`:** ajuste el modelo estableciendo la fórmula habitual en R, el método o algoritmo para entrenar, ([lista de algoritmos en `caret`](http://topepo.github.io/caret/available-models.html)) los datos, la configuración para el entrenamiento (`tcConrol = myControl`) y la longitud de hiperparámetros a considerar en el entrenamiento (`tuneLenth`). Este último argumento dependerá de los hiperparámetros que estén disponibles en `caret`, aunque también es posible asignarlos manualmente a través de `expand.grid()`. Utilizar el método igualado a \"rpart\" permitirá optimizar el parámetro *cp* y utilizando \"rpart2\" es posible optimizar la máxima profundidad del árbol. Cuando se declara `tuneLength = 5` se informa que el número máximo de profundidades a probar será 5, es decir, que al final existirán 5 resultados diferentes con el mismo algoritmo. Por último, se agrega la métrica que será utilizada para comparar los resultados de la validación cruzada.\n- **Nota:** como el procedimiento de validación cruzada implica muestreo aleatorio, es necesario asignar la semilla para garantizar replicabilidad de resultados.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmyControl <- trainControl(method = \"repeatedcv\",\n                          number = 5,\n                          repeats = 3,\n                          classProbs = TRUE,  # Permite predecir probabilidades\n                          summaryFunction = twoClassSummary) \nset.seed(1992)\nmodArbol_tune <- train(class ~ .,\n                       method = \"rpart2\",\n                       data = data,\n                       trControl = myControl,\n                       tuneLength = 5,\n                       metric = \"ROC\")\nmodArbol_tune\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n1000 samples\n  20 predictor\n   2 classes: 'bad', 'good' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold, repeated 3 times) \nSummary of sample sizes: 800, 800, 800, 800, 800, 800, ... \nResampling results across tuning parameters:\n\n  maxdepth  ROC        Sens       Spec     \n   3        0.7028968  0.3011111  0.8885714\n   6        0.7138095  0.3244444  0.8880952\n  11        0.7211151  0.3988889  0.8642857\n  14        0.7213571  0.4055556  0.8623810\n  18        0.7211746  0.3911111  0.8671429\n\nROC was used to select the optimal model using the largest value.\nThe final value used for the model was maxdepth = 14.\n```\n:::\n:::\n\n- Se observa que la mejor profundidad es 14 con la mayor sensitividad aún cuando no tiene la mejor especificidad. A continuación la matriz de confusión en el conjunto de test muestra mejoras en la capacidad de detectar los clasificados como \"malos\", ademas la precisión es notablemente superior.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredichos_tune <- predict(object = modArbol_tune, newdata = dataTest, type = \"raw\")\nconfusionMatrix(data = predichos_tune, reference = as.factor(dataTest$class),\n                positive = \"good\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction bad good\n      bad   52   29\n      good  38  181\n                                          \n               Accuracy : 0.7767          \n                 95% CI : (0.7253, 0.8225)\n    No Information Rate : 0.7             \n    P-Value [Acc > NIR] : 0.001839        \n                                          \n                  Kappa : 0.4526          \n                                          \n Mcnemar's Test P-Value : 0.328393        \n                                          \n            Sensitivity : 0.8619          \n            Specificity : 0.5778          \n         Pos Pred Value : 0.8265          \n         Neg Pred Value : 0.6420          \n             Prevalence : 0.7000          \n         Detection Rate : 0.6033          \n   Detection Prevalence : 0.7300          \n      Balanced Accuracy : 0.7198          \n                                          \n       'Positive' Class : good            \n                                          \n```\n:::\n:::\n\n\n- **Área bajo la curva** el modelo evidentemente consigue mejores resultados respecto a los ajustados inicialmente, de tal manera que el ajuste de hiperparámetros ha logrado mejorar nuestras predicciones en datos que el modelo aún no ha visto. Posiblemente el hecho de ajustar la máxima profundidad sumado al uso de validación cruzada, permite que el modelo capture de mejor manera las relaciones subyacentes entre características.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Probabilidades predichas para la clase \"good\"\npred_tune <- as.data.frame(predict(object = modArbol_tune,\n                                   newdata = dataTest, type = \"prob\"))$good\n\n# AUC\nMetrics::auc(actual = target, predicted = pred_tune)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7888624\n```\n:::\n:::\n\n\n- **Curva ROC:**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Ver función myROC() al final en material complementario    \nmyROC(predichos = pred_tune, reales = target)\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n# Complementario\n\n## Función `plot` + `caret`\n\n- La función `plot()` tiene un método específico para resultados obtenidos a través de `caret`, en este caso muestra el gráfico del hiperparámetro de interés, la máxima profundidad del árbol vs la curva ROC en el eje Y, tratando de evidenicar el valor óptimo.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(modArbol_tune)\n```\n\n::: {.cell-output-display}\n![](TreeD_R_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Gráfico interactivo con `visNetwork`\n\n- La biblioteca [`visNetwork`](https://datastorm-open.github.io/visNetwork/) permite crear gráficos interactivos para objetos de la clase *rpart*. A manera de ejemplo se presenta el gráfico para el árbol de decisión con poda. Recuerde que es interactivo y puede manipularlo con el *mouse*.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(visNetwork)\nvisTree(modArbol0_prune, \n        main = \"Árbol con poda\", width = \"100%\",\n        height = \"800px\",  edgesFontSize = 14, nodesFontSize = 16,)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-4b2849920125f3c0d1eb\" style=\"width:100%;height:800px;\" class=\"visNetwork html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-4b2849920125f3c0d1eb\">{\"x\":{\"nodes\":{\"id\":[1,2,4,5,10,11,22,44,45,23,3],\"label\":[\"checking_status\",\"credit_history\",\"bad\",\"duration\",\"bad\",\"purpose\",\"age\",\"bad\",\"good\",\"good\",\"good\"],\"level\":[1,2,3,3,4,4,5,6,6,5,2],\"color\":[\"#F1B8C2\",\"#DAC49C\",\"#7D91B6\",\"#A9D1A5\",\"#7D91B6\",\"#8AD3D0\",\"#B4C7ED\",\"#7D91B6\",\"#B9828C\",\"#B9828C\",\"#B9828C\"],\"value\":[700,385,51,334,77,257,83,42,41,174,315],\"shape\":[\"dot\",\"dot\",\"square\",\"dot\",\"square\",\"dot\",\"dot\",\"square\",\"square\",\"square\",\"square\"],\"title\":[\"<div style=\\\"text-align:center;\\\">N : <b>100%<\\/b> (700)<br>Complexity : <b>0.055<\\/b><br>bad : <b>30%<\\/b> (210)<br>good : <b>70%<\\/b> (490)<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>55%<\\/b> (385)<br>Complexity : <b>0.055<\\/b><br>bad : <b>43.6%<\\/b> (168)<br>good : <b>56.4%<\\/b> (217)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>7.3%<\\/b> (51)<br>Complexity : <b>0.014<\\/b><br>bad : <b>72.5%<\\/b> (37)<br>good : <b>27.5%<\\/b> (14)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> all paid, no credits/all paid<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>47.7%<\\/b> (334)<br>Complexity : <b>0.055<\\/b><br>bad : <b>39.2%<\\/b> (131)<br>good : <b>60.8%<\\/b> (203)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>11%<\\/b> (77)<br>Complexity : <b>0.017<\\/b><br>bad : <b>61%<\\/b> (47)<br>good : <b>39%<\\/b> (30)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> >= 27.5<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>36.7%<\\/b> (257)<br>Complexity : <b>0.038<\\/b><br>bad : <b>32.7%<\\/b> (84)<br>good : <b>67.3%<\\/b> (173)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>11.9%<\\/b> (83)<br>Complexity : <b>0.038<\\/b><br>bad : <b>49.4%<\\/b> (41)<br>good : <b>50.6%<\\/b> (42)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<br><b> purpose <\\/b> domestic appliance, education, new car, retraining<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>6%<\\/b> (42)<br>Complexity : <b>0.017<\\/b><br>bad : <b>69%<\\/b> (29)<br>good : <b>31%<\\/b> (13)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<br><b> purpose <\\/b> domestic appliance, education, new car, retraining<br><b> age <\\/b> < 35.5<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>5.9%<\\/b> (41)<br>Complexity : <b>0.01<\\/b><br>bad : <b>29.3%<\\/b> (12)<br>good : <b>70.7%<\\/b> (29)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<br><b> purpose <\\/b> domestic appliance, education, new car, retraining<br><b> age <\\/b> >= 35.5<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>24.9%<\\/b> (174)<br>Complexity : <b>0.01<\\/b><br>bad : <b>24.7%<\\/b> (43)<br>good : <b>75.3%<\\/b> (131)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<br><b> purpose <\\/b> business, furniture/equipment, other, radio/tv, repairs, used car<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>45%<\\/b> (315)<br>Complexity : <b>0.01<\\/b><br>bad : <b>13.3%<\\/b> (42)<br>good : <b>86.7%<\\/b> (273)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\"  onmouseover=\\\"this.style.cursor='pointer';\\\" onmouseout=\\\"this.style.cursor='default';\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> >=200, no checking<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\"],\"fixed\":[true,true,true,true,true,true,true,true,true,true,true],\"colorClust\":[\"#B9828C\",\"#B9828C\",\"#7D91B6\",\"#B9828C\",\"#7D91B6\",\"#B9828C\",\"#B9828C\",\"#7D91B6\",\"#B9828C\",\"#B9828C\",\"#B9828C\"],\"labelClust\":[\"good\",\"good\",\"bad\",\"good\",\"bad\",\"good\",\"good\",\"bad\",\"good\",\"good\",\"good\"],\"Leaf\":[0,0,1,0,1,0,0,1,1,1,1],\"font.size\":[16,16,16,16,16,16,16,16,16,16,16],\"scaling.min\":[22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5],\"scaling.max\":[22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5]},\"edges\":{\"id\":[\"edge1\",\"edge2\",\"edge3\",\"edge4\",\"edge5\",\"edge6\",\"edge7\",\"edge8\",\"edge9\",\"edge10\"],\"from\":[1,2,2,5,5,11,22,22,11,1],\"to\":[2,4,5,10,11,22,44,45,23,3],\"label\":[\"<0, 0<=...\",\"all pai...\",\"critica...\",\">= 27.5\",\"< 27.5\",\"domesti...\",\"< 35.5\",\">= 35.5\",\"busines...\",\">=200, ...\"],\"value\":[385,51,334,77,257,83,42,41,174,315],\"title\":[\"<div style=\\\"text-align:center;\\\"><b>checking_status<\\/b><\\/div><div style=\\\"text-align:center;\\\"><0<\\/div><div style=\\\"text-align:center;\\\">0<=X<200<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>credit_history<\\/b><\\/div><div style=\\\"text-align:center;\\\">all paid<\\/div><div style=\\\"text-align:center;\\\">no credits/all paid<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>credit_history<\\/b><\\/div><div style=\\\"text-align:center;\\\">critical/other existing credit<\\/div><div style=\\\"text-align:center;\\\">delayed previously<\\/div><div style=\\\"text-align:center;\\\">existing paid<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>duration<\\/b><\\/div><div style=\\\"text-align:center;\\\">>=27.5<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>duration<\\/b><\\/div><div style=\\\"text-align:center;\\\"><27.5<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>purpose<\\/b><\\/div><div style=\\\"text-align:center;\\\">domestic appliance<\\/div><div style=\\\"text-align:center;\\\">education<\\/div><div style=\\\"text-align:center;\\\">new car<\\/div><div style=\\\"text-align:center;\\\">retraining<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>age<\\/b><\\/div><div style=\\\"text-align:center;\\\"><35.5<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>age<\\/b><\\/div><div style=\\\"text-align:center;\\\">>=35.5<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>purpose<\\/b><\\/div><div style=\\\"text-align:center;\\\">business<\\/div><div style=\\\"text-align:center;\\\">furniture/equipment<\\/div><div style=\\\"text-align:center;\\\">other<\\/div><div style=\\\"text-align:center;\\\">radio/tv<\\/div><div style=\\\"text-align:center;\\\">repairs<\\/div><div style=\\\"text-align:center;\\\">used car<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>checking_status<\\/b><\\/div><div style=\\\"text-align:center;\\\">>=200<\\/div><div style=\\\"text-align:center;\\\">no checking<\\/div>\"],\"color\":[\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\"],\"font.size\":[14,14,14,14,14,14,14,14,14,14],\"font.align\":[\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\"],\"smooth.enabled\":[true,true,true,true,true,true,true,true,true,true],\"smooth.type\":[\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\"],\"smooth.roundness\":[0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5]},\"nodesToDataframe\":true,\"edgesToDataframe\":true,\"options\":{\"width\":\"100%\",\"height\":\"100%\",\"nodes\":{\"shape\":\"dot\"},\"manipulation\":{\"enabled\":false},\"layout\":{\"hierarchical\":{\"enabled\":true,\"direction\":\"UD\"}},\"interaction\":{\"dragNodes\":false,\"selectConnectedEdges\":false,\"tooltipDelay\":500,\"zoomSpeed\":1},\"edges\":{\"scaling\":{\"label\":{\"enabled\":false}}}},\"groups\":null,\"width\":\"100%\",\"height\":\"800px\",\"idselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"useLabels\":true,\"main\":\"Select by id\"},\"byselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"multiple\":false,\"hideColor\":\"rgba(200,200,200,0.5)\",\"highlight\":false},\"main\":{\"text\":\"Árbol con poda\",\"style\":\"font-family:Georgia, Times New Roman, Times, serif;font-weight:bold;font-size:20px;text-align:center;\"},\"submain\":{\"text\":\"\",\"style\":\"font-family:Georgia, Times New Roman, Times, serif;font-size:12px;text-align:center;\"},\"footer\":{\"text\":\"\",\"style\":\"font-family:Georgia, Times New Roman, Times, serif;font-size:12px;text-align:center;\"},\"background\":\"rgba(0, 0, 0, 0)\",\"highlight\":{\"enabled\":true,\"hoverNearest\":false,\"degree\":{\"from\":50000,\"to\":0},\"algorithm\":\"hierarchical\",\"hideColor\":\"rgba(200,200,200,0.5)\",\"labelOnly\":true},\"collapse\":{\"enabled\":true,\"fit\":true,\"resetHighlight\":true,\"clusterOptions\":{\"fixed\":true,\"physics\":false},\"keepCoord\":true,\"labelSuffix\":\"(cluster)\"},\"tooltipStay\":300,\"tooltipStyle\":\"position: fixed;visibility:hidden;padding: 5px;\\n                      white-space: nowrap;\\n                      font-family: cursive;font-size:12px;font-color:purple;background-color: #E6E6E6;\\n                      border-radius: 15px;\",\"OnceEvents\":{\"stabilized\":\"function() { \\n        this.setOptions({layout:{hierarchical:false}, physics:{solver:'barnesHut', enabled:true, stabilization : false}, nodes : {physics : false, fixed : true}});\\n    }\"},\"legend\":{\"width\":0.1,\"useGroups\":false,\"position\":\"left\",\"ncol\":1,\"stepX\":100,\"stepY\":100,\"zoom\":true,\"nodes\":{\"label\":[\"age\",\"checking_status\",\"credit_history\",\"duration\",\"purpose\",\"bad\",\"good\"],\"color\":[\"#B4C7ED\",\"#F1B8C2\",\"#DAC49C\",\"#A9D1A5\",\"#8AD3D0\",\"#7D91B6\",\"#B9828C\"],\"shape\":[\"dot\",\"dot\",\"dot\",\"dot\",\"dot\",\"square\",\"square\"],\"size\":[22,22,22,22,22,22,22],\"Leaf\":[0,0,0,0,0,1,1],\"font.size\":[16,16,16,16,16,16,16],\"id\":[10000,10001,10002,10003,10004,10005,10006]},\"nodesToDataframe\":true},\"tree\":{\"updateShape\":true,\"shapeVar\":\"dot\",\"shapeY\":\"square\",\"colorVar\":{\"variable\":[\"checking_status\",\"credit_history\",\"duration\",\"purpose\",\"age\"],\"color\":[\"#F1B8C2\",\"#DAC49C\",\"#A9D1A5\",\"#8AD3D0\",\"#B4C7ED\"]},\"colorY\":{\"colorY\":{\"modality\":[\"bad\",\"good\"],\"color\":[\"#7D91B6\",\"#B9828C\"]},\"vardecidedClust\":[\"good\",\"good\",\"bad\",\"good\",\"bad\",\"good\",\"good\",\"bad\",\"good\",\"good\",\"good\"]}},\"export\":{\"type\":\"png\",\"css\":\"float:right;-webkit-border-radius: 10;\\n                  -moz-border-radius: 10;\\n                  border-radius: 10px;\\n                  font-family: Arial;\\n                  color: #ffffff;\\n                  font-size: 12px;\\n                  background: #090a0a;\\n                  padding: 4px 8px 4px 4px;\\n                  text-decoration: none;\",\"background\":\"#fff\",\"name\":\"network.png\",\"label\":\"Export as png\"}},\"evals\":[\"OnceEvents.stabilized\"],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n\n## Función `myROC()`\n\n- Es necesario tener cargadas las bibliotecaS  `dplyr`, `ggplot2`, `hrbrthemes`, `Metrics` y `pROC` para ejecutar la función.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmyROC <- function(predichos, reales) {\n  suppressMessages(suppressWarnings(library(dplyr)))\n  suppressMessages(suppressWarnings(library(ggplot2)))\n  suppressMessages(suppressWarnings(library(pROC)))\n  suppressMessages(suppressWarnings(library(Metrics)))\n  x = roc(reales, predichos)\n  df = data_frame(TPR = x$sensitivities,\n                  FPR = 1 - x$specificities)\n  gg = df %>%\n    ggplot(aes(x = FPR, ymin = 0, ymax = TPR)) +\n    geom_polygon(aes(y = TPR), fill = \"#5A5156\", alpha = 0.7) +\n    geom_path(aes(y = TPR), col = \"#F6222E\", size = 1.3) +\n    geom_abline(\n      intercept = 0,\n      slope = 1,\n      color = \"gray37\",\n      size = 1,\n      linetype = \"dashed\"\n    ) +\n    theme_ipsum() +\n    coord_equal() +\n    labs(\n      x = \"FPR (1 - Especificidad)\",\n      y = \"TPR (Sensitividad)\",\n      title = paste0(\"Curva ROC\"),\n      subtitle = paste0(\n        \"Valor AUC: \",\n        Metrics::auc(actual = reales,\n                     predicted = predichos) %>% round(4)\n      )\n    )\n  return(gg)\n}\n```\n:::\n\n\n\n# Recursos de información\n\n- [An Introduction to Statistical Learning with Applications in R.](http://faculty.marshall.usc.edu/gareth-james/ISL/)\n- [Tree-Based Models.](https://www.statmethods.net/advstats/cart.html)\n- [Árboles de predicción - Joaquín A. Rodrigo.](https://rpubs.com/Joaquin_AR/255596)\n- [Curso DataCamp - *Tree-Based Models in R*.](https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-r)",
    "supporting": [
      "TreeD_R_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/htmlwidgets-1.5.4/htmlwidgets.js\"></script>\r\n<link href=\"../../site_libs/vis-9.1.0/vis-network.min.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/vis-9.1.0/vis-network.min.js\"></script>\r\n<script src=\"../../site_libs/visNetwork-binding-2.1.0/visNetwork.js\"></script>\r\n<script src=\"../../site_libs/FileSaver-1.1.20151003/FileSaver.min.js\"></script>\r\n<script src=\"../../site_libs/Blob-1.0/Blob.js\"></script>\r\n<script src=\"../../site_libs/canvas-toBlob-1.0/canvas-toBlob.js\"></script>\r\n<script src=\"../../site_libs/html2canvas-0.5.0/html2canvas.js\"></script>\r\n<script src=\"../../site_libs/jspdf-1.3.2/jspdf.debug.js\"></script>\r\n<script src=\"../../site_libs/jquery-1.11.3/jquery.min.js\"></script>\r\n<link href=\"../../site_libs/jquery-sparkline-2.1.2/jquery.sparkline.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/jquery-sparkline-2.1.2/jquery.sparkline.js\"></script>\r\n<script src=\"../../site_libs/sparkline-binding-2.0/sparkline.js\"></script>\r\n<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}