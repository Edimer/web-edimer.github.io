[
  {
    "path": "posts/XGBoost_R/",
    "title": "XGBoost: R",
    "description": "Algortimo XGBoost con R para resolver problemas de aprendizaje supervisado (clasificación y regresión).",
    "author": [
      {
        "name": "Edimer David Jaramillo (Sidereus)",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2021-05-01",
    "categories": [
      "R",
      "xgboost",
      "Gradient Boosting"
    ],
    "contents": "\r\n\r\nContents\r\nAlgortimo xgboost\r\nGeneralidades\r\nImplementación en R\r\nDocumentación xgboost\r\n\r\nDatos de ejemplo\r\nClasificación: detección de mastitis\r\nRegresión: predicción de la producción de sorgo\r\n\r\nRequisitos previos\r\nBibliotecas\r\nTema para ggplot2\r\nDetección de mastitis\r\nBase de datos\r\nAnálisis exploratorio\r\nTrain y Test\r\nTuning con tidymodels\r\nDesempeño del modelo\r\nImportancia de variables\r\n\r\nProducción de sorgo\r\nBase de datos\r\nAnálisis exploratorio\r\nTrain y Test\r\nTuning con tidymodels\r\nDesempeño del modelo\r\nImportancia de variables\r\n\r\nRecursos de información\r\n\r\nAlgortimo xgboost\r\nGeneralidades\r\nImplementación en R\r\nDocumentación xgboost\r\nDocumentación oficial xgboost\r\nBiblioteca xgboost en R\r\nTutorial de xgboost en R\r\nDatos de ejemplo\r\nEn este documento se pretende mostrar cómo implementar el algoritmo xgboost con R a través de la biblioteca que lleva el mismo nombre y haciendo uso del tidymodels. Para ejemplificar el ajuste de modelos de clasificación se obtuvieron datos de ejemplo aplicado en ciencias animales, especificamente en la detección de patrones de infección de mastitis en vacas. Para el ejemplo de modelos de regresión se usaron datos de producción de sorgo en Italia.\r\nClasificación: detección de mastitis\r\nArtículo publicado en PLOS ONE\r\n\r\n\r\nRegresión: predicción de la producción de sorgo\r\nArtículo publicado en Nature\r\n\r\n\r\nRequisitos previos\r\nPara replicar este documento es necesario instalar las siguientes bibliotecas:\r\ntidyverse: manipulación y visualización de datos.\r\nreadxl: lectura de datos en formato de Excel.\r\njanitor: manipulación de datos.\r\nskimr: análisis descriptivo y exploratorio de datos.\r\ntidymodels: entrenamiento y evaluación de modelos de machine learning.\r\nxgboost: algoritmo xgboost.\r\nvip: calcular importancia de variables.\r\ntidyquant: (opcional) definición de tema (theme_tq()) para gráficos con ggplot2.\r\n\r\nDescargar los datos para cada ejemplo:\r\nDatos para detección de mastitis\r\nDatos de producción de sorgo\r\n\r\nBibliotecas\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(readxl)\r\nlibrary(skimr)\r\nlibrary(janitor)\r\nlibrary(tidymodels)\r\nlibrary(xgboost)\r\nlibrary(tidyquant)\r\nlibrary(vip)\r\n\r\n\r\n\r\nTema para ggplot2\r\n\r\n\r\ntheme_set(theme_tq())\r\n\r\n\r\n\r\nDetección de mastitis\r\nLa variable respuesta está identificada como diagnosis. En principio tiene 4 niveles, sin embargo, para el ejemplo fueron filtrados sólo los niveles EDP (transmisión en el período seco - sin lactancia) y EL (transmisión en período de lactancia).\r\nLa base de datos consta de 1000 observaciones y 229 variables, es decir, que existen 228 variables predictoras. Cuando se aplicó el filtro quedaron 914 observaciones.\r\nBase de datos\r\n\r\n\r\nmastitis <- read_csv(\"data/mastitis.csv\") %>% \r\n  clean_names() %>% \r\n  filter(diagnosis %in% c(\"EDP\", \"EL\"))\r\n\r\nmastitis %>% head()\r\n\r\n\r\n# A tibble: 6 x 229\r\n  quarter_dates_q0 no_recordings_q0 l_1_q0_bmscc_000~ l_1_q0_percent_~\r\n  <chr>                       <dbl>             <dbl>            <dbl>\r\n1 06/10/2009                      0                 0              0  \r\n2 06/12/2009                      3               284             27.8\r\n3 20/04/2012                      0                 0              0  \r\n4 16/07/2009                      3               222             21.1\r\n5 16/10/2013                      3               251             27.5\r\n6 12/01/2013                      3               154             12.3\r\n# ... with 225 more variables: l_1_q0_percent_200k <dbl>,\r\n#   l_1_q0_lactation_new_imi_percent <dbl>,\r\n#   l_1_q0_dry_period_new_imi_percent <dbl>,\r\n#   l_1_q0_apparent_dry_period_cure_percent <dbl>,\r\n#   l_1_q0_dry_period_origin_cm_rate_in_12 <dbl>,\r\n#   l_1_q0_lactating_period_origin_cm_rate_in_12 <dbl>,\r\n#   l_1_q0_qrt_cmir_100_cows_year <dbl>,\r\n#   l_1_q0_cow_cmir_100_cows_year <dbl>,\r\n#   l_1_q0_clinical_mastitis_cure_rate_1st_case <dbl>,\r\n#   l_1_q0_no_calved <dbl>, l_1_q0_bmscc_000_cells_ml_2 <dbl>,\r\n#   l_1_q0_percent_chronic_2 <dbl>, l_1_q0_percent_200k_2 <dbl>,\r\n#   l_1_q0_lactation_new_imi_percent_2 <dbl>,\r\n#   l_1_q0_dry_period_new_imi_percent_2 <dbl>,\r\n#   l_1_q0_apparent_dry_period_cure_percent_2 <dbl>,\r\n#   l_1_q0_dry_period_origin_cm_rate_in_12_2 <dbl>,\r\n#   l_1_q0_lactating_period_origin_cm_rate_in_12_2 <dbl>,\r\n#   l_1_q0_qrt_cmir_100_cows_year_2 <dbl>,\r\n#   l_1_q0_cow_cmir_100_cows_year_2 <dbl>,\r\n#   l_1_q0_clinical_mastitis_cure_rate_1st_case_2 <dbl>,\r\n#   l_1_q0_no_calved_2 <dbl>, l_1_q0_bmscc_000_cells_ml_3 <dbl>,\r\n#   l_1_q0_percent_chronic_3 <dbl>, l_1_q0_percent_200k_3 <dbl>,\r\n#   l_1_q0_lactation_new_imi_percent_3 <dbl>,\r\n#   l_1_q0_dry_period_new_imi_percent_3 <dbl>,\r\n#   l_1_q0_apparent_dry_period_cure_percent_3 <dbl>,\r\n#   l_1_q0_dry_period_origin_cm_rate_in_12_3 <dbl>,\r\n#   l_1_q0_lactating_period_origin_cm_rate_in_12_3 <dbl>,\r\n#   l_1_q0_qrt_cmir_100_cows_year_3 <dbl>,\r\n#   l_1_q0_cow_cmir_100_cows_year_3 <dbl>,\r\n#   l_1_q0_clinical_mastitis_cure_rate_1st_case_3 <dbl>,\r\n#   l_1_q0_no_calved_3 <dbl>, q_1_quarter_dates <chr>,\r\n#   q_1_no_recordings <dbl>, l_1_q_1_bmscc_000_cells_ml <dbl>,\r\n#   l_1_q_1_percent_chronic <dbl>, l_1_q_1_percent_200k <dbl>,\r\n#   l_1_q_1_lactation_new_imi_percent <dbl>,\r\n#   l_1_q_1_dry_period_new_imi_percent <dbl>,\r\n#   l_1_q_1_apparent_dry_period_cure_percent <dbl>,\r\n#   l_1_q_1_dry_period_origin_cm_rate_in_12 <dbl>,\r\n#   l_1_q_1_lactating_period_origin_cm_rate_in_12 <dbl>,\r\n#   l_1_q_1_qrt_cmir_100_cows_year <dbl>,\r\n#   l_1_q_1_cow_cmir_100_cows_year <dbl>,\r\n#   l_1_q_1_clinical_mastitis_cure_rate_1st_case <dbl>,\r\n#   l_1_q_1_no_calved <dbl>, l_1_q_1_bmscc_000_cells_ml_2 <dbl>,\r\n#   l_1_q_1_percent_chronic_2 <dbl>, l_1_q_1_percent_200k_2 <dbl>,\r\n#   l_1_q_1_lactation_new_imi_percent_2 <dbl>,\r\n#   l_1_q_1_dry_period_new_imi_percent_2 <dbl>,\r\n#   l_1_q_1_apparent_dry_period_cure_percent_2 <dbl>,\r\n#   l_1_q_1_dry_period_origin_cm_rate_in_12_2 <dbl>,\r\n#   l_1_q_1_lactating_period_origin_cm_rate_in_12_2 <dbl>,\r\n#   l_1_q_1_qrt_cmir_100_cows_year_2 <dbl>,\r\n#   l_1_q_1_cow_cmir_100_cows_year_2 <dbl>,\r\n#   l_1_q_1_clinical_mastitis_cure_rate_1st_case_2 <dbl>,\r\n#   l_1_q_1_no_calved_2 <dbl>, l_1_q_1_bmscc_000_cells_ml_3 <dbl>,\r\n#   l_1_q_1_percent_chronic_3 <dbl>, l_1_q_1_percent_200k_3 <dbl>,\r\n#   l_1_q_1_lactation_new_imi_percent_3 <dbl>,\r\n#   l_1_q_1_dry_period_new_imi_percent_3 <dbl>,\r\n#   l_1_q_1_apparent_dry_period_cure_percent_3 <dbl>,\r\n#   l_1_q_1_dry_period_origin_cm_rate_in_12_3 <dbl>,\r\n#   l_1_q_1_lactating_period_origin_cm_rate_in_12_3 <dbl>,\r\n#   l_1_q_1_qrt_cmir_100_cows_year_3 <dbl>,\r\n#   l_1_q_1_cow_cmir_100_cows_year_3 <dbl>,\r\n#   l_1_q_1_clinical_mastitis_cure_rate_1st_case_3 <dbl>,\r\n#   l_1_q_1_no_calved_3 <dbl>, q_2_quarter_dates <chr>,\r\n#   q_2_no_recordings <dbl>, l_1_q_2_bmscc_000_cells_ml <dbl>,\r\n#   l_1_q_2_percent_chronic <dbl>, l_1_q_2_percent_200k <dbl>,\r\n#   l_1_q_2_lactation_new_imi_percent <dbl>,\r\n#   l_1_q_2_dry_period_new_imi_percent <dbl>,\r\n#   l_1_q_2_apparent_dry_period_cure_percent <dbl>,\r\n#   l_1_q_2_dry_period_origin_cm_rate_in_12 <dbl>,\r\n#   l_1_q_2_lactating_period_origin_cm_rate_in_12 <dbl>,\r\n#   l_1_q_2_qrt_cmir_100_cows_year <dbl>,\r\n#   l_1_q_2_cow_cmir_100_cows_year <dbl>,\r\n#   l_1_q_2_clinical_mastitis_cure_rate_1st_case <dbl>,\r\n#   l_1_q_2_no_calved <dbl>, l_1_q_2_bmscc_000_cells_ml_2 <dbl>,\r\n#   l_1_q_2_percent_chronic_2 <dbl>, l_1_q_2_percent_200k_2 <dbl>,\r\n#   l_1_q_2_lactation_new_imi_percent_2 <dbl>,\r\n#   l_1_q_2_dry_period_new_imi_percent_2 <dbl>,\r\n#   l_1_q_2_apparent_dry_period_cure_percent_2 <dbl>,\r\n#   l_1_q_2_dry_period_origin_cm_rate_in_12_2 <dbl>,\r\n#   l_1_q_2_lactating_period_origin_cm_rate_in_12_2 <dbl>,\r\n#   l_1_q_2_qrt_cmir_100_cows_year_2 <dbl>,\r\n#   l_1_q_2_cow_cmir_100_cows_year_2 <dbl>,\r\n#   l_1_q_2_clinical_mastitis_cure_rate_1st_case_2 <dbl>,\r\n#   l_1_q_2_no_calved_2 <dbl>, l_1_q_2_bmscc_000_cells_ml_3 <dbl>,\r\n#   l_1_q_2_percent_chronic_3 <dbl>, ...\r\n\r\nAnálisis exploratorio\r\nFrecuencia de variable respuesta:\r\n\r\n\r\nmastitis %>% \r\n  count(diagnosis) %>% \r\n  ggplot(aes(x = diagnosis, y = n)) +\r\n  geom_col(color = \"dodgerblue3\", fill = \"dodgerblue3\", alpha = 0.8) +\r\n  geom_label(aes(label = n)) +\r\n  labs(x = \"Diagnóstico\", y = \"Frecuencia\")\r\n\r\n\r\n\r\n\r\nFigure 1: Frecuencia absoluta de variable respuesta\r\n\r\n\r\n\r\nTrain y Test\r\nTuning con tidymodels\r\nDesempeño del modelo\r\nImportancia de variables\r\nProducción de sorgo\r\nBase de datos\r\nAnálisis exploratorio\r\nTrain y Test\r\nTuning con tidymodels\r\nDesempeño del modelo\r\nImportancia de variables\r\nRecursos de información\r\n\r\n\r\n\r\n",
    "preview": "posts/XGBoost_R/img2.png",
    "last_modified": "2021-05-01T17:21:07-05:00",
    "input_file": {}
  },
  {
    "path": "posts/TreeD_R/",
    "title": "Árbol de clasificación con R",
    "description": "Ejemplo de árboles de decisión en machine learning supervisado para clasificación. Uso de las bibliotecas rpart, rpart.plot y caret en perfilamiento de riesgo crediticio.",
    "author": [
      {
        "name": "Edimer David Jaramillo (Sidereus)",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-07-18",
    "categories": [
      "R",
      "Tree Decision"
    ],
    "contents": "\r\n\r\nContents\r\nContenido\r\nRequisitos previos\r\nBibliotecas\r\nDescripción de variables\r\nDatos\r\nDistribución de variable respuesta\r\nExploratorio\r\nInferencia\r\nÁrboles de decisión\r\nGeneralidades\r\nTrain - Test\r\nrpart default\r\nTuning con caret\r\n\r\nComplementario\r\nFunción plot + caret\r\nGráfico interactivo con visNetwork\r\nFunción myROC()\r\n\r\nRecursos de información\r\n\r\n\r\n\r\nContenido\r\n1. Información general (requisitos previos, bibliotecas, etc).2. Análisis inicial de los datos. Como el objetivo principal del documento es entrenar un modelo de árbol de decisión con R, el análisis inicial incluye sólo una parte exploratoria y algunas pruebas estadísticas.3. Entrenamiento de modelo por defecto con rpart.4. Ajuste de hiperparámetros con la biblioteca caret. La métrica para evaluar el desempeño predictivo de los modelos es el área bajo la curva ROC.5. Material complementario.6. Recursos de información.\r\nRequisitos previos\r\nInstalar las bibliotecas rpart y rpart.plot para entrenar y gráficar modelos basados en árboles.\r\nInstalar la biblioteca caret.\r\nDescargar datos para ejemplo desde la página openML. La base de datos proporciona información de personas perfiladas con riesgo crediticio bueno o malo.\r\nBibliotecas complementarias: para visualizaciones ggplot2, jcolors y hrbrthemes, para manejo de datos dplyr y para métricas de error y/o precisión Metrics y pROC.\r\nBibliotecas\r\n\r\n\r\nlibrary(dplyr)\r\nlibrary(ggplot2)\r\nlibrary(jcolors)\r\nlibrary(hrbrthemes)\r\nlibrary(rpart)\r\nlibrary(rpart.plot)\r\nlibrary(caret)\r\nlibrary(Metrics)\r\nlibrary(pROC)\r\n\r\n\r\n\r\nDescripción de variables\r\nAdemás de la variable respuesta class, se cuenta con las siguientes 20 variables.\r\n\r\n\r\nDatos\r\nSe importan los datos y se aplica la función mutate_if() para eliminar las comillas simples (’’) que están presentes en las variables tipo texto (character). A continuación sólo se muestran 5 variables (columnas) con 10 observaciones. La variable class es nuestro target o variable respuesta.\r\n\r\n\r\ndata <- data.table::fread(file = \"data/dataset_31_credit-g.csv\") %>% \r\n  mutate_if(is.character, funs(gsub(\"'\", \"\", .)))\r\nhead(data[1:10, c(1, 5, 10, 15, 21)], n = 10L) # Imprimiendo sólo 5 columnas\r\n\r\n\r\n    checking_status credit_amount other_parties  housing class\r\n 1:              <0          1169          none      own  good\r\n 2:        0<=X<200          5951          none      own   bad\r\n 3:     no checking          2096          none      own  good\r\n 4:              <0          7882     guarantor for free  good\r\n 5:              <0          4870          none for free   bad\r\n 6:     no checking          9055          none for free  good\r\n 7:     no checking          2835          none      own  good\r\n 8:        0<=X<200          6948          none     rent  good\r\n 9:     no checking          3059          none      own  good\r\n10:        0<=X<200          5234          none      own   bad\r\n\r\nDimensión de la base de datos:\r\n\r\n\r\ndim(data)\r\n\r\n\r\n[1] 1000   21\r\n\r\nDistribución de variable respuesta\r\n\r\n\r\ndata %>% \r\n  ggplot(mapping = aes(x = class, fill = class)) +\r\n  geom_bar(color = \"black\") + \r\n  scale_fill_manual(values = c(\"#5A5156\", \"#F6222E\")) +\r\n  theme_ipsum() +\r\n  theme(legend.position = \"none\")\r\n\r\n\r\n\r\n\r\nExploratorio\r\nDistribución de edad por variable objetivo: se puede apreciar que la edad promedio de los clasificados como “buenos” es más alta, además, los clasificados como “malos” en su mayoría son personas entre 20 y 30 años de edad.\r\n\r\n\r\ndata %>% \r\n  ggplot(mapping = aes(x = class, y = age, fill = class)) +\r\n  geom_violin() +\r\n  geom_boxplot(color = \"#E4E1E3\", width = 0.1, show.legend = FALSE)  +\r\n  stat_summary(fun.y = mean, color = \"#E4E1E3\", pch = 17) +\r\n  scale_fill_manual(values = c(\"#5A5156\", \"#F6222E\")) +\r\n  theme_ipsum() +\r\n  theme(legend.position = \"none\") +\r\n  labs(caption = \"El triángulo representa el promedio.\")\r\n\r\n\r\n\r\n\r\nPropósitos de crédito más frecuentes: la distribución de personas clasificadas como buenas o malas cuando el propósito es vehículo, discrepa bastante entre la opción de nuevo o usado. En vehículos usados la gran mayoría son clasificados como “buenos”, sin embargo, cuando se trata de vehículos nuevos, la distribución es similar, lo que permite inferir que es más probable que una persona se comporte como mal pagador en créditos para vehículo nuevo respecto a créditos para vehículos usados. También se podría intuir que cuando se trata de créditos para educación es igual de probable que la persona sea clasificada como “bueno” o “malo”.\r\n\r\n\r\ndata %>% \r\n  group_by(class, purpose) %>% \r\n  count() %>% \r\n  ggplot(mapping = aes(x = reorder(purpose, n), y = n, fill = class)) +\r\n  geom_col(color = \"#E4E1E3\", position = \"dodge\") +\r\n  scale_fill_manual(values = c(\"#5A5156\", \"#F6222E\")) +\r\n  labs(x = \"Purpose\") +\r\n  theme_ipsum() +\r\n  theme(legend.position = \"top\",\r\n        axis.text.x = element_text(angle = 45, hjust = 1))\r\n\r\n\r\n\r\n\r\nInferencia\r\nAnálisis de varianza: en vista de la discrepancia que se observa en la distribución de las edades para personas clasificadas como “buenas” o “malas”, realizo el análisis de varianza para contrastar si dichas diferencias son estadísticamente significativas. Nota: aunque nuestra variable respuesta es class, en este caso actúa como “predictora” o fuente de variación.\r\n\r\n\r\nmyAnova <- aov(age ~ class, data = data)\r\nsummary(myAnova)\r\n\r\n\r\n             Df Sum Sq Mean Sq F value  Pr(>F)   \r\nclass         1   1074  1073.5   8.357 0.00393 **\r\nResiduals   998 128198   128.5                   \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nEl resultado de la prueba muestra que existe evidencia estadísticamente significativa (p=0.00393) para considerar que la variación de la edad entre ambos grupos es diferente.\r\nÁrboles de decisión\r\n\r\n\r\nGeneralidades\r\n\r\n\r\nLos árboles de decisión se pueden utilizar para problemas de regresión y clasificación.\r\nSe pueden definir como una estructura jerárquica que busca particionar el espacio de características e identificar subconjuntos representativos. Desde la parte superior a inferior cada árbol tiene nodo raíz, nodos de decisión o internos y nodos hojas o terminales, los dos primeros se generan con base en reglas binarias. Mayor grado de pureza es la recompensa que busca el algoritmo al particionar el espacio inicial en subregiones, en ese orden de ideas el objetivo siempre será particionar los datos en nodos que sean lo más puros posible, sin embargo, matemáticamente es más fácil medir la impureza de una región específica, proporcionando una idea de qué tan heterogéneas son las clases en ese nodo; una métrica de uso común en problemas de clasificación para medir la impureza es el índice GINI, donde valores bajos indican mayor grado de pureza. Además del índice GINI también es posible utilizar otras métricas como la ganancia de información o la entropía.\r\nVentajas:\r\nFácil de interpretar (sujeto a la profundidad).\r\nNo requieren estandarización o normalización de variables predictoras numéricas.\r\nPermiten manipular variables categóricas sin necesidad de aplicar codificaciones tipo one-hot o variables dummy.\r\nRequieren poco preprocesamiento de datos.\r\nPermiten valores ausentes (NA).\r\nPermite relaciones no lineales.\r\n\r\nDesventajas:\r\nSi no se controla adecuadamente la profundidad del árbol existe alta probabilidad de incurrir en sobreajuste (overfitting).\r\nAlta varianza, pequeños cambios en los datos pueden arrojar resultados muy diferentes.\r\n\r\nHiperparámetros: aunque ejecutar la función rpart() con valores predeterminados puede ser una buena estrategia para iniciar, siempre estaremos interesados en ajustar determinados parámetros que nos permitan obtener mejor rendimiento predictivo. La función rpart.control() permite controlar manualmente otras opciones. Dentro los hiperparámetros más importantes en árboles de decisión están los siguientes:\r\nMínimo número de observaciones para generar una partición. En la biblioteca rpart lleva el nombre de minsplit y su valor por defecto es 20.\r\nMáxima profundiad del árbol. En la biblioteca rpart lleva el nombre de maxdepth y su valor predeterminado es 30. Este parámetro es de alta relevancia para evitar el sobreajuste.\r\nParámetro de complejidad. En la biblioteca rpart lleva el nombre de cp y su valor por defecto es 0.01. Este parámetro sirve al propósito de penalizar y contolar el tamaño del árbol, valores bajos indican árboles de mayor complejidad, es decir, mayor número de divisiones. La función rpart() internamente ejecuta validación cruzada 10 veces para estimar el valor óptimo de cp, es posible acceder a dicho resultado a través de la función plotcp() que permitirá facilmente determinar el valor adecuado para este parámetro. Cuando se tiene el valor óptimo de cp será posible “podar” el árbol para que el modelo sea optimizado, dicho resultado es posible a través de la función prune().\r\n\r\nTrain - Test\r\nPara entrenar el modelo inicialmente fracciono los datos en train y test con proporciones de 70 y 30%, respectivamente. Este proceso aunque es posible hacerlo manualmente con la función sample(), la función createDataPartition() del paquete caret agiliza el procedimiento. Para garantizar replicabilidad en los resultados se agrega la semilla.\r\n\r\n\r\nset.seed(1992)\r\nidx <- createDataPartition(y = data$class, times = 1, p = 0.70, list = FALSE)\r\ndataTrain <- data[idx, ]\r\ndataTest <- data[-idx, ]\r\n\r\n\r\n\r\nrpart default\r\nAjuste del modelo: en este caso se utilizan todas las variables predictoras para entrenar el modelo. Al imprimir el objeto que contiene el modelo podemos observar el conjunto de reglas que dan como resultado la estructura final del árbol. El método igualado a method = \"class\" indica que es un problema de clasificación, si fuese un problema de regresión el argumento tomaría el valor de method = \"anova\", aunque también permite otras opciones (consulte ?rpart o help(\"rpart\")).\r\n\r\n\r\nmodArbol0 <- rpart(class ~ ., data = dataTrain, method = \"class\")\r\nmodArbol0\r\n\r\n\r\nn= 700 \r\n\r\nnode), split, n, loss, yval, (yprob)\r\n      * denotes terminal node\r\n\r\n  1) root 700 210 good (0.3000000 0.7000000)  \r\n    2) checking_status=<0,0<=X<200 385 168 good (0.4363636 0.5636364)  \r\n      4) credit_history=all paid,no credits/all paid 51  14 bad (0.7254902 0.2745098)  \r\n        8) savings_status=<100,100<=X<500 42   8 bad (0.8095238 0.1904762) *\r\n        9) savings_status=500<=X<1000,no known savings 9   3 good (0.3333333 0.6666667) *\r\n      5) credit_history=critical/other existing credit,delayed previously,existing paid 334 131 good (0.3922156 0.6077844)  \r\n       10) duration>=27.5 77  30 bad (0.6103896 0.3896104)  \r\n         20) purpose=domestic appliance,education,furniture/equipment,new car 39  10 bad (0.7435897 0.2564103) *\r\n         21) purpose=business,other,radio/tv,repairs,used car 38  18 good (0.4736842 0.5263158)  \r\n           42) checking_status=<0 19   7 bad (0.6315789 0.3684211) *\r\n           43) checking_status=0<=X<200 19   6 good (0.3157895 0.6842105) *\r\n       11) duration< 27.5 257  84 good (0.3268482 0.6731518)  \r\n         22) purpose=domestic appliance,education,new car,retraining 83  41 good (0.4939759 0.5060241)  \r\n           44) age< 35.5 42  13 bad (0.6904762 0.3095238)  \r\n             88) credit_amount< 1392 20   1 bad (0.9500000 0.0500000) *\r\n             89) credit_amount>=1392 22  10 good (0.4545455 0.5454545)  \r\n              178) property_magnitude=life insurance,real estate 13   4 bad (0.6923077 0.3076923) *\r\n              179) property_magnitude=car,no known property 9   1 good (0.1111111 0.8888889) *\r\n           45) age>=35.5 41  12 good (0.2926829 0.7073171) *\r\n         23) purpose=business,furniture/equipment,other,radio/tv,repairs,used car 174  43 good (0.2471264 0.7528736) *\r\n    3) checking_status=>=200,no checking 315  42 good (0.1333333 0.8666667) *\r\n\r\nGráfico del modelo: la variable más importante y que da origen al nodo raíz es checking_status, que hace referencia al estado de la cuenta corriente. El historial crediticio, la duración del tiempo para pagar el crédito, el estado de la cuenta de ahorros y el propósito del crédito, también son factores determinantes. No tener suficiente capital en cualquiera de las dos cuentas, tener mal historial crediticio y además solicitar períodos de pago de alta duración, pueden ser características no deseables a la hora de solicitar un crédito.\r\n\r\n\r\nrpart.plot(modArbol0)\r\n\r\n\r\n\r\n\r\nMatriz de confusión: el modelo por default tiene precisión promedio de 0.7167, con dificultades para clasificar de forma correcta los “malos”, es decir, que tiene baja especificidad.\r\n\r\n\r\npredichos_mod0 <- predict(object = modArbol0, newdata = dataTest, type = \"class\")\r\nconfusionMatrix(data = predichos_mod0, reference = as.factor(dataTest$class),\r\n                positive = \"good\")\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction bad good\r\n      bad   31   26\r\n      good  59  184\r\n                                        \r\n               Accuracy : 0.7167        \r\n                 95% CI : (0.662, 0.767)\r\n    No Information Rate : 0.7           \r\n    P-Value [Acc > NIR] : 0.2873596     \r\n                                        \r\n                  Kappa : 0.2465        \r\n                                        \r\n Mcnemar's Test P-Value : 0.0005187     \r\n                                        \r\n            Sensitivity : 0.8762        \r\n            Specificity : 0.3444        \r\n         Pos Pred Value : 0.7572        \r\n         Neg Pred Value : 0.5439        \r\n             Prevalence : 0.7000        \r\n         Detection Rate : 0.6133        \r\n   Detection Prevalence : 0.8100        \r\n      Balanced Accuracy : 0.6103        \r\n                                        \r\n       'Positive' Class : good          \r\n                                        \r\n\r\nÁrea bajo la curva:\r\n\r\n\r\n# Probabilidades predichas para la clase \"good\"\r\npred0 <- as.data.frame(predict(object = modArbol0,\r\n                               newdata = dataTest, type = \"prob\"))$good\r\n\r\n# Transformando respuesta a entero. A la clase \"good\" le agrego 1 y \r\n# a la clase \"bad\" le agrego 0.\r\ntarget <- as.integer(as.factor(dataTest$class)) - 1\r\n\r\n# AUC\r\nMetrics::auc(actual = target, predicted = pred0)\r\n\r\n\r\n[1] 0.7034392\r\n\r\nCurva ROC: la función con la que obtengo el siguiente gráfico puede ser encontrada en mi Github.\r\n\r\n\r\n# Cargando función\r\nsource(\"functions/myROC.R\")\r\n\r\n# Ver función myROC() al final en material complementario    \r\nmyROC(predichos = pred0, reales = target)\r\n\r\n\r\n\r\n\r\nParámetro de complejidad (CP):\r\n\r\n\r\nplotcp(modArbol0)\r\n\r\n\r\n\r\n\r\n“Podando” el árbol: se elige el valor de cp = 0.025 por mostrar mejores resultados (bajo error).\r\n\r\n\r\nmodArbol0_prune <- prune(tree = modArbol0, cp = 0.025)\r\nmodArbol0_prune\r\n\r\n\r\nn= 700 \r\n\r\nnode), split, n, loss, yval, (yprob)\r\n      * denotes terminal node\r\n\r\n 1) root 700 210 good (0.3000000 0.7000000)  \r\n   2) checking_status=<0,0<=X<200 385 168 good (0.4363636 0.5636364)  \r\n     4) credit_history=all paid,no credits/all paid 51  14 bad (0.7254902 0.2745098) *\r\n     5) credit_history=critical/other existing credit,delayed previously,existing paid 334 131 good (0.3922156 0.6077844)  \r\n      10) duration>=27.5 77  30 bad (0.6103896 0.3896104) *\r\n      11) duration< 27.5 257  84 good (0.3268482 0.6731518)  \r\n        22) purpose=domestic appliance,education,new car,retraining 83  41 good (0.4939759 0.5060241)  \r\n          44) age< 35.5 42  13 bad (0.6904762 0.3095238) *\r\n          45) age>=35.5 41  12 good (0.2926829 0.7073171) *\r\n        23) purpose=business,furniture/equipment,other,radio/tv,repairs,used car 174  43 good (0.2471264 0.7528736) *\r\n   3) checking_status=>=200,no checking 315  42 good (0.1333333 0.8666667) *\r\n\r\nGráfico de árbol con “poda”:\r\n\r\n\r\nrpart.plot(modArbol0_prune)\r\n\r\n\r\n\r\n\r\nMatriz de confusión árbol con “poda”: respecto al árbol sin podar, la diferencia en precisión es muy pequeña (<0.01), sin embargo, la especificidad se aumenta de 0.3444 a 0.4556 con la “poda”, aunque la sensitividad haya reducido de 0.8762 a 0.8381.\r\n\r\n\r\npredichos_mod0_prune <- predict(object = modArbol0_prune, newdata = dataTest, type = \"class\")\r\nconfusionMatrix(data = predichos_mod0_prune, reference = as.factor(dataTest$class),\r\n                positive = \"good\")\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction bad good\r\n      bad   41   34\r\n      good  49  176\r\n                                         \r\n               Accuracy : 0.7233         \r\n                 95% CI : (0.669, 0.7732)\r\n    No Information Rate : 0.7            \r\n    P-Value [Acc > NIR] : 0.2072         \r\n                                         \r\n                  Kappa : 0.3083         \r\n                                         \r\n Mcnemar's Test P-Value : 0.1244         \r\n                                         \r\n            Sensitivity : 0.8381         \r\n            Specificity : 0.4556         \r\n         Pos Pred Value : 0.7822         \r\n         Neg Pred Value : 0.5467         \r\n             Prevalence : 0.7000         \r\n         Detection Rate : 0.5867         \r\n   Detection Prevalence : 0.7500         \r\n      Balanced Accuracy : 0.6468         \r\n                                         \r\n       'Positive' Class : good           \r\n                                         \r\n\r\nÁrea bajo la curva de árbol con “poda”:\r\n\r\n\r\n# Probabilidades predichas para la clase \"good\"\r\npred0_prune <- as.data.frame(predict(object = modArbol0_prune,\r\n                                     newdata = dataTest, type = \"prob\"))$good\r\n\r\n# AUC\r\nMetrics::auc(actual = target, predicted = pred0_prune)\r\n\r\n\r\n[1] 0.7203175\r\n\r\nCurva ROC:\r\n\r\n\r\n# Ver función myROC() al final en material complementario    \r\nmyROC(predichos = pred0_prune, reales = target)\r\n\r\n\r\n\r\n\r\nTuning con caret\r\nA diferencia de los parámetros que se “aprenden” duarante el entrenamiento del modelo, los hipeparámetros se definen previo al ajuste del mismo.\r\nEl ajuste de hiperparámetros se constituye como parte fundamental de la optimización del modelo.\r\nLa biblioteca caret proporciona un marco de trabajo unificado para entrenar y validar modelos de machine learning. En este caso, con caret podremos ajustar dos de los tres hiperparámetros mencionados anteriormente, el parámetro de complejidad y la profundidad del árbol. Las funciones trainControl() y train de la biblioteca caret facilitan el proceso.\r\ntrainControl(): permite establecer la estrategia de validación, por ejemplo validación cruzada k-fold, validación cruzada repetida, bootstrapping, entre otras. Desde esta misma función también es posible determinar el método de búsqueda de hiperparámetros, que puede ser aleatoria o cuadrícula (grid). En este caso particular utilizo validación cruzada con repeticiones, con k = 5 y 3 repeticiones. El argumento summaryFunction = twoClassSummary permite computar las métricas necesarias (sensitividad y especificidad) para obtener ROC. Busque más ayuda con help(\"trainControl\").\r\ntrain(): ajuste el modelo estableciendo la fórmula habitual en R, el método o algoritmo para entrenar, (lista de algoritmos en caret) los datos, la configuración para el entrenamiento (tcConrol = myControl) y la longitud de hiperparámetros a considerar en el entrenamiento (tuneLenth). Este último argumento dependerá de los hiperparámetros que estén disponibles en caret, aunque también es posible asignarlos manualmente a través de expand.grid(). Utilizar el método igualado a “rpart” permitirá optimizar el parámetro cp y utilizando “rpart2” es posible optimizar la máxima profundidad del árbol. Cuando se declara tuneLength = 5 se informa que el número máximo de profundidades a probar será 5, es decir, que al final existirán 5 resultados diferentes con el mismo algoritmo. Por último, se agrega la métrica que será utilizada para comparar los resultados de la validación cruzada.\r\n\r\nNota: como el procedimiento de validación cruzada implica muestreo aleatorio, es necesario asignar la semilla para garantizar replicabilidad de resultados.\r\n\r\n\r\nmyControl <- trainControl(method = \"repeatedcv\",\r\n                          number = 5,\r\n                          repeats = 3,\r\n                          classProbs = TRUE,  # Permite predecir probabilidades\r\n                          summaryFunction = twoClassSummary) \r\nset.seed(1992)\r\nmodArbol_tune <- train(class ~ .,\r\n                       method = \"rpart2\",\r\n                       data = data,\r\n                       trControl = myControl,\r\n                       tuneLength = 5,\r\n                       metric = \"ROC\")\r\nmodArbol_tune\r\n\r\n\r\nCART \r\n\r\n1000 samples\r\n  20 predictor\r\n   2 classes: 'bad', 'good' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (5 fold, repeated 3 times) \r\nSummary of sample sizes: 800, 800, 800, 800, 800, 800, ... \r\nResampling results across tuning parameters:\r\n\r\n  maxdepth  ROC        Sens       Spec     \r\n   3        0.7028968  0.3011111  0.8885714\r\n   6        0.7138095  0.3244444  0.8880952\r\n  11        0.7211151  0.3988889  0.8642857\r\n  14        0.7213571  0.4055556  0.8623810\r\n  18        0.7211746  0.3911111  0.8671429\r\n\r\nROC was used to select the optimal model using the largest value.\r\nThe final value used for the model was maxdepth = 14.\r\n\r\nSe observa que la mejor profundidad es 14 con la mayor sensitividad aún cuando no tiene la mejor especificidad. A continuación la matriz de confusión en el conjunto de test muestra mejoras en la capacidad de detectar los clasificados como “malos”, ademas la precisión es notablemente superior.\r\n\r\n\r\npredichos_tune <- predict(object = modArbol_tune, newdata = dataTest, type = \"raw\")\r\nconfusionMatrix(data = predichos_tune, reference = as.factor(dataTest$class),\r\n                positive = \"good\")\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction bad good\r\n      bad   52   29\r\n      good  38  181\r\n                                          \r\n               Accuracy : 0.7767          \r\n                 95% CI : (0.7253, 0.8225)\r\n    No Information Rate : 0.7             \r\n    P-Value [Acc > NIR] : 0.001839        \r\n                                          \r\n                  Kappa : 0.4526          \r\n                                          \r\n Mcnemar's Test P-Value : 0.328393        \r\n                                          \r\n            Sensitivity : 0.8619          \r\n            Specificity : 0.5778          \r\n         Pos Pred Value : 0.8265          \r\n         Neg Pred Value : 0.6420          \r\n             Prevalence : 0.7000          \r\n         Detection Rate : 0.6033          \r\n   Detection Prevalence : 0.7300          \r\n      Balanced Accuracy : 0.7198          \r\n                                          \r\n       'Positive' Class : good            \r\n                                          \r\n\r\nÁrea bajo la curva el modelo evidentemente consigue mejores resultados respecto a los ajustados inicialmente, de tal manera que el ajuste de hiperparámetros ha logrado mejorar nuestras predicciones en datos que el modelo aún no ha visto. Posiblemente el hecho de ajustar la máxima profundidad sumado al uso de validación cruzada, permite que el modelo capture de mejor manera las relaciones subyacentes entre características.\r\n\r\n\r\n# Probabilidades predichas para la clase \"good\"\r\npred_tune <- as.data.frame(predict(object = modArbol_tune,\r\n                                   newdata = dataTest, type = \"prob\"))$good\r\n\r\n# AUC\r\nMetrics::auc(actual = target, predicted = pred_tune)\r\n\r\n\r\n[1] 0.7888624\r\n\r\nCurva ROC:\r\n\r\n\r\n# Ver función myROC() al final en material complementario    \r\nmyROC(predichos = pred_tune, reales = target)\r\n\r\n\r\n\r\n\r\nComplementario\r\nFunción plot + caret\r\nLa función plot() tiene un método específico para resultados obtenidos a través de caret, en este caso muestra el gráfico del hiperparámetro de interés, la máxima profundidad del árbol vs la curva ROC en el eje Y, tratando de evidenicar el valor óptimo.\r\n\r\n\r\nplot(modArbol_tune)\r\n\r\n\r\n\r\n\r\nGráfico interactivo con visNetwork\r\nLa biblioteca visNetwork permite crear gráficos interactivos para objetos de la clase rpart. A manera de ejemplo se presenta el gráfico para el árbol de decisión con poda. Recuerde que es interactivo y puede manipularlo con el mouse.\r\n\r\n\r\nlibrary(visNetwork)\r\nvisTree(modArbol0_prune, \r\n        main = \"Árbol con poda\", width = \"100%\",\r\n        height = \"800px\",  edgesFontSize = 14, nodesFontSize = 16,)\r\n\r\n\r\n\r\n{\"x\":{\"nodes\":{\"id\":[1,2,4,5,10,11,22,44,45,23,3],\"label\":[\"checking_status\",\"credit_history\",\"bad\",\"duration\",\"bad\",\"purpose\",\"age\",\"bad\",\"good\",\"good\",\"good\"],\"level\":[1,2,3,3,4,4,5,6,6,5,2],\"color\":[\"#F1B8C2\",\"#DAC49C\",\"#7D91B6\",\"#A9D1A5\",\"#7D91B6\",\"#8AD3D0\",\"#B4C7ED\",\"#7D91B6\",\"#B9828C\",\"#B9828C\",\"#B9828C\"],\"value\":[700,385,51,334,77,257,83,42,41,174,315],\"shape\":[\"dot\",\"dot\",\"square\",\"dot\",\"square\",\"dot\",\"dot\",\"square\",\"square\",\"square\",\"square\"],\"title\":[\"<div style=\\\"text-align:center;\\\">N : <b>100%<\\/b> (700)<br>Complexity : <b>0.055<\\/b><br>bad : <b>30%<\\/b> (210)<br>good : <b>70%<\\/b> (490)<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>55%<\\/b> (385)<br>Complexity : <b>0.055<\\/b><br>bad : <b>43.6%<\\/b> (168)<br>good : <b>56.4%<\\/b> (217)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>7.3%<\\/b> (51)<br>Complexity : <b>0.014<\\/b><br>bad : <b>72.5%<\\/b> (37)<br>good : <b>27.5%<\\/b> (14)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> all paid, no credits/all paid<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>47.7%<\\/b> (334)<br>Complexity : <b>0.055<\\/b><br>bad : <b>39.2%<\\/b> (131)<br>good : <b>60.8%<\\/b> (203)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>11%<\\/b> (77)<br>Complexity : <b>0.017<\\/b><br>bad : <b>61%<\\/b> (47)<br>good : <b>39%<\\/b> (30)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> >= 27.5<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>36.7%<\\/b> (257)<br>Complexity : <b>0.038<\\/b><br>bad : <b>32.7%<\\/b> (84)<br>good : <b>67.3%<\\/b> (173)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>11.9%<\\/b> (83)<br>Complexity : <b>0.038<\\/b><br>bad : <b>49.4%<\\/b> (41)<br>good : <b>50.6%<\\/b> (42)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<br><b> purpose <\\/b> domestic appliance, education, new car, retraining<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>6%<\\/b> (42)<br>Complexity : <b>0.017<\\/b><br>bad : <b>69%<\\/b> (29)<br>good : <b>31%<\\/b> (13)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<br><b> purpose <\\/b> domestic appliance, education, new car, retraining<br><b> age <\\/b> < 35.5<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>5.9%<\\/b> (41)<br>Complexity : <b>0.01<\\/b><br>bad : <b>29.3%<\\/b> (12)<br>good : <b>70.7%<\\/b> (29)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<br><b> purpose <\\/b> domestic appliance, education, new car, retraining<br><b> age <\\/b> >= 35.5<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>24.9%<\\/b> (174)<br>Complexity : <b>0.01<\\/b><br>bad : <b>24.7%<\\/b> (43)<br>good : <b>75.3%<\\/b> (131)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> <0, 0<=X<200<br><b> credit_history <\\/b> critical/other existing credit, delayed previously, existing paid<br><b> duration <\\/b> < 27.5<br><b> purpose <\\/b> business, furniture/equipment, other, radio/tv, repairs, used car<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\",\"<div style=\\\"text-align:center;\\\">N : <b>45%<\\/b> (315)<br>Complexity : <b>0.01<\\/b><br>bad : <b>13.3%<\\/b> (42)<br>good : <b>86.7%<\\/b> (273)<hr class = \\\"rPartvisNetwork\\\">\\n<div class =\\\"showOnMe2\\\"><div style=\\\"text-align:center;\\\"><U style=\\\"color:blue;\\\" class = \\\"classActivePointer\\\">Rules<\\/U><\\/div>\\n<div class=\\\"showMeRpartTTp2\\\" style=\\\"display:none;\\\">\\n<b> checking_status <\\/b> >=200, no checking<\\/script><script type=\\\"text/javascript\\\">$(document).ready(function(){\\n$(\\\".showOnMe2\\\").click(function(){\\n$(\\\".showMeRpartTTp2\\\").toggle();\\n$.sparkline_display_visible();\\n});\\n  });<\\/script><\\/div><\\/div>\\n\\n<\\/div>\"],\"fixed\":[true,true,true,true,true,true,true,true,true,true,true],\"colorClust\":[\"#B9828C\",\"#B9828C\",\"#7D91B6\",\"#B9828C\",\"#7D91B6\",\"#B9828C\",\"#B9828C\",\"#7D91B6\",\"#B9828C\",\"#B9828C\",\"#B9828C\"],\"labelClust\":[\"good\",\"good\",\"bad\",\"good\",\"bad\",\"good\",\"good\",\"bad\",\"good\",\"good\",\"good\"],\"Leaf\":[0,0,1,0,1,0,0,1,1,1,1],\"font.size\":[16,16,16,16,16,16,16,16,16,16,16],\"scaling.min\":[22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5],\"scaling.max\":[22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5,22.5]},\"edges\":{\"id\":[\"edge1\",\"edge2\",\"edge3\",\"edge4\",\"edge5\",\"edge6\",\"edge7\",\"edge8\",\"edge9\",\"edge10\"],\"from\":[1,2,2,5,5,11,22,22,11,1],\"to\":[2,4,5,10,11,22,44,45,23,3],\"label\":[\"<0, 0<=...\",\"all pai...\",\"critica...\",\">= 27.5\",\"< 27.5\",\"domesti...\",\"< 35.5\",\">= 35.5\",\"busines...\",\">=200, ...\"],\"value\":[385,51,334,77,257,83,42,41,174,315],\"title\":[\"<div style=\\\"text-align:center;\\\"><b>checking_status<\\/b><\\/div><div style=\\\"text-align:center;\\\"><0<\\/div><div style=\\\"text-align:center;\\\">0<=X<200<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>credit_history<\\/b><\\/div><div style=\\\"text-align:center;\\\">all paid<\\/div><div style=\\\"text-align:center;\\\">no credits/all paid<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>credit_history<\\/b><\\/div><div style=\\\"text-align:center;\\\">critical/other existing credit<\\/div><div style=\\\"text-align:center;\\\">delayed previously<\\/div><div style=\\\"text-align:center;\\\">existing paid<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>duration<\\/b><\\/div><div style=\\\"text-align:center;\\\">>=27.5<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>duration<\\/b><\\/div><div style=\\\"text-align:center;\\\"><27.5<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>purpose<\\/b><\\/div><div style=\\\"text-align:center;\\\">domestic appliance<\\/div><div style=\\\"text-align:center;\\\">education<\\/div><div style=\\\"text-align:center;\\\">new car<\\/div><div style=\\\"text-align:center;\\\">retraining<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>age<\\/b><\\/div><div style=\\\"text-align:center;\\\"><35.5<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>age<\\/b><\\/div><div style=\\\"text-align:center;\\\">>=35.5<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>purpose<\\/b><\\/div><div style=\\\"text-align:center;\\\">business<\\/div><div style=\\\"text-align:center;\\\">furniture/equipment<\\/div><div style=\\\"text-align:center;\\\">other<\\/div><div style=\\\"text-align:center;\\\">radio/tv<\\/div><div style=\\\"text-align:center;\\\">repairs<\\/div><div style=\\\"text-align:center;\\\">used car<\\/div>\",\"<div style=\\\"text-align:center;\\\"><b>checking_status<\\/b><\\/div><div style=\\\"text-align:center;\\\">>=200<\\/div><div style=\\\"text-align:center;\\\">no checking<\\/div>\"],\"color\":[\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\",\"#8181F7\"],\"font.size\":[14,14,14,14,14,14,14,14,14,14],\"font.align\":[\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\",\"horizontal\"],\"smooth.enabled\":[true,true,true,true,true,true,true,true,true,true],\"smooth.type\":[\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\",\"cubicBezier\"],\"smooth.roundness\":[0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5]},\"nodesToDataframe\":true,\"edgesToDataframe\":true,\"options\":{\"width\":\"100%\",\"height\":\"100%\",\"nodes\":{\"shape\":\"dot\"},\"manipulation\":{\"enabled\":false},\"layout\":{\"hierarchical\":{\"enabled\":true,\"direction\":\"UD\"}},\"interaction\":{\"dragNodes\":false,\"selectConnectedEdges\":false,\"tooltipDelay\":500},\"edges\":{\"scaling\":{\"label\":{\"enabled\":false}}}},\"groups\":null,\"width\":\"100%\",\"height\":\"800px\",\"idselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"useLabels\":true,\"main\":\"Select by id\"},\"byselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"multiple\":false,\"hideColor\":\"rgba(200,200,200,0.5)\",\"highlight\":false},\"main\":{\"text\":\"Árbol con poda\",\"style\":\"font-family:Georgia, Times New Roman, Times, serif;font-weight:bold;font-size:20px;text-align:center;\"},\"submain\":{\"text\":\"\",\"style\":\"font-family:Georgia, Times New Roman, Times, serif;font-size:12px;text-align:center;\"},\"footer\":{\"text\":\"\",\"style\":\"font-family:Georgia, Times New Roman, Times, serif;font-size:12px;text-align:center;\"},\"background\":\"rgba(0, 0, 0, 0)\",\"highlight\":{\"enabled\":true,\"hoverNearest\":false,\"degree\":{\"from\":50000,\"to\":0},\"algorithm\":\"hierarchical\",\"hideColor\":\"rgba(200,200,200,0.5)\",\"labelOnly\":true},\"collapse\":{\"enabled\":true,\"fit\":true,\"resetHighlight\":true,\"clusterOptions\":{\"fixed\":true,\"physics\":false},\"keepCoord\":true,\"labelSuffix\":\"(cluster)\"},\"tooltipStay\":300,\"tooltipStyle\":\"position: fixed;visibility:hidden;padding: 5px;\\n                      white-space: nowrap;\\n                      font-family: cursive;font-size:12px;font-color:purple;background-color: #E6E6E6;\\n                      border-radius: 15px;\",\"OnceEvents\":{\"stabilized\":\"function() { \\n        this.setOptions({layout:{hierarchical:false}, physics:{solver:'barnesHut', enabled:true, stabilization : false}, nodes : {physics : false, fixed : true}});\\n    }\"},\"legend\":{\"width\":0.1,\"useGroups\":false,\"position\":\"left\",\"ncol\":1,\"stepX\":100,\"stepY\":100,\"zoom\":true,\"nodes\":{\"label\":[\"age\",\"checking_status\",\"credit_history\",\"duration\",\"purpose\",\"bad\",\"good\"],\"color\":[\"#B4C7ED\",\"#F1B8C2\",\"#DAC49C\",\"#A9D1A5\",\"#8AD3D0\",\"#7D91B6\",\"#B9828C\"],\"shape\":[\"dot\",\"dot\",\"dot\",\"dot\",\"dot\",\"square\",\"square\"],\"size\":[22,22,22,22,22,22,22],\"Leaf\":[0,0,0,0,0,1,1],\"font.size\":[16,16,16,16,16,16,16],\"id\":[10000,10001,10002,10003,10004,10005,10006]},\"nodesToDataframe\":true},\"tree\":{\"updateShape\":true,\"shapeVar\":\"dot\",\"shapeY\":\"square\",\"colorVar\":{\"variable\":[\"checking_status\",\"credit_history\",\"duration\",\"purpose\",\"age\"],\"color\":[\"#F1B8C2\",\"#DAC49C\",\"#A9D1A5\",\"#8AD3D0\",\"#B4C7ED\"]},\"colorY\":{\"colorY\":{\"modality\":[\"bad\",\"good\"],\"color\":[\"#7D91B6\",\"#B9828C\"]},\"vardecidedClust\":[\"good\",\"good\",\"bad\",\"good\",\"bad\",\"good\",\"good\",\"bad\",\"good\",\"good\",\"good\"]}},\"export\":{\"type\":\"png\",\"css\":\"float:right;-webkit-border-radius: 10;\\n                  -moz-border-radius: 10;\\n                  border-radius: 10px;\\n                  font-family: Arial;\\n                  color: #ffffff;\\n                  font-size: 12px;\\n                  background: #090a0a;\\n                  padding: 4px 8px 4px 4px;\\n                  text-decoration: none;\",\"background\":\"#fff\",\"name\":\"network.png\",\"label\":\"Export as png\"}},\"evals\":[\"OnceEvents.stabilized\"],\"jsHooks\":[]}\r\nFunción myROC()\r\nEs necesario tener cargadas las bibliotecaS dplyr, ggplot2, hrbrthemes, Metrics y pROC para ejecutar la función.\r\n\r\n\r\nmyROC <- function(predichos, reales) {\r\n  suppressMessages(suppressWarnings(library(dplyr)))\r\n  suppressMessages(suppressWarnings(library(ggplot2)))\r\n  suppressMessages(suppressWarnings(library(pROC)))\r\n  suppressMessages(suppressWarnings(library(Metrics)))\r\n  x = roc(reales, predichos)\r\n  df = data_frame(TPR = x$sensitivities,\r\n                  FPR = 1 - x$specificities)\r\n  gg = df %>%\r\n    ggplot(aes(x = FPR, ymin = 0, ymax = TPR)) +\r\n    geom_polygon(aes(y = TPR), fill = \"#5A5156\", alpha = 0.7) +\r\n    geom_path(aes(y = TPR), col = \"#F6222E\", size = 1.3) +\r\n    geom_abline(\r\n      intercept = 0,\r\n      slope = 1,\r\n      color = \"gray37\",\r\n      size = 1,\r\n      linetype = \"dashed\"\r\n    ) +\r\n    theme_ipsum() +\r\n    coord_equal() +\r\n    labs(\r\n      x = \"FPR (1 - Especificidad)\",\r\n      y = \"TPR (Sensitividad)\",\r\n      title = paste0(\"Curva ROC\"),\r\n      subtitle = paste0(\r\n        \"Valor AUC: \",\r\n        Metrics::auc(actual = reales,\r\n                     predicted = predichos) %>% round(4)\r\n      )\r\n    )\r\n  return(gg)\r\n}\r\n\r\n\r\n\r\nRecursos de información\r\nAn Introduction to Statistical Learning with Applications in R.\r\nTree-Based Models.\r\nÁrboles de predicción - Joaquín A. Rodrigo.\r\nCurso DataCamp - Tree-Based Models in R.\r\n\r\n\r\n\r\n",
    "preview": "posts/TreeD_R/img1.png",
    "last_modified": "2021-04-02T11:47:01-05:00",
    "input_file": {}
  },
  {
    "path": "posts/BERT_Text/",
    "title": "BERT con R y Python",
    "description": "Ejemplo de uso de TensorFlow con R y Python para procesamiento de texto con algoritmo BERT de Google.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-06-04",
    "categories": [
      "R",
      "Py",
      "TensorFlow",
      "ML",
      "Text Mining"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/BERT_Text/bert2.png",
    "last_modified": "2020-06-04T17:03:54-05:00",
    "input_file": {}
  },
  {
    "path": "posts/TextMining_R/",
    "title": "Minería de texto con R",
    "description": "Algortimos de machine learning para clasificación de texto.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-04-29",
    "categories": [
      "R",
      "Text Mining"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/TextMining_R/img2.png",
    "last_modified": "2020-04-29T08:56:48-05:00",
    "input_file": {}
  },
  {
    "path": "posts/GBM_R/",
    "title": "Gradient Boosting con R",
    "description": "Ejemplo de uso de algoritmo Gradient Boosting con R en machine learning supervisado para clasificación.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-04-26",
    "categories": [
      "R",
      "GBM"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/GBM_R/img1.png",
    "last_modified": "2020-04-26T12:34:08-05:00",
    "input_file": {}
  },
  {
    "path": "posts/PyCaret/",
    "title": "PyCaret",
    "description": "Algoritmos de machine learning con la nueva (lanzamiento en marzo de 2020) herramienta PyCaret.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-04-24",
    "categories": [
      "Py",
      "ML"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/PyCaret/img3.png",
    "last_modified": "2020-04-24T13:08:39-05:00",
    "input_file": {}
  },
  {
    "path": "posts/Tidymodels_R/",
    "title": "Tidymodels en R: Clasificación",
    "description": "Algoritmos de machine learning supervisado con tidymodels y R. Entranamiento de modelos en problema de clasificación. Replicación de estudio publicado en Plos One.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-04-24",
    "categories": [
      "R",
      "Tidymodels",
      "ML"
    ],
    "contents": "\r\nGeneralidades\r\nArtículo Plos One\r\n",
    "preview": "posts/Tidymodels_R/img1.jpg",
    "last_modified": "2020-05-02T22:00:07-05:00",
    "input_file": {}
  },
  {
    "path": "posts/catBoost_r/",
    "title": "CatBoost en R y Python",
    "description": "Algortimo CatBoost con R y Python. Ejemplo en problemas de regresión y clasificación.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-04-19",
    "categories": [
      "R",
      "xgboost",
      "Gradient Boosting"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/catBoost_r/img2.png",
    "last_modified": "2020-04-20T00:35:39-05:00",
    "input_file": {}
  },
  {
    "path": "posts/LGBM_Py/",
    "title": "LightGBM con R",
    "description": "Ejemplo aplicado del algoritmo LightGBM (Microsoft) con R, en problemas de clasificación y regresión.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-04-19",
    "categories": [
      "R",
      "lightgbm",
      "Gradient Boosting"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/LGBM_Py/img1.png",
    "last_modified": "2021-02-05T18:55:46-05:00",
    "input_file": {}
  },
  {
    "path": "posts/caret_R/",
    "title": "ML con caret en R (1)",
    "description": "Algoritmos de machine learning con caret y R. Entrenamiento de modelos random forest y support vector machine en problemas de clasificación supervisada.",
    "author": [
      {
        "name": "Edimer David Jaramillo (Sidereus)",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-03-23",
    "categories": [
      "R",
      "caret",
      "ML"
    ],
    "contents": "\r\n\r\nContents\r\nDatos\r\nProblema\r\nImportando datos\r\nExploración\r\nVariable respuesta\r\nDistribuciones\r\nCorrelaciones\r\n\r\nTrain y Test\r\nModelos\r\nRandom Forest\r\nAlgoritmo\r\nDesempeño\r\n\r\nSVM\r\nAlgoritmo\r\nDesempeño\r\n\r\nComparación de modelos\r\n\r\n\r\nDatos\r\nFuente: predicción de estrellas púlsar.\r\n¿Qué es un púlsar?\r\nProblema\r\nDescripción: a través de emisiones de radio detectables en nuestro planeta, los científicos perfilan los púlsares en función de múltiples métricas provenientes del análisis de señales; el ruido causado por interferencia de radiofrecuencia dificulta la labor de los investigadores. Se propone generar un sistema automático que proporcione alta precisión para detectar estrellas púlsar. (ver más información)\r\nTipo de aprendizaje: Aprendizaje Supervisado - Clasificación Binaria.\r\nAlgoritmos:\r\nRandom Forest\r\nSupport Vector Machine-SVM\r\n\r\nImportando datos\r\n\r\n\r\n# Cargando biblioteca data.table\r\nlibrary(data.table)\r\n\r\n# Nombres de variables\r\nnombres <- c(\"media_pefil\", \"de_perfil\", \"curtosis_perfil\", \"asimet_perfil\", \"media_dmsnr\",\r\n             \"de_dmsnr\", \"curtosis_dmsnr\", \"asimet_dmsnr\", \"pulsar\")\r\n\r\ndf_pulsar <- fread(\"data/pulsar_stars.csv\", sep = \",\", col.names = nombres,\r\n                   colClasses = c(rep(\"numeric\", 8), \"factor\"))\r\nhead(df_pulsar)\r\n\r\n\r\n   media_pefil de_perfil curtosis_perfil asimet_perfil media_dmsnr\r\n1:   140.56250  55.68378     -0.23457141    -0.6996484    3.199833\r\n2:   102.50781  58.88243      0.46531815    -0.5150879    1.677258\r\n3:   103.01562  39.34165      0.32332837     1.0511644    3.121237\r\n4:   136.75000  57.17845     -0.06841464    -0.6362384    3.642977\r\n5:    88.72656  40.67223      0.60086608     1.1234917    1.178930\r\n6:    93.57031  46.69811      0.53190485     0.4167211    1.636288\r\n   de_dmsnr curtosis_dmsnr asimet_dmsnr pulsar\r\n1: 19.11043       7.975532     74.24222      0\r\n2: 14.86015      10.576487    127.39358      0\r\n3: 21.74467       7.735822     63.17191      0\r\n4: 20.95928       6.896499     53.59366      0\r\n5: 11.46872      14.269573    252.56731      0\r\n6: 14.54507      10.621748    131.39400      0\r\n\r\nExploración\r\nDefiniento tema de ggplot2 para gráficos:\r\n\r\n\r\n# Cargando biblioteca tidyverse\r\nlibrary(tidyverse)\r\n\r\n# Tema personalizado para gráficos\r\nmi_temagg <- theme_light() +\r\n  theme(axis.text.x = element_text(color = \"black\"),\r\n        axis.text.y = element_text(color = \"black\"),\r\n        strip.background = element_rect(fill = \"gray5\"),\r\n        strip.text = element_text(color = \"white\", size = 12))\r\n\r\n\r\n\r\nVariable respuesta\r\n\r\n\r\ndf_pulsar %>% group_by(pulsar) %>% count() %>% \r\n  ggplot(data = ., aes(x = pulsar, y = n)) +\r\n  geom_col(color = \"black\", fill = \"#033660\") +\r\n  geom_label(aes(label = n)) +\r\n  labs(x = \"¿Púlsar?\", title = \"Distribución de variable respuesta\",\r\n       subtitle = \"0=No\\n1=Sí\") +\r\n  mi_temagg\r\n\r\n\r\n\r\n\r\nDistribuciones\r\n\r\n\r\ndf_pulsar %>% \r\n  gather(key = \"variable\", value = \"valor\", -pulsar) %>% \r\n  ggplot(data = ., aes(x = valor, fill = pulsar)) +\r\n  facet_wrap(~variable, scales = \"free\", ncol = 4) +\r\n  geom_density(alpha = 0.9) +\r\n  scale_x_log10() +\r\n  labs(x = \"\", y = \"Densidad\", title = \"Escala logarítmica\",\r\n       fill = \"¿Púlsar?\") +\r\n  scale_fill_manual(values = c(\"#790222\", \"#033660\")) +\r\n  mi_temagg\r\n\r\n\r\n\r\n\r\nCorrelaciones\r\n\r\n\r\n# Cargando biblioteca corrplot\r\nlibrary(corrplot)\r\n\r\ndf_pulsar %>% mutate_if(is.numeric, scale)  %>% select_if(is.numeric) %>%\r\n  cor(method = \"spearman\") %>% \r\n  corrplot(method = \"pie\", type = \"upper\", order = \"hclust\", diag = FALSE,\r\n           tl.srt = 35, tl.col = \"black\", tl.cex = 1)\r\n\r\n\r\n\r\n\r\nTrain y Test\r\nLa partición se hace 70 y 30%, para entrenamiento (df_train) y prueba (df_test), respectivamente.\r\nEl argumento list = FALSE en la función createDataPartition, permite que el objeto sea devuelto en forma de vector.\r\nDocumentación de biblioteca caret.\r\n\r\n\r\n# Cargando biblioteca caret\r\nlibrary(caret)\r\n\r\n# Semilla para reproducir resutlados\r\nset.seed(073)\r\n\r\n# Particiones\r\nidx <- createDataPartition(y = df_pulsar$pulsar, times = 1, p = 0.7, list = FALSE)\r\ndf_train <- df_pulsar[idx, ]\r\ndf_test <- df_pulsar[-idx, ]\r\n\r\n\r\n\r\nProporción de la variable respuesta en train y test:\r\n\r\n\r\nggpubr::ggarrange(\r\n  df_train %>% group_by(pulsar) %>% count() %>% ungroup() %>% mutate(prop = n/sum(n)) %>% \r\n  ggplot(data = ., aes(x = pulsar, y = prop)) +\r\n  geom_col(color = \"black\", fill = \"#033660\") +\r\n  geom_label(aes(label = round(prop, digits = 2))) +\r\n  labs(x = \"¿Púlsar?\", title = \"Distribución en train\",\r\n       subtitle = \"0=No\\n1=Sí\") +\r\n  mi_temagg,\r\n\r\n  df_test %>% group_by(pulsar) %>% count() %>% ungroup() %>% mutate(prop = n/sum(n)) %>% \r\n  ggplot(data = ., aes(x = pulsar, y = prop)) +\r\n  geom_col(color = \"black\", fill = \"#033660\") +\r\n  geom_label(aes(label = round(prop, digits = 2))) +\r\n  labs(x = \"¿Púlsar?\", title = \"Distribución en test\",\r\n       subtitle = \"0=No\\n1=Sí\") +\r\n  mi_temagg,\r\n  \r\n  ncol = 2\r\n)\r\n\r\n\r\n\r\n\r\nModelos\r\nSe utiliza el método ranger.\r\nLos argumentos se han dejado como están por defecto.\r\nReferencia de algoritmo random forest con caret.\r\nEn este caso particular se usa el método ranger que permite ajustar tres hiperparámetros:\r\nmtry: número de predictores seleccionados.\r\nsplitrule: criterio de división. En problemas de clasificación se suele utilizar Gini, aunque hay más disponibles. Ver documentación de ranger.\r\nmin.node.size: número mínimo de observaciones en cada nodo. Por defecto para problemas de clasificación es 1.\r\n\r\nRandom Forest\r\nAlgoritmo\r\n\r\n\r\n# Algoritmo de random forest\r\nmodelo_rf <- train(pulsar ~ ., data = df_train, method = \"ranger\")\r\n\r\n# Guardando modelo\r\nsaveRDS(object = modelo_rf, file = \"models_fit/RandomForest.rds\")\r\n\r\n\r\n\r\nResultados:\r\n\r\n\r\n# Cargando modelo\r\nmod_rf <- readRDS(\"models_fit/RandomForest.rds\")\r\n\r\n# Resultados del modelo\r\nmod_rf\r\n\r\n\r\nRandom Forest \r\n\r\n12530 samples\r\n    8 predictor\r\n    2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Bootstrapped (25 reps) \r\nSummary of sample sizes: 12530, 12530, 12530, 12530, 12530, 12530, ... \r\nResampling results across tuning parameters:\r\n\r\n  mtry  splitrule   Accuracy   Kappa    \r\n  2     gini        0.9801226  0.8758954\r\n  2     extratrees  0.9794474  0.8705685\r\n  5     gini        0.9801169  0.8762727\r\n  5     extratrees  0.9803843  0.8777407\r\n  8     gini        0.9795793  0.8731006\r\n  8     extratrees  0.9804887  0.8788098\r\n\r\nTuning parameter 'min.node.size' was held constant at a value of 1\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final values used for the model were mtry = 8, splitrule\r\n = extratrees and min.node.size = 1.\r\n\r\nDesempeño\r\nMatriz de confusión en test:\r\n\r\n\r\n# Predicciones en nuevos datos\r\npredict_rf <- predict(object = mod_rf, newdata = df_test)\r\n\r\n# Matriz de confución\r\nconfusionMatrix(predict_rf, df_test$pulsar, positive = \"1\")\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction    0    1\r\n         0 4840   84\r\n         1   37  407\r\n                                          \r\n               Accuracy : 0.9775          \r\n                 95% CI : (0.9731, 0.9813)\r\n    No Information Rate : 0.9085          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8583          \r\n                                          \r\n Mcnemar's Test P-Value : 2.892e-05       \r\n                                          \r\n            Sensitivity : 0.82892         \r\n            Specificity : 0.99241         \r\n         Pos Pred Value : 0.91667         \r\n         Neg Pred Value : 0.98294         \r\n             Prevalence : 0.09147         \r\n         Detection Rate : 0.07582         \r\n   Detection Prevalence : 0.08271         \r\n      Balanced Accuracy : 0.91067         \r\n                                          \r\n       'Positive' Class : 1               \r\n                                          \r\n\r\nSVM\r\nSe utiliza el método svmRadial que está contenido en la biblioteca kernlab.\r\nLa configuración está por defecto.\r\nEste algoritmo permite ajustar hiperparámetros sigma y C (costo).\r\nDocumentación kernlab.\r\nAlgoritmo\r\n\r\n\r\n# Algoritmo\r\nmodelo_svmR <- train(pulsar ~ ., data = df_train, method = \"svmRadial\")\r\n\r\n# Guardando modelo\r\nsaveRDS(object = modelo_svmR, file = \"models_fit/SVM_Radial.rds\")\r\n\r\n\r\n\r\nResultados:\r\n\r\n\r\n# Cargando modelo\r\nmod_svmR <- readRDS(\"models_fit/SVM_Radial.rds\")\r\n\r\n# Resultados del modelo\r\nmod_svmR\r\n\r\n\r\nSupport Vector Machines with Radial Basis Function Kernel \r\n\r\n12530 samples\r\n    8 predictor\r\n    2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Bootstrapped (25 reps) \r\nSummary of sample sizes: 12530, 12530, 12530, 12530, 12530, 12530, ... \r\nResampling results across tuning parameters:\r\n\r\n  C     Accuracy   Kappa    \r\n  0.25  0.9785764  0.8629191\r\n  0.50  0.9785329  0.8635606\r\n  1.00  0.9787235  0.8654589\r\n\r\nTuning parameter 'sigma' was held constant at a value of 0.4893064\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final values used for the model were sigma = 0.4893064 and C = 1.\r\n\r\nDesempeño\r\n\r\n\r\npredict_svmR <- predict(object = mod_svmR, newdata = df_test)\r\nconfusionMatrix(predict_svmR, df_test$pulsar, positive = \"1\")\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction    0    1\r\n         0 4852   95\r\n         1   25  396\r\n                                          \r\n               Accuracy : 0.9776          \r\n                 95% CI : (0.9733, 0.9814)\r\n    No Information Rate : 0.9085          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8563          \r\n                                          \r\n Mcnemar's Test P-Value : 2.999e-10       \r\n                                          \r\n            Sensitivity : 0.80652         \r\n            Specificity : 0.99487         \r\n         Pos Pred Value : 0.94062         \r\n         Neg Pred Value : 0.98080         \r\n             Prevalence : 0.09147         \r\n         Detection Rate : 0.07377         \r\n   Detection Prevalence : 0.07843         \r\n      Balanced Accuracy : 0.90070         \r\n                                          \r\n       'Positive' Class : 1               \r\n                                          \r\n\r\nComparación de modelos\r\n\r\n\r\nmod_svmR$resample %>% \r\n  select(-Resample) %>% \r\n  mutate(Modelo = \"SVM\") %>% \r\n  bind_rows(mod_rf$resample) %>% \r\n  select(-Resample) %>% \r\n  replace_na(list(Modelo = \"Random Forest\")) %>% \r\n  gather(key = \"Medida\", value = \"Valor\", -Modelo) %>% \r\n  ggplot(data = ., aes(x = Modelo, y = Valor, fill = Modelo)) +\r\n  facet_wrap(~Medida, scales = \"free\", ncol = 2) +\r\n  geom_violin(alpha = 0.9) +\r\n  stat_summary(fun = mean, geom = \"point\", pch = 19) +\r\n  labs(y = \"\", title = \"Comparación de modelos\",\r\n       subtitle = \"Predicción de estrellas púlsar\") +\r\n  scale_fill_manual(values =  c(\"#790222\", \"#033660\")) +\r\n  mi_temagg +\r\n  theme(legend.position = \"none\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/caret_R/img1.png",
    "last_modified": "2021-04-02T11:47:43-05:00",
    "input_file": {}
  },
  {
    "path": "posts/ELearning_R/",
    "title": "Ensemble Learning con R",
    "description": "Ejemplo de uso de meta-clasficador con métodos de ensemble learning en R.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "Tree Decision"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/ELearning_R/img1.png",
    "last_modified": "2020-02-11T15:46:20-05:00",
    "input_file": {}
  },
  {
    "path": "posts/GAMs_R/",
    "title": "Modelos GAM con R",
    "description": "Ejemplo de aplicación de modelos aditivos generalizados (GAM) mediante la biblioteca mgcv y mgcViz. Ejemplo con variables que se distribuyen de forma binomial y poisson.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "mgcv",
      "mgcViz",
      "GAM"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/GAMs_R/img1.png",
    "last_modified": "2020-01-30T13:36:51-05:00",
    "input_file": {}
  },
  {
    "path": "posts/H2o_R/",
    "title": "Machine Learning con H2o + R",
    "description": "Ejemplo de uso de H2o con R para machine learning. Ajuste de modelos de series temporales (forecasting), random forest, regresión logística y clustering con k-means.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "H2o",
      "ML"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/H2o_R/img1.png",
    "last_modified": "2020-01-30T13:49:05-05:00",
    "input_file": {}
  },
  {
    "path": "posts/Inferencia_R/",
    "title": "Inferencia con R",
    "description": "Estadística inferencial con R. Validación de supuestos de normalidad, homocedasticidad e independencia. Aplicación de métodos paramétricos y no paramétricos. Pruebas t-student, análisis de varianza, prueba chi-cuadrado.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "Inferencia"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/Inferencia_R/img1.png",
    "last_modified": "2020-01-30T13:50:32-05:00",
    "input_file": {}
  },
  {
    "path": "posts/Keras_R/",
    "title": "Keras con R",
    "description": "Ejemplo de uso de Keras con R para machine learning supervisado. Ajuste de modelos de deep learning con aplicaciones en problemas de regresión y clasificación.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "Keras",
      "ML"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/Keras_R/img1.png",
    "last_modified": "2020-01-30T13:50:52-05:00",
    "input_file": {}
  },
  {
    "path": "posts/mlr3_R/",
    "title": "Machine Learning con mlr3 en R",
    "description": "Machine learning con la biblioteca mlr3. Ejemplo de uso en problemas de aprendizaje supervisado (clasificación y regresión) y no supervisado (reducción de dimensionalidad, clustering).",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "mlr3"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/mlr3_R/img1.png",
    "last_modified": "2020-04-20T00:21:06-05:00",
    "input_file": {}
  },
  {
    "path": "posts/RandomF_R_Py/",
    "title": "Random Forest con R y Python",
    "description": "Ejemplo de uso de bosques aleatorios con R y Python en machine learning supervisado para clasificación y regresión. Comparación de modelos ajustados con ambos lenguajes de programación sobre los mismos conjuntos de datos.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "Py",
      "Random Forest"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/RandomF_R_Py/img1.png",
    "last_modified": "2020-02-03T07:33:00-05:00",
    "input_file": {}
  },
  {
    "path": "posts/Regression_R/",
    "title": "Modelos de Regresión con R",
    "description": "Ejemplo de usos de modelos de regresión lineal simple, múltiple, regresión polinómica, splines y modelos aditivos generalizados (GAM) con R.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "Regression",
      "ML"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/Regression_R/img1.png",
    "last_modified": "2020-01-30T15:21:00-05:00",
    "input_file": {}
  },
  {
    "path": "posts/SDM_R/",
    "title": "Distribución de Especies con R",
    "description": "Aplicación de algoritmos de machine learning en modelos de distribución de especies  (SDM - Species Distribution Models). Caso de uso en  modelamiento de nicho ecológico de Bothrops atrox (serpiente Mapana X) en Colombia.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "SVM"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/SDM_R/img1.png",
    "last_modified": "2020-02-07T13:46:00-05:00",
    "input_file": {}
  },
  {
    "path": "posts/SVM_R/",
    "title": "Support Vector Machine con R",
    "description": "Ejemplo de uso con máquinas de soporte vectorial en R para clasificación y regresión. Utilización de bibliotecas para entrenamiento y visualización de modelos.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "SVM"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/SVM_R/img1.png",
    "last_modified": "2020-02-03T07:44:01-05:00",
    "input_file": {}
  },
  {
    "path": "posts/TensorFlow_R/",
    "title": "TensorFlow con R",
    "description": "Ejemplo de uso de TensorFlow con R para machine learning supervisado. Aplicación en problemas de regresión (regresión lineal simple) y clasificación (regresión logística).",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "TensorFlow",
      "ML"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/TensorFlow_R/img1.png",
    "last_modified": "2020-01-30T13:52:18-05:00",
    "input_file": {}
  },
  {
    "path": "posts/TimesSeries_R/",
    "title": "Series Temporales con R",
    "description": "Comparación de modelos de series de tiempo para forecasting. Rendimiento de redes neuronales profundas (deep learning) recurrentes versus métodos clásicos en análisis de series temporales.",
    "author": [
      {
        "name": "Edimer David Jaramillo",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-21",
    "categories": [
      "R",
      "Series Temporales"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/TimesSeries_R/img1.png",
    "last_modified": "2020-01-30T15:26:27-05:00",
    "input_file": {}
  },
  {
    "path": "posts/py_r_1/",
    "title": "R + Python: I",
    "description": "Utilizando python desde R con la biblioteca reticulate. Elementos básicos de python para operaciones numéricas comunes, visualización y ejemplo corto con scikit-learn.",
    "author": [
      {
        "name": "Edimer David Jaramillo (Sidereus)",
        "url": "https://edimer.github.io/"
      }
    ],
    "date": "2020-01-20",
    "categories": [
      "R",
      "Py"
    ],
    "contents": "\r\n\r\nContents\r\nRequisitos previos\r\nBiblioteca Reticulate\r\nImportando módulos de python\r\nImportando numpy\r\nImportando os\r\n\r\nUsando python\r\nFunción de python llamada por R\r\nUsando numpy\r\nGráfico con matplotlib\r\nAyudas\r\nObjetos\r\nTupla desde R\r\nDiccionario desde R\r\nTupla en python\r\nTipos de objetos en ambos lenguajes\r\n\r\nÍndices\r\nInstalando un módulo de python desde R\r\nInstalando pandas\r\nImportando pandas y leyendo archivo .csv\r\nImportando tensorflow desde python\r\n\r\nVisualizando datos con matplotlib\r\nEjemplo 1\r\nEjemplo 2\r\nEjemplo 3\r\n\r\nModelo con scikit-learn\r\nImportando módulos de python\r\nCargando datos\r\nSelección de características\r\nTrain - Test\r\nConstruyendo Modelo\r\nEvaluación del modelo\r\n\r\n\r\nRequisitos previos\r\nTener instalado Python\r\nRecomendable instalar Anaconda Navigator\r\nInstalar la biblioteca reticulate desde R.\r\nBiblioteca Reticulate\r\n\r\n\r\n\r\n\r\nlibrary(reticulate)\r\n\r\n\r\n\r\nImportando módulos de python\r\nImportando numpy\r\n\r\n\r\nnp <- import(\"numpy\")\r\nnp$argmin(c(2, 1, 3))\r\n\r\n\r\n[1] 1\r\n\r\nEn esta salida se muestra cómo aplicar la función arcgmin de python sobre un vector de R. Devuelve la posición (índice) donde se encuentra el valor mínimo del vector dado.\r\nEs posible acceder a todas las funciones de numpy desde el objeto np con el símbolo dólar $.\r\n\r\n\r\nImportando os\r\n\r\n\r\nos <- import(\"os\")\r\nos$getcwd()\r\n\r\n\r\n[1] \"D:\\\\DocumentosEdimer\\\\Github\\\\web-edimer.github.io\\\\_posts\\\\py_r_1\"\r\n\r\nUsando python\r\n\r\nimport numpy as np\r\nnp.argmax(np.array([1, 4, 10]))\r\n2\r\n\r\nFunción de python llamada por R\r\nDeclarando la función en python:\r\n\r\ndef add(x, y):\r\n  return x + y\r\n  \r\nadd(2, 2)  \r\n4\r\n\r\nLlamando la función add() desde R\r\n\r\n\r\npy$add(2, 2)\r\n\r\n\r\n[1] 4\r\n\r\nUsando numpy\r\n\r\nnp.arange(0, 5)\r\narray([0, 1, 2, 3, 4])\r\n\r\n\r\nnp.arange(0, 10, 2)\r\narray([0, 2, 4, 6, 8])\r\n\r\n\r\nnp.ones((2, 2))\r\narray([[1., 1.],\r\n       [1., 1.]])\r\n\r\nSimulando 100 valores aleatorios de la distribución normal, con media 2 y varianza 3:.\r\n\r\nnp.random.seed(1)\r\nvalores = np.random.normal(loc = 2, scale = 3, size = 100)\r\nvalores\r\narray([ 6.87303609,  0.16473076,  0.41548474, -1.21890587,  4.59622289,\r\n       -4.90461609,  7.23443529, -0.2836207 ,  2.95711729,  1.25188887,\r\n        6.38632381, -4.18042213,  1.03274839,  0.84783694,  5.40130833,\r\n       -1.2996738 ,  1.48271538, -0.63357525,  2.12664124,  3.74844564,\r\n       -1.30185753,  5.43417113,  4.70477216,  3.50748302,  4.70256785,\r\n       -0.05118358,  1.63132932, -0.8073083 ,  1.19633576,  3.5910664 ,\r\n       -0.07498226,  0.80973942, -0.0615181 , -0.53561692, -0.01373839,\r\n        1.9620062 , -1.35193105,  2.70324709,  6.97940653,  4.22613248,\r\n        1.42449334, -0.66288689, -0.24147488,  7.0773638 ,  2.15242326,\r\n        0.08901306,  2.57274645,  8.30076541,  2.36047686,  3.85160933,\r\n        2.90051096,  0.94325046, -1.42755459,  0.95197183,  1.3733173 ,\r\n        3.75986957,  4.51695024,  4.79330624,  2.85676198,  4.65542349,\r\n       -0.26319382,  5.75860447,  3.53878946,  1.10572149,  3.46555444,\r\n        1.77328486,  5.39488816,  6.55945045,  8.55672622, -2.18948901,\r\n       -2.33234142,  0.48660241,  2.48011121,  4.62850676,  2.94690484,\r\n       -4.06660365,  1.08138796,  4.48392393,  2.69028421,  4.28603354,\r\n        1.33301557,  1.39772579,  2.55968417,  3.23015494,  2.59489916,\r\n        2.35702594, -0.01198686,  3.13269136,  2.36546381,  5.38845172,\r\n        5.59675364,  2.55546925,  0.87414515,  0.08380878,  3.27048306,\r\n        2.23202021,  0.96843897,  2.13079057,  0.13999747,  4.0940961 ])\r\n\r\nGráfico con matplotlib\r\n\r\nimport matplotlib\r\nimport matplotlib.pyplot as plt\r\n\r\nfig, g1 = plt.subplots()\r\ng1 = g1.hist(valores, bins = 30)\r\ng1 = plt.grid()\r\ng1\r\n\r\n\r\n\r\nAyudas\r\n\r\n\r\nos <- import(\"os\")\r\npy_help(os$chdir)\r\n\r\n\r\n\r\nEn el editor de texto aparecerá el siguiente texto:\r\n\r\n\r\nObjetos\r\nTupla desde R\r\nCreando una tupla y obteniendo su clase:\r\n\r\n\r\ntupla1 <- tuple(c(1, 2, 3, \"A\"))\r\ntupla1\r\n\r\n\r\n(['1', '2', '3', 'A'],)\r\n\r\n\r\n# Clase en python\r\nclass(tupla1)\r\n\r\n\r\n[1] \"python.builtin.tuple\"  \"python.builtin.object\"\r\n\r\nCoercionar el objeto tupla1 de clase tuple en python directamente a R:\r\n\r\n\r\ntupla1_r <- py_to_r(tupla1)\r\ntupla1_r\r\n\r\n\r\n[[1]]\r\n[1] \"1\" \"2\" \"3\" \"A\"\r\n\r\n\r\n# Clase en R\r\nclass(tupla1_r)\r\n\r\n\r\n[1] \"list\"\r\n\r\nDiccionario desde R\r\n\r\n\r\n# Objeto\r\ndict1 <- dict(x = \"Hola\", y = 3.5, z = 1L)\r\ndict1\r\n\r\n\r\n{'x': 'Hola', 'y': 3.5, 'z': 1}\r\n\r\n\r\n# Clase\r\nclass(dict1)\r\n\r\n\r\n[1] \"python.builtin.dict\"   \"python.builtin.object\"\r\n\r\n\r\n# Nombres\r\nnames(dict1)\r\n\r\n\r\n[1] \"x\" \"y\" \"z\"\r\n\r\n\r\n# Atributos\r\nattributes(dict1)\r\n\r\n\r\n$class\r\n[1] \"python.builtin.dict\"   \"python.builtin.object\"\r\n\r\n\r\n# Coerción a objeto R\r\ndict1_r <- py_to_r(dict1)\r\ndict1_r\r\n\r\n\r\n$x\r\n[1] \"Hola\"\r\n\r\n$y\r\n[1] 3.5\r\n\r\n$z\r\n[1] 1\r\n\r\n\r\n# Clase en R\r\nclass(dict1_r)\r\n\r\n\r\n[1] \"list\"\r\n\r\nTupla en python\r\nCreando tupla en python:\r\n\r\n# Creando tupla\r\naltura = (1.65, 1.72, 1.56, 1.84, 1.92)\r\naltura\r\n(1.65, 1.72, 1.56, 1.84, 1.92)\r\n\r\n\r\n# Otra tupla\r\npeso = (67, 75, 67, 78, 85)\r\npeso\r\n(67, 75, 67, 78, 85)\r\n\r\n\r\n# Tipo (clase) de objetos\r\ntype(altura)\r\n<class 'tuple'>\r\ntype(peso)\r\n<class 'tuple'>\r\n\r\nLlamando la tupla desde R:\r\n\r\n\r\nclass(py$altura)\r\n\r\n\r\n[1] \"list\"\r\n\r\nplot(x = py$altura, y = py$peso, pch = 19, cex = 2)\r\n\r\n\r\n\r\n\r\nTipos de objetos en ambos lenguajes\r\n\r\n\r\nÍndices\r\nDesde python:\r\n\r\naltura\r\n(1.65, 1.72, 1.56, 1.84, 1.92)\r\n\r\n\r\naltura[0]\r\n1.65\r\n\r\nEn R:\r\n\r\n\r\npy$altura[1]\r\n\r\n\r\n[[1]]\r\n[1] 1.65\r\n\r\nInstalando un módulo de python desde R\r\nInstalando pandas\r\n\r\n\r\npy_install(\"pandas\")\r\n\r\n\r\n\r\nImportando pandas y leyendo archivo .csv\r\n\r\nimport pandas as pd\r\niris_py = pd.read_csv(\"Iris.csv\")\r\niris_py\r\n     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width    Species\r\n0             5.1          3.5           1.4          0.2     setosa\r\n1             4.9          3.0           1.4          0.2     setosa\r\n2             4.7          3.2           1.3          0.2     setosa\r\n3             4.6          3.1           1.5          0.2     setosa\r\n4             5.0          3.6           1.4          0.2     setosa\r\n..            ...          ...           ...          ...        ...\r\n145           6.7          3.0           5.2          2.3  virginica\r\n146           6.3          2.5           5.0          1.9  virginica\r\n147           6.5          3.0           5.2          2.0  virginica\r\n148           6.2          3.4           5.4          2.3  virginica\r\n149           5.9          3.0           5.1          1.8  virginica\r\n\r\n[150 rows x 5 columns]\r\n\r\n\r\ntype(iris_py)\r\n<class 'pandas.core.frame.DataFrame'>\r\n\r\nEstadísticos descriptivos:\r\n\r\niris_py.describe()\r\n       Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\r\ncount    150.000000   150.000000    150.000000   150.000000\r\nmean       5.843333     3.057333      3.758000     1.199333\r\nstd        0.828066     0.435866      1.765298     0.762238\r\nmin        4.300000     2.000000      1.000000     0.100000\r\n25%        5.100000     2.800000      1.600000     0.300000\r\n50%        5.800000     3.000000      4.350000     1.300000\r\n75%        6.400000     3.300000      5.100000     1.800000\r\nmax        7.900000     4.400000      6.900000     2.500000\r\n\r\nSeleccionando variables por nombre:\r\n\r\niris_py[[\"Sepal.Length\", \"Sepal.Width\"]]\r\n     Sepal.Length  Sepal.Width\r\n0             5.1          3.5\r\n1             4.9          3.0\r\n2             4.7          3.2\r\n3             4.6          3.1\r\n4             5.0          3.6\r\n..            ...          ...\r\n145           6.7          3.0\r\n146           6.3          2.5\r\n147           6.5          3.0\r\n148           6.2          3.4\r\n149           5.9          3.0\r\n\r\n[150 rows x 2 columns]\r\n\r\nFiltrando datos:\r\n\r\nfiltro = iris_py[\"Sepal.Width\"] <= 2.2\r\niris_py[filtro]\r\n     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width     Species\r\n60            5.0          2.0           3.5          1.0  versicolor\r\n62            6.0          2.2           4.0          1.0  versicolor\r\n68            6.2          2.2           4.5          1.5  versicolor\r\n119           6.0          2.2           5.0          1.5   virginica\r\n\r\nDataframe como array:\r\n\r\niris_py.values\r\narray([[5.1, 3.5, 1.4, 0.2, 'setosa'],\r\n       [4.9, 3.0, 1.4, 0.2, 'setosa'],\r\n       [4.7, 3.2, 1.3, 0.2, 'setosa'],\r\n       [4.6, 3.1, 1.5, 0.2, 'setosa'],\r\n       [5.0, 3.6, 1.4, 0.2, 'setosa'],\r\n       [5.4, 3.9, 1.7, 0.4, 'setosa'],\r\n       [4.6, 3.4, 1.4, 0.3, 'setosa'],\r\n       [5.0, 3.4, 1.5, 0.2, 'setosa'],\r\n       [4.4, 2.9, 1.4, 0.2, 'setosa'],\r\n       [4.9, 3.1, 1.5, 0.1, 'setosa'],\r\n       [5.4, 3.7, 1.5, 0.2, 'setosa'],\r\n       [4.8, 3.4, 1.6, 0.2, 'setosa'],\r\n       [4.8, 3.0, 1.4, 0.1, 'setosa'],\r\n       [4.3, 3.0, 1.1, 0.1, 'setosa'],\r\n       [5.8, 4.0, 1.2, 0.2, 'setosa'],\r\n       [5.7, 4.4, 1.5, 0.4, 'setosa'],\r\n       [5.4, 3.9, 1.3, 0.4, 'setosa'],\r\n       [5.1, 3.5, 1.4, 0.3, 'setosa'],\r\n       [5.7, 3.8, 1.7, 0.3, 'setosa'],\r\n       [5.1, 3.8, 1.5, 0.3, 'setosa'],\r\n       [5.4, 3.4, 1.7, 0.2, 'setosa'],\r\n       [5.1, 3.7, 1.5, 0.4, 'setosa'],\r\n       [4.6, 3.6, 1.0, 0.2, 'setosa'],\r\n       [5.1, 3.3, 1.7, 0.5, 'setosa'],\r\n       [4.8, 3.4, 1.9, 0.2, 'setosa'],\r\n       [5.0, 3.0, 1.6, 0.2, 'setosa'],\r\n       [5.0, 3.4, 1.6, 0.4, 'setosa'],\r\n       [5.2, 3.5, 1.5, 0.2, 'setosa'],\r\n       [5.2, 3.4, 1.4, 0.2, 'setosa'],\r\n       [4.7, 3.2, 1.6, 0.2, 'setosa'],\r\n       [4.8, 3.1, 1.6, 0.2, 'setosa'],\r\n       [5.4, 3.4, 1.5, 0.4, 'setosa'],\r\n       [5.2, 4.1, 1.5, 0.1, 'setosa'],\r\n       [5.5, 4.2, 1.4, 0.2, 'setosa'],\r\n       [4.9, 3.1, 1.5, 0.2, 'setosa'],\r\n       [5.0, 3.2, 1.2, 0.2, 'setosa'],\r\n       [5.5, 3.5, 1.3, 0.2, 'setosa'],\r\n       [4.9, 3.6, 1.4, 0.1, 'setosa'],\r\n       [4.4, 3.0, 1.3, 0.2, 'setosa'],\r\n       [5.1, 3.4, 1.5, 0.2, 'setosa'],\r\n       [5.0, 3.5, 1.3, 0.3, 'setosa'],\r\n       [4.5, 2.3, 1.3, 0.3, 'setosa'],\r\n       [4.4, 3.2, 1.3, 0.2, 'setosa'],\r\n       [5.0, 3.5, 1.6, 0.6, 'setosa'],\r\n       [5.1, 3.8, 1.9, 0.4, 'setosa'],\r\n       [4.8, 3.0, 1.4, 0.3, 'setosa'],\r\n       [5.1, 3.8, 1.6, 0.2, 'setosa'],\r\n       [4.6, 3.2, 1.4, 0.2, 'setosa'],\r\n       [5.3, 3.7, 1.5, 0.2, 'setosa'],\r\n       [5.0, 3.3, 1.4, 0.2, 'setosa'],\r\n       [7.0, 3.2, 4.7, 1.4, 'versicolor'],\r\n       [6.4, 3.2, 4.5, 1.5, 'versicolor'],\r\n       [6.9, 3.1, 4.9, 1.5, 'versicolor'],\r\n       [5.5, 2.3, 4.0, 1.3, 'versicolor'],\r\n       [6.5, 2.8, 4.6, 1.5, 'versicolor'],\r\n       [5.7, 2.8, 4.5, 1.3, 'versicolor'],\r\n       [6.3, 3.3, 4.7, 1.6, 'versicolor'],\r\n       [4.9, 2.4, 3.3, 1.0, 'versicolor'],\r\n       [6.6, 2.9, 4.6, 1.3, 'versicolor'],\r\n       [5.2, 2.7, 3.9, 1.4, 'versicolor'],\r\n       [5.0, 2.0, 3.5, 1.0, 'versicolor'],\r\n       [5.9, 3.0, 4.2, 1.5, 'versicolor'],\r\n       [6.0, 2.2, 4.0, 1.0, 'versicolor'],\r\n       [6.1, 2.9, 4.7, 1.4, 'versicolor'],\r\n       [5.6, 2.9, 3.6, 1.3, 'versicolor'],\r\n       [6.7, 3.1, 4.4, 1.4, 'versicolor'],\r\n       [5.6, 3.0, 4.5, 1.5, 'versicolor'],\r\n       [5.8, 2.7, 4.1, 1.0, 'versicolor'],\r\n       [6.2, 2.2, 4.5, 1.5, 'versicolor'],\r\n       [5.6, 2.5, 3.9, 1.1, 'versicolor'],\r\n       [5.9, 3.2, 4.8, 1.8, 'versicolor'],\r\n       [6.1, 2.8, 4.0, 1.3, 'versicolor'],\r\n       [6.3, 2.5, 4.9, 1.5, 'versicolor'],\r\n       [6.1, 2.8, 4.7, 1.2, 'versicolor'],\r\n       [6.4, 2.9, 4.3, 1.3, 'versicolor'],\r\n       [6.6, 3.0, 4.4, 1.4, 'versicolor'],\r\n       [6.8, 2.8, 4.8, 1.4, 'versicolor'],\r\n       [6.7, 3.0, 5.0, 1.7, 'versicolor'],\r\n       [6.0, 2.9, 4.5, 1.5, 'versicolor'],\r\n       [5.7, 2.6, 3.5, 1.0, 'versicolor'],\r\n       [5.5, 2.4, 3.8, 1.1, 'versicolor'],\r\n       [5.5, 2.4, 3.7, 1.0, 'versicolor'],\r\n       [5.8, 2.7, 3.9, 1.2, 'versicolor'],\r\n       [6.0, 2.7, 5.1, 1.6, 'versicolor'],\r\n       [5.4, 3.0, 4.5, 1.5, 'versicolor'],\r\n       [6.0, 3.4, 4.5, 1.6, 'versicolor'],\r\n       [6.7, 3.1, 4.7, 1.5, 'versicolor'],\r\n       [6.3, 2.3, 4.4, 1.3, 'versicolor'],\r\n       [5.6, 3.0, 4.1, 1.3, 'versicolor'],\r\n       [5.5, 2.5, 4.0, 1.3, 'versicolor'],\r\n       [5.5, 2.6, 4.4, 1.2, 'versicolor'],\r\n       [6.1, 3.0, 4.6, 1.4, 'versicolor'],\r\n       [5.8, 2.6, 4.0, 1.2, 'versicolor'],\r\n       [5.0, 2.3, 3.3, 1.0, 'versicolor'],\r\n       [5.6, 2.7, 4.2, 1.3, 'versicolor'],\r\n       [5.7, 3.0, 4.2, 1.2, 'versicolor'],\r\n       [5.7, 2.9, 4.2, 1.3, 'versicolor'],\r\n       [6.2, 2.9, 4.3, 1.3, 'versicolor'],\r\n       [5.1, 2.5, 3.0, 1.1, 'versicolor'],\r\n       [5.7, 2.8, 4.1, 1.3, 'versicolor'],\r\n       [6.3, 3.3, 6.0, 2.5, 'virginica'],\r\n       [5.8, 2.7, 5.1, 1.9, 'virginica'],\r\n       [7.1, 3.0, 5.9, 2.1, 'virginica'],\r\n       [6.3, 2.9, 5.6, 1.8, 'virginica'],\r\n       [6.5, 3.0, 5.8, 2.2, 'virginica'],\r\n       [7.6, 3.0, 6.6, 2.1, 'virginica'],\r\n       [4.9, 2.5, 4.5, 1.7, 'virginica'],\r\n       [7.3, 2.9, 6.3, 1.8, 'virginica'],\r\n       [6.7, 2.5, 5.8, 1.8, 'virginica'],\r\n       [7.2, 3.6, 6.1, 2.5, 'virginica'],\r\n       [6.5, 3.2, 5.1, 2.0, 'virginica'],\r\n       [6.4, 2.7, 5.3, 1.9, 'virginica'],\r\n       [6.8, 3.0, 5.5, 2.1, 'virginica'],\r\n       [5.7, 2.5, 5.0, 2.0, 'virginica'],\r\n       [5.8, 2.8, 5.1, 2.4, 'virginica'],\r\n       [6.4, 3.2, 5.3, 2.3, 'virginica'],\r\n       [6.5, 3.0, 5.5, 1.8, 'virginica'],\r\n       [7.7, 3.8, 6.7, 2.2, 'virginica'],\r\n       [7.7, 2.6, 6.9, 2.3, 'virginica'],\r\n       [6.0, 2.2, 5.0, 1.5, 'virginica'],\r\n       [6.9, 3.2, 5.7, 2.3, 'virginica'],\r\n       [5.6, 2.8, 4.9, 2.0, 'virginica'],\r\n       [7.7, 2.8, 6.7, 2.0, 'virginica'],\r\n       [6.3, 2.7, 4.9, 1.8, 'virginica'],\r\n       [6.7, 3.3, 5.7, 2.1, 'virginica'],\r\n       [7.2, 3.2, 6.0, 1.8, 'virginica'],\r\n       [6.2, 2.8, 4.8, 1.8, 'virginica'],\r\n       [6.1, 3.0, 4.9, 1.8, 'virginica'],\r\n       [6.4, 2.8, 5.6, 2.1, 'virginica'],\r\n       [7.2, 3.0, 5.8, 1.6, 'virginica'],\r\n       [7.4, 2.8, 6.1, 1.9, 'virginica'],\r\n       [7.9, 3.8, 6.4, 2.0, 'virginica'],\r\n       [6.4, 2.8, 5.6, 2.2, 'virginica'],\r\n       [6.3, 2.8, 5.1, 1.5, 'virginica'],\r\n       [6.1, 2.6, 5.6, 1.4, 'virginica'],\r\n       [7.7, 3.0, 6.1, 2.3, 'virginica'],\r\n       [6.3, 3.4, 5.6, 2.4, 'virginica'],\r\n       [6.4, 3.1, 5.5, 1.8, 'virginica'],\r\n       [6.0, 3.0, 4.8, 1.8, 'virginica'],\r\n       [6.9, 3.1, 5.4, 2.1, 'virginica'],\r\n       [6.7, 3.1, 5.6, 2.4, 'virginica'],\r\n       [6.9, 3.1, 5.1, 2.3, 'virginica'],\r\n       [5.8, 2.7, 5.1, 1.9, 'virginica'],\r\n       [6.8, 3.2, 5.9, 2.3, 'virginica'],\r\n       [6.7, 3.3, 5.7, 2.5, 'virginica'],\r\n       [6.7, 3.0, 5.2, 2.3, 'virginica'],\r\n       [6.3, 2.5, 5.0, 1.9, 'virginica'],\r\n       [6.5, 3.0, 5.2, 2.0, 'virginica'],\r\n       [6.2, 3.4, 5.4, 2.3, 'virginica'],\r\n       [5.9, 3.0, 5.1, 1.8, 'virginica']], dtype=object)\r\n\r\nImportando tensorflow desde python\r\n\r\nimport tensorflow as tf\r\n\r\nFunciones desde tf:\r\n\r\n\r\nVisualizando datos con matplotlib\r\nEjemplo 1\r\n\r\nimport matplotlib.pyplot as plt\r\nx = np.arange(0, 20)\r\ny = x**2\r\ng1 = plt.plot(x, y, \"g--\")\r\ng1 = plt.title(\"X vs Y\")\r\ng1 = plt.xlabel(\"Eje x\")\r\ng1 = plt.ylabel(\"Eje Y\")  \r\ng1\r\n\r\n\r\n\r\nEjemplo 2\r\n\r\nw = np.arange(0, 50).reshape(5, 10)\r\nw\r\narray([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\r\n       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\r\n       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\r\n       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\r\n       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])\r\n\r\n\r\ng2 = plt.imshow(w)\r\ng2 = plt.colorbar()\r\nplt.show()\r\n\r\n\r\n\r\nEjemplo 3\r\nGráfico desde un Dataframe:\r\n\r\ng3 = iris_py.plot(x = \"Sepal.Length\", y = \"Sepal.Width\", kind = \"scatter\",\r\n                  color = \"red\")                 \r\ng3\r\n\r\n\r\n\r\nModelo con scikit-learn\r\nEjemplo DataCamp\r\nFuente de datos: PIMA\r\nscikit-learn\r\nImportando módulos de python\r\n\r\nimport pandas as pd\r\nimport sklearn\r\nfrom sklearn.tree import DecisionTreeClassifier \r\nfrom sklearn.model_selection import train_test_split \r\nfrom sklearn import metrics \r\n\r\nCargando datos\r\n\r\ncol_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree',\r\n             'age', 'label']\r\n# load dataset\r\npima = pd.read_csv(\"diabetes.csv\", header=None, names=col_names)\r\npima = pima[1:]\r\npima.head()\r\n  pregnant glucose  bp skin insulin   bmi pedigree age label\r\n1        6     148  72   35       0  33.6    0.627  50     1\r\n2        1      85  66   29       0  26.6    0.351  31     0\r\n3        8     183  64    0       0  23.3    0.672  32     1\r\n4        1      89  66   23      94  28.1    0.167  21     0\r\n5        0     137  40   35     168  43.1    2.288  33     1\r\n\r\nSelección de características\r\n\r\n# Fraccionando la base de datos en predictoras (X) y respuesta (Y)\r\nfeature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\r\nX = pima[feature_cols] \r\ny = pima.label\r\n\r\nTrain - Test\r\n\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\r\n\r\nConstruyendo Modelo\r\n\r\n# Clasificador\r\nclf = DecisionTreeClassifier()\r\n\r\n# Clasificador en train --> Entrenando modelo\r\nclf_fit = clf.fit(X = X_train, y = y_train)\r\n\r\nEvaluación del modelo\r\n\r\n# Predicciones\r\ny_pred = clf_fit.predict(X_test)\r\nprint(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\r\nAccuracy: 0.6753246753246753\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/py_r_1/img.png",
    "last_modified": "2021-04-02T11:46:09-05:00",
    "input_file": {}
  }
]
