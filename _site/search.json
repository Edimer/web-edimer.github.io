[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Información",
    "section": "",
    "text": "¡Soy más amigo de Salviati que de Simplicio, aunque respeto y admiro la visión neutral de Sagredo!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning con R y Python",
    "section": "",
    "text": "R\n\n\nxgboost\n\n\nGradient Boosting\n\n\nML\n\n\n\n\nAlgortimo XGBoost con R para resolver problemas de aprendizaje supervisado (clasificación).\n\n\n\n\n\n\n1 may 2021\n\n\nEdimer (Sidereus)\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nTree Decision\n\n\nML\n\n\n\n\nEjemplo de árboles de decisión en machine learning supervisado para clasificación. Uso de las bibliotecas rpart, rpart.plot y caret en perfilamiento de riesgo crediticio.\n\n\n\n\n\n\n18 jul 2020\n\n\nEdimer (Sidereus)\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\ncaret\n\n\nML\n\n\n\n\nAlgoritmos de machine learning con caret y R. Entrenamiento de modelos random forest y support vector machine en problemas de clasificación supervisada.\n\n\n\n\n\n\n23 mar 2020\n\n\nEdimer (Sidereus)\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nPython\n\n\nProgramación\n\n\n\n\nUtilizando python desde R con la biblioteca reticulate. Elementos básicos de python para operaciones numéricas comunes, visualización y ejemplo corto con scikit-learn.\n\n\n\n\n\n\n20 ene 2020\n\n\nEdimer (Sidereus)\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/caret_r/caret_R.html",
    "href": "posts/caret_r/caret_R.html",
    "title": "Algoritmos de ML con caret en R (1)",
    "section": "",
    "text": "Fuente: predicción de estrellas púlsar.\n¿Qué es un púlsar?"
  },
  {
    "objectID": "posts/caret_r/caret_R.html#variable-respuesta",
    "href": "posts/caret_r/caret_R.html#variable-respuesta",
    "title": "Algoritmos de ML con caret en R (1)",
    "section": "Variable respuesta",
    "text": "Variable respuesta\n\nCódigodf_pulsar %>% group_by(pulsar) %>% count() %>% \n  ggplot(data = ., aes(x = pulsar, y = n)) +\n  geom_col(color = \"black\", fill = \"#033660\") +\n  geom_label(aes(label = n)) +\n  labs(x = \"¿Púlsar?\"?\", titl= \"Distribución de variable respuesta\"ta\",\n       subtitle = \"0=No\\n1=Sí\"))++\n  mi_temagg"
  },
  {
    "objectID": "posts/caret_r/caret_R.html#distribuciones",
    "href": "posts/caret_r/caret_R.html#distribuciones",
    "title": "Algoritmos de ML con caret en R (1)",
    "section": "Distribuciones",
    "text": "Distribuciones\n\nCódigodf_pulsar %>% \n  gather(key = \"variable\", value = \"valor\", -pulsar) %>% \n  ggplot(data = ., aes(x = valor, fill = pulsar)) +\n  facet_wrap(~variable, scales = \"free\", ncol = 4) +\n  geom_density(alpha = 0.9) +\n  scale_x_log10() +\n  labs(x = \"\", y = \"Densidad\", title = \"Escala logarítmica\"\",\n       fill = \"¿Púlsar?\")\"+ +\n  scale_fill_manual(values = c(\"#790222\", \"#033660\")) +\n  mi_temagg"
  },
  {
    "objectID": "posts/caret_r/caret_R.html#correlaciones",
    "href": "posts/caret_r/caret_R.html#correlaciones",
    "title": "Algoritmos de ML con caret en R (1)",
    "section": "Correlaciones",
    "text": "Correlaciones\n\nCódigo# Cargando biblioteca corrplot\nlibrary(corrplot)\n\ndf_pulsar %>% mutate_if(is.numeric, scale)  %>% select_if(is.numeric) %>%\n  cor(method = \"spearman\") %>% \n  corrplot(method = \"pie\", type = \"upper\", order = \"hclust\", diag = FALSE,\n           tl.srt = 35, tl.col = \"black\", tl.cex = 1)"
  },
  {
    "objectID": "posts/caret_r/caret_R.html#random-forest",
    "href": "posts/caret_r/caret_R.html#random-forest",
    "title": "Algoritmos de ML con caret en R (1)",
    "section": "Random Forest",
    "text": "Random Forest\nAlgoritmo\n\nCódigo# Algoritmo de random forest\nmodelo_rf <- train(pulsar ~ ., data = df_train, method = \"ranger\")\n\n# Guardando modelo\nsaveRDS(object = modelo_rf, file = \"models_fit/RandomForest.rds\")\n\n\n\nResultados:\n\n\nCódigo# Cargando modelo\nmod_rf <- readRDS(\"models_fit/RandomForest.rds\")\n\n# Resultados del modelo\nmod_rf\n\nRandom Forest \n\n12530 samples\n    8 predictor\n    2 classes: '0', '1' \n\nNo pre-processing\nResampling: Bootstrapped (25 reps) \nSummary of sample sizes: 12530, 12530, 12530, 12530, 12530, 12530, ... \nResampling results across tuning parameters:\n\n  mtry  splitrule   Accuracy   Kappa    \n  2     gini        0.9801226  0.8758954\n  2     extratrees  0.9794474  0.8705685\n  5     gini        0.9801169  0.8762727\n  5     extratrees  0.9803843  0.8777407\n  8     gini        0.9795793  0.8731006\n  8     extratrees  0.9804887  0.8788098\n\nTuning parameter 'min.node.size' was held constant at a value of 1\nAccuracy was used to select the optimal model using the largest value.\nThe final values used for the model were mtry = 8, splitrule = extratrees\n and min.node.size = 1.\n\n\nDesempeño\n\nMatriz de confusión en test:\n\n\nCódigo# Predicciones en nuevos datos\npredict_rf <- predict(object = mod_rf, newdata = df_test)\n\n# Matriz de confuciónn\nconfusionMatrix(predict_rf, df_test$pulsar, positive = \"1\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 4840   84\n         1   37  407\n                                          \n               Accuracy : 0.9775          \n                 95% CI : (0.9731, 0.9813)\n    No Information Rate : 0.9085          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8583          \n                                          \n Mcnemar's Test P-Value : 2.892e-05       \n                                          \n            Sensitivity : 0.82892         \n            Specificity : 0.99241         \n         Pos Pred Value : 0.91667         \n         Neg Pred Value : 0.98294         \n             Prevalence : 0.09147         \n         Detection Rate : 0.07582         \n   Detection Prevalence : 0.08271         \n      Balanced Accuracy : 0.91067         \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "posts/caret_r/caret_R.html#svm",
    "href": "posts/caret_r/caret_R.html#svm",
    "title": "Algoritmos de ML con caret en R (1)",
    "section": "SVM",
    "text": "SVM\n\nSe utiliza el método svmRadial que está contenido en la biblioteca kernlab.\nLa configuración está por defecto.\nEste algoritmo permite ajustar hiperparámetros sigma y C (costo).\nDocumentación kernlab.\n\nAlgoritmo\n\nCódigo# Algoritmo\nmodelo_svmR <- train(pulsar ~ ., data = df_train, method = \"svmRadial\")\n\n# Guardando modelo\nsaveRDS(object = modelo_svmR, file = \"models_fit/SVM_Radial.rds\")\n\n\n\nResultados:\n\n\nCódigo# Cargando modelo\nmod_svmR <- readRDS(\"models_fit/SVM_Radial.rds\")\n\n# Resultados del modelo\nmod_svmR\n\nSupport Vector Machines with Radial Basis Function Kernel \n\n12530 samples\n    8 predictor\n    2 classes: '0', '1' \n\nNo pre-processing\nResampling: Bootstrapped (25 reps) \nSummary of sample sizes: 12530, 12530, 12530, 12530, 12530, 12530, ... \nResampling results across tuning parameters:\n\n  C     Accuracy   Kappa    \n  0.25  0.9785764  0.8629191\n  0.50  0.9785329  0.8635606\n  1.00  0.9787235  0.8654589\n\nTuning parameter 'sigma' was held constant at a value of 0.4893064\nAccuracy was used to select the optimal model using the largest value.\nThe final values used for the model were sigma = 0.4893064 and C = 1.\n\n\nDesempeño\n\nCódigopredict_svmR <- predict(object = mod_svmR, newdata = df_test)\nconfusionMatrix(predict_svmR, df_test$pulsar, positive = \"1\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 4852   95\n         1   25  396\n                                          \n               Accuracy : 0.9776          \n                 95% CI : (0.9733, 0.9814)\n    No Information Rate : 0.9085          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8563          \n                                          \n Mcnemar's Test P-Value : 2.999e-10       \n                                          \n            Sensitivity : 0.80652         \n            Specificity : 0.99487         \n         Pos Pred Value : 0.94062         \n         Neg Pred Value : 0.98080         \n             Prevalence : 0.09147         \n         Detection Rate : 0.07377         \n   Detection Prevalence : 0.07843         \n      Balanced Accuracy : 0.90070         \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "posts/caret_r/caret_R.html#comparación-de-modelos",
    "href": "posts/caret_r/caret_R.html#comparación-de-modelos",
    "title": "Algoritmos de ML con caret en R (1)",
    "section": "Comparación de modelos",
    "text": "Comparación de modelos\n\nCódigomod_svmR$resample %>% \n  select(-Resample) %>% \n  mutate(Modelo = \"SVM\") %>% \n  bind_rows(mod_rf$resample) %>% \n  select(-Resample) %>% \n  replace_na(list(Modelo = \"Random Forest\")) %>% \n  gather(key = \"Medida\", value = \"Valor\", -Modelo) %>% \n  ggplot(data = ., aes(x = Modelo, y = Valor, fill = Modelo)) +\n  facet_wrap(~Medida, scales = \"free\", ncol = 2) +\n  geom_violin(alpha = 0.9) +\n  stat_summary(fun = mean, geom = \"point\", pch = 19) +\n  labs(y = \"\", title = \"Comparación de modelos\"\",\n       subtitle = \"Predicción de estrellas púlsar\")\"+ +\n  scale_fill_manual(values =  c(\"#790222\", \"#033660\")) +\n  mi_temagg +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html",
    "href": "posts/pyr1/Py_R_1.html",
    "title": "R + Python: I",
    "section": "",
    "text": "Tener instalado Python\n\nRecomendable instalar Anaconda Navigator\n\nInstalar la biblioteca reticulate desde R."
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#importando-numpy",
    "href": "posts/pyr1/Py_R_1.html#importando-numpy",
    "title": "R + Python: I",
    "section": "Importando numpy\n",
    "text": "Importando numpy\n\n\nCódigonp <- import(\"numpy\")\nnp$argmin(c(2, 1, 3))\n\n[1] 1\n\n\n\nEn esta salida se muestra cómo aplicar la función arcgmin de python sobre un vector de R. Devuelve la posición (índice) donde se encuentra el valor mínimo del vector dado.\nEs posible acceder a todas las funciones de numpy desde el objeto np con el símbolo dólar $."
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#importando-os",
    "href": "posts/pyr1/Py_R_1.html#importando-os",
    "title": "R + Python: I",
    "section": "Importando os\n",
    "text": "Importando os\n\n\nCódigoos <- import(\"os\")\nos$getcwd()\n\n[1] \"D:\\\\Otros\\\\Github\\\\web-edimer\\\\web-edimer.github.io\\\\posts\\\\pyr1\""
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#tupla-desde-r",
    "href": "posts/pyr1/Py_R_1.html#tupla-desde-r",
    "title": "R + Python: I",
    "section": "Tupla desde R\n",
    "text": "Tupla desde R\n\n\nCreando una tupla y obteniendo su clase:\n\n\nCódigotupla1 <- tuple(c(1, 2, 3, \"A\"))\ntupla1\n## (['1', '2', '3', 'A'],)\n\n# Clase en python\nclass(tupla1)\n## [1] \"python.builtin.tuple\"  \"python.builtin.object\"\n\n\n\nCoercionar el objeto tupla1 de clase tuple en python directamente a R:\n\n\nCódigotupla1_r <- py_to_r(tupla1)\ntupla1_r\n## [[1]]\n## [1] \"1\" \"2\" \"3\" \"A\"\n\n# Clase en R\nclass(tupla1_r)\n## [1] \"list\""
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#diccionario-desde-r",
    "href": "posts/pyr1/Py_R_1.html#diccionario-desde-r",
    "title": "R + Python: I",
    "section": "Diccionario desde R\n",
    "text": "Diccionario desde R\n\n\nCódigo# Objeto\ndict1 <- dict(x = \"Hola\", y = 3.5, z = 1L)\ndict1\n## {'x': 'Hola', 'y': 3.5, 'z': 1}\n\n# Clase\nclass(dict1)\n## [1] \"python.builtin.dict\"   \"python.builtin.object\"\n\n# Nombres\nnames(dict1)\n## [1] \"x\" \"y\" \"z\"\n\n# Atributos\nattributes(dict1)\n## $class\n## [1] \"python.builtin.dict\"   \"python.builtin.object\"\n\n# Coerción a objeto RR\ndict1_r <- py_to_r(dict1)\ndict1_r\n## $x\n## [1] \"Hola\"\n## \n## $y\n## [1] 3.5\n## \n## $z\n## [1] 1\n\n# Clase en R\nclass(dict1_r)\n## [1] \"list\""
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#tupla-en-python",
    "href": "posts/pyr1/Py_R_1.html#tupla-en-python",
    "title": "R + Python: I",
    "section": "Tupla en python\n",
    "text": "Tupla en python\n\n\nCreando tupla en python:\n\n\nCódigo# Creando tupla\naltura = (1.65, 1.72, 1.56, 1.84, 1.92)\naltura\n\n(1.65, 1.72, 1.56, 1.84, 1.92)\n\n\n\nCódigo# Otra tupla\npeso = (67, 75, 67, 78, 85)\npeso\n\n(67, 75, 67, 78, 85)\n\n\n\nCódigo# Tipo (clase) de objetos\ntype(altura)\n\n<class 'tuple'>\n\nCódigotype(peso)\n\n<class 'tuple'>\n\n\n\nLlamando la tupla desde R:\n\n\nCódigoclass(py$altura)\n## [1] \"list\"\nplot(x = py$altura, y = py$peso, pch = 19, cex = 2)"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#tipos-de-objetos-en-ambos-lenguajes",
    "href": "posts/pyr1/Py_R_1.html#tipos-de-objetos-en-ambos-lenguajes",
    "title": "R + Python: I",
    "section": "Tipos de objetos en ambos lenguajes",
    "text": "Tipos de objetos en ambos lenguajes"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#instalando-pandas",
    "href": "posts/pyr1/Py_R_1.html#instalando-pandas",
    "title": "R + Python: I",
    "section": "Instalando pandas\n",
    "text": "Instalando pandas\n\n\nCódigopy_install(\"pandas\")"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#importando-pandas-y-leyendo-archivo-.csv",
    "href": "posts/pyr1/Py_R_1.html#importando-pandas-y-leyendo-archivo-.csv",
    "title": "R + Python: I",
    "section": "Importando pandas y leyendo archivo .csv\n",
    "text": "Importando pandas y leyendo archivo .csv\n\n\nCódigoimport pandas as pd\niris_py = pd.read_csv(\"Iris.csv\")\niris_py\n\n     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width    Species\n0             5.1          3.5           1.4          0.2     setosa\n1             4.9          3.0           1.4          0.2     setosa\n2             4.7          3.2           1.3          0.2     setosa\n3             4.6          3.1           1.5          0.2     setosa\n4             5.0          3.6           1.4          0.2     setosa\n..            ...          ...           ...          ...        ...\n145           6.7          3.0           5.2          2.3  virginica\n146           6.3          2.5           5.0          1.9  virginica\n147           6.5          3.0           5.2          2.0  virginica\n148           6.2          3.4           5.4          2.3  virginica\n149           5.9          3.0           5.1          1.8  virginica\n\n[150 rows x 5 columns]\n\n\n\nCódigotype(iris_py)\n\n<class 'pandas.core.frame.DataFrame'>\n\n\n\nEstadísticos descriptivos:\n\n\nCódigoiris_py.describe()\n\n       Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\ncount    150.000000   150.000000    150.000000   150.000000\nmean       5.843333     3.057333      3.758000     1.199333\nstd        0.828066     0.435866      1.765298     0.762238\nmin        4.300000     2.000000      1.000000     0.100000\n25%        5.100000     2.800000      1.600000     0.300000\n50%        5.800000     3.000000      4.350000     1.300000\n75%        6.400000     3.300000      5.100000     1.800000\nmax        7.900000     4.400000      6.900000     2.500000\n\n\n\nSeleccionando variables por nombre:\n\n\nCódigoiris_py[[\"Sepal.Length\", \"Sepal.Width\"]]\n\n     Sepal.Length  Sepal.Width\n0             5.1          3.5\n1             4.9          3.0\n2             4.7          3.2\n3             4.6          3.1\n4             5.0          3.6\n..            ...          ...\n145           6.7          3.0\n146           6.3          2.5\n147           6.5          3.0\n148           6.2          3.4\n149           5.9          3.0\n\n[150 rows x 2 columns]\n\n\n\nFiltrando datos:\n\n\nCódigofiltro = iris_py[\"Sepal.Width\"] <= 2.2\niris_py[filtro]\n\n     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width     Species\n60            5.0          2.0           3.5          1.0  versicolor\n62            6.0          2.2           4.0          1.0  versicolor\n68            6.2          2.2           4.5          1.5  versicolor\n119           6.0          2.2           5.0          1.5   virginica\n\n\n\n\nDataframe como array:\n\n\nCódigoiris_py.values\n\narray([[5.1, 3.5, 1.4, 0.2, 'setosa'],\n       [4.9, 3.0, 1.4, 0.2, 'setosa'],\n       [4.7, 3.2, 1.3, 0.2, 'setosa'],\n       [4.6, 3.1, 1.5, 0.2, 'setosa'],\n       [5.0, 3.6, 1.4, 0.2, 'setosa'],\n       [5.4, 3.9, 1.7, 0.4, 'setosa'],\n       [4.6, 3.4, 1.4, 0.3, 'setosa'],\n       [5.0, 3.4, 1.5, 0.2, 'setosa'],\n       [4.4, 2.9, 1.4, 0.2, 'setosa'],\n       [4.9, 3.1, 1.5, 0.1, 'setosa'],\n       [5.4, 3.7, 1.5, 0.2, 'setosa'],\n       [4.8, 3.4, 1.6, 0.2, 'setosa'],\n       [4.8, 3.0, 1.4, 0.1, 'setosa'],\n       [4.3, 3.0, 1.1, 0.1, 'setosa'],\n       [5.8, 4.0, 1.2, 0.2, 'setosa'],\n       [5.7, 4.4, 1.5, 0.4, 'setosa'],\n       [5.4, 3.9, 1.3, 0.4, 'setosa'],\n       [5.1, 3.5, 1.4, 0.3, 'setosa'],\n       [5.7, 3.8, 1.7, 0.3, 'setosa'],\n       [5.1, 3.8, 1.5, 0.3, 'setosa'],\n       [5.4, 3.4, 1.7, 0.2, 'setosa'],\n       [5.1, 3.7, 1.5, 0.4, 'setosa'],\n       [4.6, 3.6, 1.0, 0.2, 'setosa'],\n       [5.1, 3.3, 1.7, 0.5, 'setosa'],\n       [4.8, 3.4, 1.9, 0.2, 'setosa'],\n       [5.0, 3.0, 1.6, 0.2, 'setosa'],\n       [5.0, 3.4, 1.6, 0.4, 'setosa'],\n       [5.2, 3.5, 1.5, 0.2, 'setosa'],\n       [5.2, 3.4, 1.4, 0.2, 'setosa'],\n       [4.7, 3.2, 1.6, 0.2, 'setosa'],\n       [4.8, 3.1, 1.6, 0.2, 'setosa'],\n       [5.4, 3.4, 1.5, 0.4, 'setosa'],\n       [5.2, 4.1, 1.5, 0.1, 'setosa'],\n       [5.5, 4.2, 1.4, 0.2, 'setosa'],\n       [4.9, 3.1, 1.5, 0.2, 'setosa'],\n       [5.0, 3.2, 1.2, 0.2, 'setosa'],\n       [5.5, 3.5, 1.3, 0.2, 'setosa'],\n       [4.9, 3.6, 1.4, 0.1, 'setosa'],\n       [4.4, 3.0, 1.3, 0.2, 'setosa'],\n       [5.1, 3.4, 1.5, 0.2, 'setosa'],\n       [5.0, 3.5, 1.3, 0.3, 'setosa'],\n       [4.5, 2.3, 1.3, 0.3, 'setosa'],\n       [4.4, 3.2, 1.3, 0.2, 'setosa'],\n       [5.0, 3.5, 1.6, 0.6, 'setosa'],\n       [5.1, 3.8, 1.9, 0.4, 'setosa'],\n       [4.8, 3.0, 1.4, 0.3, 'setosa'],\n       [5.1, 3.8, 1.6, 0.2, 'setosa'],\n       [4.6, 3.2, 1.4, 0.2, 'setosa'],\n       [5.3, 3.7, 1.5, 0.2, 'setosa'],\n       [5.0, 3.3, 1.4, 0.2, 'setosa'],\n       [7.0, 3.2, 4.7, 1.4, 'versicolor'],\n       [6.4, 3.2, 4.5, 1.5, 'versicolor'],\n       [6.9, 3.1, 4.9, 1.5, 'versicolor'],\n       [5.5, 2.3, 4.0, 1.3, 'versicolor'],\n       [6.5, 2.8, 4.6, 1.5, 'versicolor'],\n       [5.7, 2.8, 4.5, 1.3, 'versicolor'],\n       [6.3, 3.3, 4.7, 1.6, 'versicolor'],\n       [4.9, 2.4, 3.3, 1.0, 'versicolor'],\n       [6.6, 2.9, 4.6, 1.3, 'versicolor'],\n       [5.2, 2.7, 3.9, 1.4, 'versicolor'],\n       [5.0, 2.0, 3.5, 1.0, 'versicolor'],\n       [5.9, 3.0, 4.2, 1.5, 'versicolor'],\n       [6.0, 2.2, 4.0, 1.0, 'versicolor'],\n       [6.1, 2.9, 4.7, 1.4, 'versicolor'],\n       [5.6, 2.9, 3.6, 1.3, 'versicolor'],\n       [6.7, 3.1, 4.4, 1.4, 'versicolor'],\n       [5.6, 3.0, 4.5, 1.5, 'versicolor'],\n       [5.8, 2.7, 4.1, 1.0, 'versicolor'],\n       [6.2, 2.2, 4.5, 1.5, 'versicolor'],\n       [5.6, 2.5, 3.9, 1.1, 'versicolor'],\n       [5.9, 3.2, 4.8, 1.8, 'versicolor'],\n       [6.1, 2.8, 4.0, 1.3, 'versicolor'],\n       [6.3, 2.5, 4.9, 1.5, 'versicolor'],\n       [6.1, 2.8, 4.7, 1.2, 'versicolor'],\n       [6.4, 2.9, 4.3, 1.3, 'versicolor'],\n       [6.6, 3.0, 4.4, 1.4, 'versicolor'],\n       [6.8, 2.8, 4.8, 1.4, 'versicolor'],\n       [6.7, 3.0, 5.0, 1.7, 'versicolor'],\n       [6.0, 2.9, 4.5, 1.5, 'versicolor'],\n       [5.7, 2.6, 3.5, 1.0, 'versicolor'],\n       [5.5, 2.4, 3.8, 1.1, 'versicolor'],\n       [5.5, 2.4, 3.7, 1.0, 'versicolor'],\n       [5.8, 2.7, 3.9, 1.2, 'versicolor'],\n       [6.0, 2.7, 5.1, 1.6, 'versicolor'],\n       [5.4, 3.0, 4.5, 1.5, 'versicolor'],\n       [6.0, 3.4, 4.5, 1.6, 'versicolor'],\n       [6.7, 3.1, 4.7, 1.5, 'versicolor'],\n       [6.3, 2.3, 4.4, 1.3, 'versicolor'],\n       [5.6, 3.0, 4.1, 1.3, 'versicolor'],\n       [5.5, 2.5, 4.0, 1.3, 'versicolor'],\n       [5.5, 2.6, 4.4, 1.2, 'versicolor'],\n       [6.1, 3.0, 4.6, 1.4, 'versicolor'],\n       [5.8, 2.6, 4.0, 1.2, 'versicolor'],\n       [5.0, 2.3, 3.3, 1.0, 'versicolor'],\n       [5.6, 2.7, 4.2, 1.3, 'versicolor'],\n       [5.7, 3.0, 4.2, 1.2, 'versicolor'],\n       [5.7, 2.9, 4.2, 1.3, 'versicolor'],\n       [6.2, 2.9, 4.3, 1.3, 'versicolor'],\n       [5.1, 2.5, 3.0, 1.1, 'versicolor'],\n       [5.7, 2.8, 4.1, 1.3, 'versicolor'],\n       [6.3, 3.3, 6.0, 2.5, 'virginica'],\n       [5.8, 2.7, 5.1, 1.9, 'virginica'],\n       [7.1, 3.0, 5.9, 2.1, 'virginica'],\n       [6.3, 2.9, 5.6, 1.8, 'virginica'],\n       [6.5, 3.0, 5.8, 2.2, 'virginica'],\n       [7.6, 3.0, 6.6, 2.1, 'virginica'],\n       [4.9, 2.5, 4.5, 1.7, 'virginica'],\n       [7.3, 2.9, 6.3, 1.8, 'virginica'],\n       [6.7, 2.5, 5.8, 1.8, 'virginica'],\n       [7.2, 3.6, 6.1, 2.5, 'virginica'],\n       [6.5, 3.2, 5.1, 2.0, 'virginica'],\n       [6.4, 2.7, 5.3, 1.9, 'virginica'],\n       [6.8, 3.0, 5.5, 2.1, 'virginica'],\n       [5.7, 2.5, 5.0, 2.0, 'virginica'],\n       [5.8, 2.8, 5.1, 2.4, 'virginica'],\n       [6.4, 3.2, 5.3, 2.3, 'virginica'],\n       [6.5, 3.0, 5.5, 1.8, 'virginica'],\n       [7.7, 3.8, 6.7, 2.2, 'virginica'],\n       [7.7, 2.6, 6.9, 2.3, 'virginica'],\n       [6.0, 2.2, 5.0, 1.5, 'virginica'],\n       [6.9, 3.2, 5.7, 2.3, 'virginica'],\n       [5.6, 2.8, 4.9, 2.0, 'virginica'],\n       [7.7, 2.8, 6.7, 2.0, 'virginica'],\n       [6.3, 2.7, 4.9, 1.8, 'virginica'],\n       [6.7, 3.3, 5.7, 2.1, 'virginica'],\n       [7.2, 3.2, 6.0, 1.8, 'virginica'],\n       [6.2, 2.8, 4.8, 1.8, 'virginica'],\n       [6.1, 3.0, 4.9, 1.8, 'virginica'],\n       [6.4, 2.8, 5.6, 2.1, 'virginica'],\n       [7.2, 3.0, 5.8, 1.6, 'virginica'],\n       [7.4, 2.8, 6.1, 1.9, 'virginica'],\n       [7.9, 3.8, 6.4, 2.0, 'virginica'],\n       [6.4, 2.8, 5.6, 2.2, 'virginica'],\n       [6.3, 2.8, 5.1, 1.5, 'virginica'],\n       [6.1, 2.6, 5.6, 1.4, 'virginica'],\n       [7.7, 3.0, 6.1, 2.3, 'virginica'],\n       [6.3, 3.4, 5.6, 2.4, 'virginica'],\n       [6.4, 3.1, 5.5, 1.8, 'virginica'],\n       [6.0, 3.0, 4.8, 1.8, 'virginica'],\n       [6.9, 3.1, 5.4, 2.1, 'virginica'],\n       [6.7, 3.1, 5.6, 2.4, 'virginica'],\n       [6.9, 3.1, 5.1, 2.3, 'virginica'],\n       [5.8, 2.7, 5.1, 1.9, 'virginica'],\n       [6.8, 3.2, 5.9, 2.3, 'virginica'],\n       [6.7, 3.3, 5.7, 2.5, 'virginica'],\n       [6.7, 3.0, 5.2, 2.3, 'virginica'],\n       [6.3, 2.5, 5.0, 1.9, 'virginica'],\n       [6.5, 3.0, 5.2, 2.0, 'virginica'],\n       [6.2, 3.4, 5.4, 2.3, 'virginica'],\n       [5.9, 3.0, 5.1, 1.8, 'virginica']], dtype=object)"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#importando-tensorflow-desde-python",
    "href": "posts/pyr1/Py_R_1.html#importando-tensorflow-desde-python",
    "title": "R + Python: I",
    "section": "Importando tensorflow desde python",
    "text": "Importando tensorflow desde python\n\nCódigoimport tensorflow as tf\n\n\n\nFunciones desde tf:"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#ejemplo-1",
    "href": "posts/pyr1/Py_R_1.html#ejemplo-1",
    "title": "R + Python: I",
    "section": "Ejemplo 1",
    "text": "Ejemplo 1\n\nCódigoimport matplotlib.pyplot as plt\nx = np.arange(0, 20)\ny = x**2\ng1 = plt.plot(x, y, \"g--\")\ng1 = plt.title(\"X vs Y\")\ng1 = plt.xlabel(\"Eje x\")\ng1 = plt.ylabel(\"Eje Y\")  \ng1"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#ejemplo-2",
    "href": "posts/pyr1/Py_R_1.html#ejemplo-2",
    "title": "R + Python: I",
    "section": "Ejemplo 2",
    "text": "Ejemplo 2\n\nCódigow = np.arange(0, 50).reshape(5, 10)\nw\n\narray([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])\n\n\n\nCódigog2 = plt.imshow(w)\ng2 = plt.colorbar()\nplt.show()"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#ejemplo-3",
    "href": "posts/pyr1/Py_R_1.html#ejemplo-3",
    "title": "R + Python: I",
    "section": "Ejemplo 3",
    "text": "Ejemplo 3\n\nGráfico desde un Dataframe:\n\n\nCódigog3 = iris_py.plot(x = \"Sepal.Length\", y = \"Sepal.Width\", kind = \"scatter\",\n                  color = \"red\")                 \ng3"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#importando-módulos-de-python-1",
    "href": "posts/pyr1/Py_R_1.html#importando-módulos-de-python-1",
    "title": "R + Python: I",
    "section": "Importando módulos de python\n",
    "text": "Importando módulos de python\n\n\nCódigoimport pandas as pd\nimport sklearn\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import train_test_split \nfrom sklearn import metrics"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#cargando-datos",
    "href": "posts/pyr1/Py_R_1.html#cargando-datos",
    "title": "R + Python: I",
    "section": "Cargando datos",
    "text": "Cargando datos\n\nCódigocol_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree',\n             'age', 'label']\n# load dataset\npima = pd.read_csv(\"diabetes.csv\", header=None, names=col_names)\npima = pima[1:]\npima.head()\n\n  pregnant glucose  bp skin insulin   bmi pedigree age label\n1        6     148  72   35       0  33.6    0.627  50     1\n2        1      85  66   29       0  26.6    0.351  31     0\n3        8     183  64    0       0  23.3    0.672  32     1\n4        1      89  66   23      94  28.1    0.167  21     0\n5        0     137  40   35     168  43.1    2.288  33     1"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#selección-de-características",
    "href": "posts/pyr1/Py_R_1.html#selección-de-características",
    "title": "R + Python: I",
    "section": "Selección de características",
    "text": "Selección de características\n\nCódigo# Fraccionando la base de datos en predictoras (X) y respuesta (Y)\nfeature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\nX = pima[feature_cols] \ny = pima.label"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#train---test",
    "href": "posts/pyr1/Py_R_1.html#train---test",
    "title": "R + Python: I",
    "section": "Train - Test",
    "text": "Train - Test\n\nCódigoX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#construyendo-modelo",
    "href": "posts/pyr1/Py_R_1.html#construyendo-modelo",
    "title": "R + Python: I",
    "section": "Construyendo Modelo",
    "text": "Construyendo Modelo\n\nCódigo# Clasificador\nclf = DecisionTreeClassifier()\n\n# Clasificador en train --> Entrenando modelo\nclf_fit = clf.fit(X = X_train, y = y_train)"
  },
  {
    "objectID": "posts/pyr1/Py_R_1.html#evaluación-del-modelo",
    "href": "posts/pyr1/Py_R_1.html#evaluación-del-modelo",
    "title": "R + Python: I",
    "section": "Evaluación del modelo",
    "text": "Evaluación del modelo\n\nCódigo# Predicciones\ny_pred = clf_fit.predict(X_test)\nprint(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n\nAccuracy: 0.6753246753246753"
  },
  {
    "objectID": "posts/tree_decision/TreeD_R.html#generalidades",
    "href": "posts/tree_decision/TreeD_R.html#generalidades",
    "title": "Árbol de clasificación con R",
    "section": "Generalidades",
    "text": "Generalidades\n\n\n\n\nLos árboles de decisión se pueden utilizar para problemas de regresión y clasificación.\nSe pueden definir como una estructura jerárquica que busca particionar el espacio de características e identificar subconjuntos representativos. Desde la parte superior a inferior cada árbol tiene nodo raíz, nodos de decisión o internos y nodos hojas o terminales, los dos primeros se generan con base en reglas binarias. Mayor grado de pureza es la recompensa que busca el algoritmo al particionar el espacio inicial en subregiones, en ese orden de ideas el objetivo siempre será particionar los datos en nodos que sean lo más puros posible, sin embargo, matemáticamente es más fácil medir la impureza de una región específica, proporcionando una idea de qué tan heterogéneas son las clases en ese nodo; una métrica de uso común en problemas de clasificación para medir la impureza es el índice GINI, donde valores bajos indican mayor grado de pureza. Además del índice GINI también es posible utilizar otras métricas como la ganancia de información o la entropía.\n\nVentajas:\n\nFácil de interpretar (sujeto a la profundidad).\nNo requieren estandarización o normalización de variables predictoras numéricas.\nPermiten manipular variables categóricas sin necesidad de aplicar codificaciones tipo one-hot o variables dummy.\nRequieren poco preprocesamiento de datos.\nPermiten valores ausentes (NA).\nPermite relaciones no lineales.\n\n\n\nDesventajas:\n\nSi no se controla adecuadamente la profundidad del árbol existe alta probabilidad de incurrir en sobreajuste (overfitting).\n\nAlta varianza, pequeños cambios en los datos pueden arrojar resultados muy diferentes.\n\n\n\nHiperparámetros: aunque ejecutar la función rpart() con valores predeterminados puede ser una buena estrategia para iniciar, siempre estaremos interesados en ajustar determinados parámetros que nos permitan obtener mejor rendimiento predictivo. La función rpart.control() permite controlar manualmente otras opciones. Dentro los hiperparámetros más importantes en árboles de decisión están los siguientes:\n\nMínimo número de observaciones para generar una partición. En la biblioteca rpart lleva el nombre de minsplit y su valor por defecto es 20.\nMáxima profundiad del árbol. En la biblioteca rpart lleva el nombre de maxdepth y su valor predeterminado es 30. Este parámetro es de alta relevancia para evitar el sobreajuste.\nParámetro de complejidad. En la biblioteca rpart lleva el nombre de cp y su valor por defecto es 0.01. Este parámetro sirve al propósito de penalizar y contolar el tamaño del árbol, valores bajos indican árboles de mayor complejidad, es decir, mayor número de divisiones. La función rpart() internamente ejecuta validación cruzada 10 veces para estimar el valor óptimo de cp, es posible acceder a dicho resultado a través de la función plotcp() que permitirá facilmente determinar el valor adecuado para este parámetro. Cuando se tiene el valor óptimo de cp será posible “podar” el árbol para que el modelo sea optimizado, dicho resultado es posible a través de la función prune()."
  },
  {
    "objectID": "posts/tree_decision/TreeD_R.html#train---test",
    "href": "posts/tree_decision/TreeD_R.html#train---test",
    "title": "Árbol de clasificación con R",
    "section": "Train - Test",
    "text": "Train - Test\n\nPara entrenar el modelo inicialmente fracciono los datos en train y test con proporciones de 70 y 30%, respectivamente. Este proceso aunque es posible hacerlo manualmente con la función sample(), la función createDataPartition() del paquete caret agiliza el procedimiento. Para garantizar replicabilidad en los resultados se agrega la semilla.\n\n\nCódigoset.seed(1992)\nidx <- createDataPartition(y = data$class, times = 1, p = 0.70, list = FALSE)\ndataTrain <- data[idx, ]\ndataTest <- data[-idx, ]"
  },
  {
    "objectID": "posts/tree_decision/TreeD_R.html#rpart-default",
    "href": "posts/tree_decision/TreeD_R.html#rpart-default",
    "title": "Árbol de clasificación con R",
    "section": "\nrpart default\n",
    "text": "rpart default\n\n\n\nAjuste del modelo: en este caso se utilizan todas las variables predictoras para entrenar el modelo. Al imprimir el objeto que contiene el modelo podemos observar el conjunto de reglas que dan como resultado la estructura final del árbol. El método igualado a method = \"class\" indica que es un problema de clasificación, si fuese un problema de regresión el argumento tomaría el valor de method = \"anova\", aunque también permite otras opciones (consulte ?rpart o help(\"rpart\")).\n\n\nCódigomodArbol0 <- rpart(class ~ ., data = dataTrain, method = \"class\")\nmodArbol0\n\nn= 700 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 700 210 good (0.3000000 0.7000000)  \n    2) checking_status=<0,0<=X<200 385 168 good (0.4363636 0.5636364)  \n      4) credit_history=all paid,no credits/all paid 51  14 bad (0.7254902 0.2745098)  \n        8) savings_status=<100,100<=X<500 42   8 bad (0.8095238 0.1904762) *\n        9) savings_status=500<=X<1000,no known savings 9   3 good (0.3333333 0.6666667) *\n      5) credit_history=critical/other existing credit,delayed previously,existing paid 334 131 good (0.3922156 0.6077844)  \n       10) duration>=27.5 77  30 bad (0.6103896 0.3896104)  \n         20) purpose=domestic appliance,education,furniture/equipment,new car 39  10 bad (0.7435897 0.2564103) *\n         21) purpose=business,other,radio/tv,repairs,used car 38  18 good (0.4736842 0.5263158)  \n           42) checking_status=<0 19   7 bad (0.6315789 0.3684211) *\n           43) checking_status=0<=X<200 19   6 good (0.3157895 0.6842105) *\n       11) duration< 27.5 257  84 good (0.3268482 0.6731518)  \n         22) purpose=domestic appliance,education,new car,retraining 83  41 good (0.4939759 0.5060241)  \n           44) age< 35.5 42  13 bad (0.6904762 0.3095238)  \n             88) credit_amount< 1392 20   1 bad (0.9500000 0.0500000) *\n             89) credit_amount>=1392 22  10 good (0.4545455 0.5454545)  \n              178) property_magnitude=life insurance,real estate 13   4 bad (0.6923077 0.3076923) *\n              179) property_magnitude=car,no known property 9   1 good (0.1111111 0.8888889) *\n           45) age>=35.5 41  12 good (0.2926829 0.7073171) *\n         23) purpose=business,furniture/equipment,other,radio/tv,repairs,used car 174  43 good (0.2471264 0.7528736) *\n    3) checking_status=>=200,no checking 315  42 good (0.1333333 0.8666667) *\n\n\n\n\nGráfico del modelo: la variable más importante y que da origen al nodo raíz es checking_status, que hace referencia al estado de la cuenta corriente. El historial crediticio, la duración del tiempo para pagar el crédito, el estado de la cuenta de ahorros y el propósito del crédito, también son factores determinantes. No tener suficiente capital en cualquiera de las dos cuentas, tener mal historial crediticio y además solicitar períodos de pago de alta duración, pueden ser características no deseables a la hora de solicitar un crédito.\n\n\nCódigorpart.plot(modArbol0)\n\n\n\n\n\n\n\n\n\nMatriz de confusión: el modelo por default tiene precisión promedio de 0.7167, con dificultades para clasificar de forma correcta los “malos”, es decir, que tiene baja especificidad.\n\n\nCódigopredichos_mod0 <- predict(object = modArbol0, newdata = dataTest, type = \"class\")\nconfusionMatrix(data = predichos_mod0, reference = as.factor(dataTest$class),\n                positive = \"good\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction bad good\n      bad   31   26\n      good  59  184\n                                        \n               Accuracy : 0.7167        \n                 95% CI : (0.662, 0.767)\n    No Information Rate : 0.7           \n    P-Value [Acc > NIR] : 0.2873596     \n                                        \n                  Kappa : 0.2465        \n                                        \n Mcnemar's Test P-Value : 0.0005187     \n                                        \n            Sensitivity : 0.8762        \n            Specificity : 0.3444        \n         Pos Pred Value : 0.7572        \n         Neg Pred Value : 0.5439        \n             Prevalence : 0.7000        \n         Detection Rate : 0.6133        \n   Detection Prevalence : 0.8100        \n      Balanced Accuracy : 0.6103        \n                                        \n       'Positive' Class : good          \n                                        \n\n\n\nÁrea bajo la curva:\n\n\nCódigo# Probabilidades predichas para la clase \"good\"\npred0 <- as.data.frame(predict(object = modArbol0,\n                               newdata = dataTest, type = \"prob\"))$good\n\n# Transformando respuesta a entero. A la clase \"good\" le agrego 1 y \n# a la clase \"bad\" le agrego 0.\ntarget <- as.integer(as.factor(dataTest$class)) - 1\n\n# AUC\nMetrics::auc(actual = target, predicted = pred0)\n\n[1] 0.7034392\n\n\n\n\nCurva ROC: la función con la que obtengo el siguiente gráfico puede ser encontrada en mi Github.\n\n\n\nCódigo# Cargando funciónn\nsource(\"functions/myROC.R\")\n\n# Ver función myROC() al final en material complementario     \nmyROC(predichos = pred0, reales = target)\n\n\n\n\n\n\n\n\nParámetro de complejidad (CP):\n\n\nCódigoplotcp(modArbol0)\n\n\n\n\n\n\n\n\n\n“Podando” el árbol: se elige el valor de cp = 0.025 por mostrar mejores resultados (bajo error).\n\n\nCódigomodArbol0_prune <- prune(tree = modArbol0, cp = 0.025)\nmodArbol0_prune\n\nn= 700 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 700 210 good (0.3000000 0.7000000)  \n   2) checking_status=<0,0<=X<200 385 168 good (0.4363636 0.5636364)  \n     4) credit_history=all paid,no credits/all paid 51  14 bad (0.7254902 0.2745098) *\n     5) credit_history=critical/other existing credit,delayed previously,existing paid 334 131 good (0.3922156 0.6077844)  \n      10) duration>=27.5 77  30 bad (0.6103896 0.3896104) *\n      11) duration< 27.5 257  84 good (0.3268482 0.6731518)  \n        22) purpose=domestic appliance,education,new car,retraining 83  41 good (0.4939759 0.5060241)  \n          44) age< 35.5 42  13 bad (0.6904762 0.3095238) *\n          45) age>=35.5 41  12 good (0.2926829 0.7073171) *\n        23) purpose=business,furniture/equipment,other,radio/tv,repairs,used car 174  43 good (0.2471264 0.7528736) *\n   3) checking_status=>=200,no checking 315  42 good (0.1333333 0.8666667) *\n\n\n\nGráfico de árbol con “poda”:\n\n\nCódigorpart.plot(modArbol0_prune)\n\n\n\n\n\n\n\n\n\nMatriz de confusión árbol con “poda”: respecto al árbol sin podar, la diferencia en precisión es muy pequeña (<0.01), sin embargo, la especificidad se aumenta de 0.3444 a 0.4556 con la “poda”, aunque la sensitividad haya reducido de 0.8762 a 0.8381.\n\n\nCódigopredichos_mod0_prune <- predict(object = modArbol0_prune, newdata = dataTest, type = \"class\")\nconfusionMatrix(data = predichos_mod0_prune, reference = as.factor(dataTest$class),\n                positive = \"good\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction bad good\n      bad   41   34\n      good  49  176\n                                         \n               Accuracy : 0.7233         \n                 95% CI : (0.669, 0.7732)\n    No Information Rate : 0.7            \n    P-Value [Acc > NIR] : 0.2072         \n                                         \n                  Kappa : 0.3083         \n                                         \n Mcnemar's Test P-Value : 0.1244         \n                                         \n            Sensitivity : 0.8381         \n            Specificity : 0.4556         \n         Pos Pred Value : 0.7822         \n         Neg Pred Value : 0.5467         \n             Prevalence : 0.7000         \n         Detection Rate : 0.5867         \n   Detection Prevalence : 0.7500         \n      Balanced Accuracy : 0.6468         \n                                         \n       'Positive' Class : good           \n                                         \n\n\n\nÁrea bajo la curva de árbol con “poda”:\n\n\nCódigo# Probabilidades predichas para la clase \"good\"\npred0_prune <- as.data.frame(predict(object = modArbol0_prune,\n                                     newdata = dataTest, type = \"prob\"))$good\n\n# AUC\nMetrics::auc(actual = target, predicted = pred0_prune)\n\n[1] 0.7203175\n\n\n\nCurva ROC:\n\n\nCódigo# Ver función myROC() al final en material complementario     \nmyROC(predichos = pred0_prune, reales = target)"
  },
  {
    "objectID": "posts/tree_decision/TreeD_R.html#tuning-con-caret",
    "href": "posts/tree_decision/TreeD_R.html#tuning-con-caret",
    "title": "Árbol de clasificación con R",
    "section": "Tuning con caret",
    "text": "Tuning con caret\n\nA diferencia de los parámetros que se “aprenden” duarante el entrenamiento del modelo, los hipeparámetros se definen previo al ajuste del mismo.\nEl ajuste de hiperparámetros se constituye como parte fundamental de la optimización del modelo.\nLa biblioteca caret proporciona un marco de trabajo unificado para entrenar y validar modelos de machine learning. En este caso, con caret podremos ajustar dos de los tres hiperparámetros mencionados anteriormente, el parámetro de complejidad y la profundidad del árbol. Las funciones trainControl() y train de la biblioteca caret facilitan el proceso.\n\n\ntrainControl(): permite establecer la estrategia de validación, por ejemplo validación cruzada k-fold, validación cruzada repetida, bootstrapping, entre otras. Desde esta misma función también es posible determinar el método de búsqueda de hiperparámetros, que puede ser aleatoria o cuadrícula (grid). En este caso particular utilizo validación cruzada con repeticiones, con k = 5 y 3 repeticiones. El argumento summaryFunction = twoClassSummary permite computar las métricas necesarias (sensitividad y especificidad) para obtener ROC. Busque más ayuda con help(\"trainControl\").\n\ntrain(): ajuste el modelo estableciendo la fórmula habitual en R, el método o algoritmo para entrenar, (lista de algoritmos en caret) los datos, la configuración para el entrenamiento (tcConrol = myControl) y la longitud de hiperparámetros a considerar en el entrenamiento (tuneLenth). Este último argumento dependerá de los hiperparámetros que estén disponibles en caret, aunque también es posible asignarlos manualmente a través de expand.grid(). Utilizar el método igualado a “rpart” permitirá optimizar el parámetro cp y utilizando “rpart2” es posible optimizar la máxima profundidad del árbol. Cuando se declara tuneLength = 5 se informa que el número máximo de profundidades a probar será 5, es decir, que al final existirán 5 resultados diferentes con el mismo algoritmo. Por último, se agrega la métrica que será utilizada para comparar los resultados de la validación cruzada.\n\n\n\nNota: como el procedimiento de validación cruzada implica muestreo aleatorio, es necesario asignar la semilla para garantizar replicabilidad de resultados.\n\n\nCódigomyControl <- trainControl(method = \"repeatedcv\",\n                          number = 5,\n                          repeats = 3,\n                          classProbs = TRUE,  # Permite predecir probabilidades\n                          summaryFunction = twoClassSummary) \nset.seed(1992)\nmodArbol_tune <- train(class ~ .,\n                       method = \"rpart2\",\n                       data = data,\n                       trControl = myControl,\n                       tuneLength = 5,\n                       metric = \"ROC\")\nmodArbol_tune\n\nCART \n\n1000 samples\n  20 predictor\n   2 classes: 'bad', 'good' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold, repeated 3 times) \nSummary of sample sizes: 800, 800, 800, 800, 800, 800, ... \nResampling results across tuning parameters:\n\n  maxdepth  ROC        Sens       Spec     \n   3        0.7028968  0.3011111  0.8885714\n   6        0.7138095  0.3244444  0.8880952\n  11        0.7211151  0.3988889  0.8642857\n  14        0.7213571  0.4055556  0.8623810\n  18        0.7211746  0.3911111  0.8671429\n\nROC was used to select the optimal model using the largest value.\nThe final value used for the model was maxdepth = 14.\n\n\n\nSe observa que la mejor profundidad es 14 con la mayor sensitividad aún cuando no tiene la mejor especificidad. A continuación la matriz de confusión en el conjunto de test muestra mejoras en la capacidad de detectar los clasificados como “malos”, ademas la precisión es notablemente superior.\n\n\nCódigopredichos_tune <- predict(object = modArbol_tune, newdata = dataTest, type = \"raw\")\nconfusionMatrix(data = predichos_tune, reference = as.factor(dataTest$class),\n                positive = \"good\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction bad good\n      bad   52   29\n      good  38  181\n                                          \n               Accuracy : 0.7767          \n                 95% CI : (0.7253, 0.8225)\n    No Information Rate : 0.7             \n    P-Value [Acc > NIR] : 0.001839        \n                                          \n                  Kappa : 0.4526          \n                                          \n Mcnemar's Test P-Value : 0.328393        \n                                          \n            Sensitivity : 0.8619          \n            Specificity : 0.5778          \n         Pos Pred Value : 0.8265          \n         Neg Pred Value : 0.6420          \n             Prevalence : 0.7000          \n         Detection Rate : 0.6033          \n   Detection Prevalence : 0.7300          \n      Balanced Accuracy : 0.7198          \n                                          \n       'Positive' Class : good            \n                                          \n\n\n\n\nÁrea bajo la curva el modelo evidentemente consigue mejores resultados respecto a los ajustados inicialmente, de tal manera que el ajuste de hiperparámetros ha logrado mejorar nuestras predicciones en datos que el modelo aún no ha visto. Posiblemente el hecho de ajustar la máxima profundidad sumado al uso de validación cruzada, permite que el modelo capture de mejor manera las relaciones subyacentes entre características.\n\n\nCódigo# Probabilidades predichas para la clase \"good\"\npred_tune <- as.data.frame(predict(object = modArbol_tune,\n                                   newdata = dataTest, type = \"prob\"))$good\n\n# AUC\nMetrics::auc(actual = target, predicted = pred_tune)\n\n[1] 0.7888624\n\n\n\nCurva ROC:\n\n\nCódigo# Ver función myROC() al final en material complementario     \nmyROC(predichos = pred_tune, reales = target)"
  },
  {
    "objectID": "posts/tree_decision/TreeD_R.html#función-plot-caret",
    "href": "posts/tree_decision/TreeD_R.html#función-plot-caret",
    "title": "Árbol de clasificación con R",
    "section": "Función plot + caret\n",
    "text": "Función plot + caret\n\n\nLa función plot() tiene un método específico para resultados obtenidos a través de caret, en este caso muestra el gráfico del hiperparámetro de interés, la máxima profundidad del árbol vs la curva ROC en el eje Y, tratando de evidenicar el valor óptimo.\n\n\nCódigoplot(modArbol_tune)"
  },
  {
    "objectID": "posts/tree_decision/TreeD_R.html#gráfico-interactivo-con-visnetwork",
    "href": "posts/tree_decision/TreeD_R.html#gráfico-interactivo-con-visnetwork",
    "title": "Árbol de clasificación con R",
    "section": "Gráfico interactivo con visNetwork\n",
    "text": "Gráfico interactivo con visNetwork\n\n\nLa biblioteca visNetwork permite crear gráficos interactivos para objetos de la clase rpart. A manera de ejemplo se presenta el gráfico para el árbol de decisión con poda. Recuerde que es interactivo y puede manipularlo con el mouse.\n\n\nCódigolibrary(visNetwork)\nvisTree(modArbol0_prune, \n        main = \"Árbol con poda\"\", width==\"100%\"\",\n        height = \"800px\",  edgesFontSize = 14, nodesFontSize = 16,)"
  },
  {
    "objectID": "posts/tree_decision/TreeD_R.html#función-myroc",
    "href": "posts/tree_decision/TreeD_R.html#función-myroc",
    "title": "Árbol de clasificación con R",
    "section": "Función myROC()\n",
    "text": "Función myROC()\n\n\nEs necesario tener cargadas las bibliotecaS dplyr, ggplot2, hrbrthemes, Metrics y pROC para ejecutar la función.\n\n\nCódigomyROC <- function(predichos, reales) {\n  suppressMessages(suppressWarnings(library(dplyr)))\n  suppressMessages(suppressWarnings(library(ggplot2)))\n  suppressMessages(suppressWarnings(library(pROC)))\n  suppressMessages(suppressWarnings(library(Metrics)))\n  x = roc(reales, predichos)\n  df = data_frame(TPR = x$sensitivities,\n                  FPR = 1 - x$specificities)\n  gg = df %>%\n    ggplot(aes(x = FPR, ymin = 0, ymax = TPR)) +\n    geom_polygon(aes(y = TPR), fill = \"#5A5156\", alpha = 0.7) +\n    geom_path(aes(y = TPR), col = \"#F6222E\", size = 1.3) +\n    geom_abline(\n      intercept = 0,\n      slope = 1,\n      color = \"gray37\",\n      size = 1,\n      linetype = \"dashed\"\n    ) +\n    theme_ipsum() +\n    coord_equal() +\n    labs(\n      x = \"FPR (1 - Especificidad)\",\n      y = \"TPR (Sensitividad)\",\n      title = paste0(\"Curva ROC\"),\n      subtitle = paste0(\n        \"Valor AUC: \",\n        Metrics::auc(actual = reales,\n                     predicted = predichos) %>% round(4)\n      )\n    )\n  return(gg)\n}"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html",
    "href": "posts/XGBoost_R/XGBoost_R.html",
    "title": "XGBoost con R",
    "section": "",
    "text": "Documentación oficial xgboost\nBiblioteca xgboost en R\nTutorial de xgboost en R"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#detección-de-mastitis",
    "href": "posts/XGBoost_R/XGBoost_R.html#detección-de-mastitis",
    "title": "XGBoost con R",
    "section": "Detección de mastitis",
    "text": "Detección de mastitis\n\nArtículo publicado en PLOS ONE"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#base-de-datos",
    "href": "posts/XGBoost_R/XGBoost_R.html#base-de-datos",
    "title": "XGBoost con R",
    "section": "Base de datos",
    "text": "Base de datos\n\nCódigomastitis <- read_csv(\"data/mastitis.csv\") %>% \n  clean_names() %>% \n  filter(diagnosis %in% c(\"EDP\", \"EL\"))\n\nmastitis %>% \n  select(diagnosis, 1:5) %>%\n  head() %>%\n  kable(caption = \"6 primeras filas de la base de datos con 6 columnas\")\n\n\n6 primeras filas de la base de datos con 6 columnas\n\n\n\n\n\n\n\n\n\ndiagnosis\nquarter_dates_q0\nno_recordings_q0\nl_1_q0_bmscc_000_cells_ml\nl_1_q0_percent_chronic\nl_1_q0_percent_200k\n\n\n\nEDP\n06/10/2009\n0\n0\n0.0\n0.0\n\n\nEDP\n06/12/2009\n3\n284\n27.8\n40.6\n\n\nEL\n20/04/2012\n0\n0\n0.0\n0.0\n\n\nEL\n16/07/2009\n3\n222\n21.1\n26.3\n\n\nEL\n16/10/2013\n3\n251\n27.5\n34.3\n\n\nEDP\n12/01/2013\n3\n154\n12.3\n17.0"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#análisis-exploratorio",
    "href": "posts/XGBoost_R/XGBoost_R.html#análisis-exploratorio",
    "title": "XGBoost con R",
    "section": "Análisis exploratorio",
    "text": "Análisis exploratorio\n\nFrecuencia absoluta para niveles de la variable respuesta.\n\n\nCódigomastitis %>% \n  count(diagnosis) %>% \n  ggplot(aes(x = diagnosis, y = n)) +\n  geom_col(color = \"dodgerblue3\", fill = \"dodgerblue3\", alpha = 0.8) +\n  geom_label(aes(label = n)) +\n  labs(x = \"Diagnóstico\"\", y==\"Frecuencia\"))\n\n\n\nFrecuencia absoluta de variable respuesta\n\n\n\n\n\nDistribuciones de algunas variables numéricas: como el número de variables es alto, selecciono al azar 8 de ellas para construir el gráfico.\n\n\nCódigo# Números al azarr\nset.seed(1992)\nvariables_azar <- sample(x = 228, size = 8, replace = FALSE)\n\nmastitis %>% \n  select(diagnosis, variables_azar) %>% \n  pivot_longer(cols = -diagnosis) %>% \n  ggplot(aes(x = value, fill = diagnosis, color = diagnosis)) +\n  facet_wrap(~name, scales = \"free\", ncol = 4) +\n  geom_density(alpha = 0.8) +\n  scale_x_log10() +\n  scale_color_jama() +\n  scale_fill_jama() +\n  labs(x = \"\", y = \"Densidad\", color = \"Diagnóstico\"\",\n       fill = \"Diagnóstico\"))\n\n\n\nDensidades de 8 variables al azar (transformación con logaritmo en base 10)\n\n\n\n\n\nVerificamos si existen valores ausentes. Se observan algunas filas con valores NA.\n\n\nCódigovis_miss(mastitis)\n\n\n\nValores ausentes en el conjunto de datos\n\n\n\n\n\nCon la finalidad de evidenciar si existe algún patrón de asociación subyacente en el total de variables, se realizó análisis de componentes principales y se grafican los dos primeros componentes. No existe algún comportamiento de agrupación al reducir la dimensión a los dos primeros componentes. Se observó que la retención de variabilidad de estas dos coordenadas apenas alcanzó el 30% aproximadamente.\n\n\nCódigo# Análisis de componentes principaless\ndatos_pca <- mastitis\npca <- PCA(X = datos_pca %>%\n             select(where(is.numeric)),\n           scale.unit = TRUE,\n           graph = FALSE)\n\n# Agregando componentes a la base de datos\ndatos_pca$cp1 <- pca$ind$coord[, 1]\ndatos_pca$cp2 <- pca$ind$coord[, 2]\n\n# Gráfico de las 2 primeras componentess\ndatos_pca %>% \n  ggplot(aes(x = cp1, y = cp2, color = diagnosis)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"black\", linetype = 2) +\n  geom_vline(xintercept = 0, color = \"black\", linetype = 2) +\n  scale_color_jama() +\n  labs(x = \"CP1 (15.74 %)\", y = \"CP2 (14.09 %)\", color = \"Diagnóstico\"))\n\n\n\nComponente principal 1 vs componente principal 2\n\n\n\n\n\nLos resultados exploratorios sugieren cuatro cosas importantes:\n\nEl problema de clasificación bajo análisis podría ser denominado de clases balanceadas, ya que las frecuencias absolutas son similares para cada nivel a predecir.\nAlgunas variables predictoras no tienen comportamiento gaussiano. Parte de la estrategia del análisis, en estos casos, podría ser la implementación de algún tipo de transformación previo al entrenamiento de los modelos, no obstante, este paso no se aplicará dada la robustez que presenta el algoritmo XGBoost frente a distribuciones asimétricas.\nExisten observaciones con valores ausentes para una o más variables. Algunos algoritmos como la regresión logística o los bosques aleatorios, no permiten la inclusión de valores NA al entrenar los modelos, sin embargo, con XGBoost no existe este inconveniente, puesto que soporta valores vacíos.\nEl análisis de componentes principales no muestra alguna tendencia de agrupación entre las clases evaluadas. La retención de variabilidad de las tres primeras componentes no supera el 50%, resultado que podría sugerir que las relaciones de tipo lineal no son plausibles en este conjunto de datos."
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#train-y-test",
    "href": "posts/XGBoost_R/XGBoost_R.html#train-y-test",
    "title": "XGBoost con R",
    "section": "Train y Test",
    "text": "Train y Test\n\nEn este ejemplo los datos fueron divididos en train y test con proporciones de 80 y 20 %, respectivamente. Se utiliza muestreo estratificado en función de la variable respuesta. Se eliminaron 4 variables que tienen información de fechas; aunque podrían ser tratadas de alguna manera especial, en este caso no fueron tenidas en cuenta.\nLa biblioteca rsample permite realizar la división.\n\n\nCódigo# Variables fechas\nvariables_fechas <- mastitis %>% \n  select(is.character, -diagnosis) %>% \n  names()\n\n# Datos para modelos\ndata_modelos <- mastitis %>% select(-variables_fechas)\n\nset.seed(1992)\nparticiones <- initial_split(data = data_modelos, prop = 0.80, strata = diagnosis)\ntrain <- training(particiones)\ntest <- testing(particiones)\n\n\n\nPodemos ver el objeto particiones que proporciona información de la partición de datos. Los modelos son entrenados con 733 observaciones y con 181 se evalúa el desempeño de los mismos.\n\n\nCódigoparticiones\n\n<Training/Testing/Total>\n<731/183/914>"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#validación-cruzada",
    "href": "posts/XGBoost_R/XGBoost_R.html#validación-cruzada",
    "title": "XGBoost con R",
    "section": "Validación cruzada",
    "text": "Validación cruzada\n\nSe utiliza validación cruzada k-fold con \\(k = 10\\).\nLa biblioteca rsample permite configurar diferentes métodos de validación cruzada.\n\n\nCódigoset.seed(1992)\nconfig_cv <- vfold_cv(data = train, v = 10)"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#preprocesamiento",
    "href": "posts/XGBoost_R/XGBoost_R.html#preprocesamiento",
    "title": "XGBoost con R",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\n\nEn este ejemplo no se hará énfasis en las estrategias de preprocesamiento o ingeniería de características, sin embargo, serán comparados algoritmos con imputación de valores ausentes (con método k vecinos más cercanos) respecto a algoritmos sin imputación.\nLa biblioteca recipes permite realizar múltiples tareas de preprocesamiento e ingeniería de características.\n\n\nCódigono_impute <- recipe(diagnosis ~ ., data = train)\nsi_impute <- recipe(diagnosis ~ ., data = train) %>% \n  step_impute_knn(all_predictors())"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#modelo-xgboost",
    "href": "posts/XGBoost_R/XGBoost_R.html#modelo-xgboost",
    "title": "XGBoost con R",
    "section": "Modelo XGBoost",
    "text": "Modelo XGBoost\n\nEl algoritmo XGboost tiene múltiples hiperparámetros que pueden ser sintonizados, sin embargo, en este ejemplo sólo ser hará tuning sobre los siguientes:\n\n\nmtry: número de predictores que se muestrearán aleatoriamente en cada división al crear los modelos.\n\nmin_n: número mínimo de observaciones requeridas en un nodo para que se produzca la división.\n\ntree_depth: profundidad máxima del árbol (número de divisiones).\n\n\nEl número de árboles (trees) se estableció en 1000.\nLa tasa de aprendizaje (learn_rate) se estableció en 0.1.\nLa proporción de observaciones muestreadas (sample_size) en cada rutina de ajuste se estableció en 0.8.\nLos demás hiperparámetros se mantienen por defecto.\nPara más información acerca de los hiperparámetros que permite ajustar parsnip, consultar este enlace.\n\n\n\nCódigomodelo_xgboost <- boost_tree(mtry = tune(),\n                             min_n = tune(),\n                             tree_depth = tune(),\n                             trees = 1000,\n                             learn_rate = 0.1,\n                             sample_size = 0.8) %>% \n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#flujos-de-trabajo-pipelines",
    "href": "posts/XGBoost_R/XGBoost_R.html#flujos-de-trabajo-pipelines",
    "title": "XGBoost con R",
    "section": "Flujos de trabajo (pipelines)",
    "text": "Flujos de trabajo (pipelines)\n\nLos flujos de trabajo son una manera flexible de trabajar con tidymodels. Se fundamenta en la misma idea de los pipelines de scikit-learn de Python. Es posible construir nuestro flujo de trabajo con recetas y modelos declarados previamente.\nConsultar más información de la biblioteca workflows.\nFlujo de trabajo sin imputación:\n\n\nCódigowf_no_impute <- workflow() %>% \n  add_recipe(no_impute) %>% \n  add_model(modelo_xgboost)\n\n\n\nFlujo de trabajo con imputación:\n\n\nCódigowf_si_impute <- workflow() %>% \n  add_recipe(si_impute) %>% \n  add_model(modelo_xgboost)"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#grid",
    "href": "posts/XGBoost_R/XGBoost_R.html#grid",
    "title": "XGBoost con R",
    "section": "Grid",
    "text": "Grid\n\nEn este caso se utiliza la cuadrícula a través de diseños de llenado de espacio (space-filling designs), los cuales intentan encontrar una configuración de puntos (combinaciones) que cubren el espacio de parámetros con menor probabilidad de valores que se traslapan. Para este ejemplo el tamaño de la cuadrícula fue de 10.\nPara este caso particular se usan diseños de máxima entropía, descritos en el año 1987 por Shewry y Wynn en el artículo “Maximum Entropy Sampling”. También podrían ser implementados diseños de hipercubos latinos o diseños de proyección máxima. Si no se desea utilizar alguno de estos métodos, podría ser implementada una cuadrícula regular a través de métodos aleatorios (grid random).\nMayor información en la página web de la biblioteca dials.\n\n\n\nCódigo# Parámetros para tuningg\nparams_xgb <- parameters(\n  finalize(mtry(), x = train[, -1]),\n  min_n(range = c(2L, 50L)),\n  tree_depth(range = c(3L, 8L))\n)\n\n# Grid\nset.seed(2021)\ngrid_xgb <- params_xgb %>% \n  grid_max_entropy(size = 10)\n\n\n\nA continuación se muestra la cuadrícula de búsqueda de los mejores hiperparámetros. Se evidencia que los puntos no se solapan, de tal manera que el espacio de búsqueda no es redundante.\n\n\nCódigogrid_xgb %>% \n  ggplot(aes(x = .panel_x, y = .panel_y)) +\n  facet_matrix(vars(mtry, min_n, tree_depth), layer.diag = 2) +\n  geom_point()\n\n\n\nCuadrícula de tamaño 10 con método de máxima entropía"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#tuning-con-tidymodels",
    "href": "posts/XGBoost_R/XGBoost_R.html#tuning-con-tidymodels",
    "title": "XGBoost con R",
    "section": "Tuning con tidymodels\n",
    "text": "Tuning con tidymodels\n\n\nLa función tune_grid() de la biblioteca tune permite evaluar los modelos con cada combinación de paramétros establecidos previamente en la cuadrícula.\nTuning sin imputación:\n\n\nCódigoregisterDoParallel(parallel::detectCores() - 1) # Inicio Paralelizaciónn\n\nset.seed(2021)\ntuned_no_impute <- tune_grid(\n  object = wf_no_impute,\n  resamples = config_cv,\n  grid = grid_xgb\n)\n\nstopImplicitCluster() # Fin Paralelizaciónn\n\n\n\nTuning con imputación:\n\n\nCódigoregisterDoParallel(parallel::detectCores() - 1) # Inicio Paralelizaciónn\n\nset.seed(2021)\ntuned_si_impute <- tune_grid(\n  object = wf_si_impute,\n  resamples = config_cv,\n  grid = grid_xgb\n)\n\nstopImplicitCluster() # Fin Paralelizaciónn"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#resultados-accuracy",
    "href": "posts/XGBoost_R/XGBoost_R.html#resultados-accuracy",
    "title": "XGBoost con R",
    "section": "Resultados Accuracy\n",
    "text": "Resultados Accuracy\n\n\nResultados de Accuracy en modelos sin imputación. La precisión más alta se consigue con aproximadamente 150 variables (mtry), menos de 10 observaciones para que se produzca la división del árbol (min_n) y profunidad de más o menos 6 (tree_depth).\n\n\nCódigotuned_no_impute %>% \n  collect_metrics() %>% \n  filter(.metric == \"accuracy\") %>% \n  ggplot(aes(x = mtry, y = min_n, size = tree_depth, color = mean)) +\n  geom_point() +\n  scale_color_viridis_c() +\n  labs(color = \"Accuracy\")\n\n\n\n\n\nResultados de Accuracy en modelos con imputación. La precisión más alta se consigue con aproximadamente 25 variables (mtry), poco menos de 50 observaciones para que se produzca la división del árbol (min_n) y profunidad de más o menos 4 (tree_depth).\n\n\nCódigotuned_si_impute %>% \n  collect_metrics() %>% \n  filter(.metric == \"accuracy\") %>% \n  ggplot(aes(x = mtry, y = min_n, size = tree_depth, color = mean)) +\n  geom_point() +\n  scale_color_viridis_c() +\n  labs(color = \"Accuracy\")\n\n\n\n\n\nSe observa que los mejores hiperparámetros para los algoritmos entrenados con y sin imputación, discrepan considerablemente. Aunque en este caso realicé la evaluación del desempeño de los modelos basado en la métrica Accuracy, es posible utilizar cualquier otra para problemas de clasificación."
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#mejores-hiperparámetros",
    "href": "posts/XGBoost_R/XGBoost_R.html#mejores-hiperparámetros",
    "title": "XGBoost con R",
    "section": "Mejores hiperparámetros",
    "text": "Mejores hiperparámetros\n\nMejores hiperparámetros en modelos sin imputación:\n\n\nCódigomejor_no_impute <- tuned_no_impute %>% \n  select_best(metric = \"accuracy\")\n\nmejor_no_impute\n\n\n\n  \n\n\n\n\nMejores hiperparámetros en modelos con imputación:\n\n\nCódigomejor_si_impute <- tuned_si_impute %>% \n  select_best(metric = \"accuracy\")\n\nmejor_si_impute"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#ajuste-final",
    "href": "posts/XGBoost_R/XGBoost_R.html#ajuste-final",
    "title": "XGBoost con R",
    "section": "Ajuste final",
    "text": "Ajuste final\n\nModelo sin imputación:\n\n\nCódigofinal_no_impute <- finalize_workflow(\n  x = wf_no_impute,\n  parameters = mejor_no_impute\n) %>% \n  fit(data = train)\n\n\n\nModelo con imputación:\n\n\nCódigofinal_si_impute <- finalize_workflow(\n  x = wf_si_impute,\n  parameters = mejor_si_impute\n) %>% \n  fit(data = train)"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#predicciones-train",
    "href": "posts/XGBoost_R/XGBoost_R.html#predicciones-train",
    "title": "XGBoost con R",
    "section": "Predicciones Train",
    "text": "Predicciones Train\n\nModelo sin imputación:\n\n\nCódigopred_no_impute_train <- final_no_impute %>% \n  predict(new_data = train, type = \"class\")\n\n\n\nModelo con imputación:\n\n\nCódigopred_si_impute_train <- final_si_impute %>% \n  predict(new_data = train, type = \"class\")"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#predicciones-test",
    "href": "posts/XGBoost_R/XGBoost_R.html#predicciones-test",
    "title": "XGBoost con R",
    "section": "Predicciones Test",
    "text": "Predicciones Test\n\nModelo sin imputación:\n\n\nCódigopred_no_impute_test <- final_no_impute %>% \n  predict(new_data = test, type = \"class\")\n\n\n\nModelo con imputación:\n\n\nCódigopred_si_impute_test <- final_si_impute %>% \n  predict(new_data = test, type = \"class\")"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#matriz-de-confusión-train",
    "href": "posts/XGBoost_R/XGBoost_R.html#matriz-de-confusión-train",
    "title": "XGBoost con R",
    "section": "Matriz de confusión Train",
    "text": "Matriz de confusión Train\n\nMatriz de confusión modelo sin imputación:\n\n\nCódigodata.frame(\n  predicho = as.factor(pred_no_impute_train$.pred_class),\n  real = as.factor(train$diagnosis)\n) %>% \n  conf_mat(truth = real, estimate = predicho) %>% \n  pluck(1) %>% \n  as_tibble()  %>% \n  ggplot(aes(x = Prediction, y = Truth, alpha = n)) +\n  geom_tile(show.legend = FALSE) +\n  geom_text(aes(label = n), colour = \"white\", alpha = 1, size = 8)\n\n\n\nMatriz de confusión en train - modelo sin imputación\n\n\n\n\n\nMatriz de confusión modelo con imputación:\n\n\nCódigodata.frame(\n  predicho = as.factor(pred_si_impute_train$.pred_class),\n  real = as.factor(train$diagnosis)\n) %>% \n  conf_mat(truth = real, estimate = predicho) %>% \n  pluck(1) %>% \n  as_tibble()  %>% \n  ggplot(aes(x = Prediction, y = Truth, alpha = n)) +\n  geom_tile(show.legend = FALSE) +\n  geom_text(aes(label = n), colour = \"white\", alpha = 1, size = 8)\n\n\n\nMatriz de confusión en train - modelo con imputación"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#matriz-de-confusión-test",
    "href": "posts/XGBoost_R/XGBoost_R.html#matriz-de-confusión-test",
    "title": "XGBoost con R",
    "section": "Matriz de confusión Test",
    "text": "Matriz de confusión Test\n\nMatriz de confusión modelo sin imputación:\n\n\nCódigodata.frame(\n  predicho = as.factor(pred_no_impute_test$.pred_class),\n  real = as.factor(test$diagnosis)\n) %>% \n  conf_mat(truth = real, estimate = predicho) %>% \n  pluck(1) %>% \n  as_tibble()  %>% \n  ggplot(aes(x = Prediction, y = Truth, alpha = n)) +\n  geom_tile(show.legend = FALSE) +\n  geom_text(aes(label = n), colour = \"white\", alpha = 1, size = 8)\n\n\n\nMatriz de confusión en test - modelo sin imputación\n\n\n\n\n\nMatriz de confusión modelo con imputación:\n\n\nCódigodata.frame(\n  predicho = as.factor(pred_si_impute_test$.pred_class),\n  real = as.factor(test$diagnosis)\n) %>% \n  conf_mat(truth = real, estimate = predicho) %>% \n  pluck(1) %>% \n  as_tibble()  %>% \n  ggplot(aes(x = Prediction, y = Truth, alpha = n)) +\n  geom_tile(show.legend = FALSE) +\n  geom_text(aes(label = n), colour = \"white\", alpha = 1, size = 8)\n\n\n\nMatriz de confusión en test - modelo con imputación"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#desempeño-de-modelos",
    "href": "posts/XGBoost_R/XGBoost_R.html#desempeño-de-modelos",
    "title": "XGBoost con R",
    "section": "Desempeño de modelos",
    "text": "Desempeño de modelos\n\nGenero una base de datos con los resultados de las clases predichas en cada tipo de modelo (con y sin imputación) para los conjuntos de entrenamiento y prueba.\n\n\nCódigotabla_accuracy <- data.frame(\n  predicho = pred_no_impute_train$.pred_class,\n  real = train$diagnosis,\n  datos = \"Train\",\n  tipo = \"Sin imputación\"\"\n) %>%\n  bind_rows(\n    data.frame(\n      predicho = pred_si_impute_train$.pred_class,\n      real = train$diagnosis,\n      datos = \"Train\",\n      tipo = \"Con imputación\"\"\n    )\n  ) %>%\n  bind_rows(\n    data.frame(\n      predicho = pred_no_impute_test$.pred_class,\n      real = test$diagnosis,\n      datos = \"Test\",\n      tipo = \"Sin imputación\"\"\n    )\n  ) %>% \n  bind_rows(\n    data.frame(\n      predicho = pred_si_impute_test$.pred_class,\n      real = test$diagnosis,\n      datos = \"Test\",\n      tipo = \"Con imputación\"\"\n    )\n  ) %>% \n  mutate(across(where(is.character), as.factor))\n\ntabla_accuracy %>%\n  group_by(datos, tipo) %>% \n  summarise(accuracy = accuracy_vec(truth = real, estimate = predicho)) %>% \n  kable(caption = \"Accuracy en train y test para dos modelos XGBoost\")\n\n\nAccuracy en train y test para dos modelos XGBoost\n\ndatos\ntipo\naccuracy\n\n\n\nTest\nCon imputación\n0.7540984\n\n\nTest\nSin imputación\n0.7814208\n\n\nTrain\nCon imputación\n0.8481532\n\n\nTrain\nSin imputación\n0.9972640\n\n\n\n\n\n\nGráfico Accuracy: la capacidad predictiva es superior en el modelo que fue entrenado sin acudir a la imputación de datos.\n\n\nCódigotabla_accuracy %>%\n  group_by(datos, tipo) %>% \n  summarise(accuracy = accuracy_vec(truth = real, estimate = predicho)) %>% \n  ggplot(aes(x = tipo, y = accuracy, color = datos, fill = datos)) +\n  geom_col(position = \"dodge\", alpha = 0.8) +\n  scale_color_jama() +\n  scale_fill_jama() +\n  labs(x = \"Preprocesamiento\", y = \"Accuracy\",\n       color = \"\", fill = \"\")\n\n\n\nAccuracy en train y test para dos modelos XGBoost"
  },
  {
    "objectID": "posts/XGBoost_R/XGBoost_R.html#importancia-de-variables",
    "href": "posts/XGBoost_R/XGBoost_R.html#importancia-de-variables",
    "title": "XGBoost con R",
    "section": "Importancia de variables",
    "text": "Importancia de variables\n\n10 variables de mayor importancia en modelo sin imputación:\n\n\nCódigofinal_no_impute %>% \n  pull_workflow_fit() %>%\n  vip(geom = \"point\", n = 10)\n\n\n\nImportancia de variables - modelo sin imputación\n\n\n\n\n\n10 variables de mayor importancia en modelo sin imputación:\n\n\nCódigofinal_si_impute %>% \n  pull_workflow_fit() %>%\n  vip(geom = \"point\", n = 10)\n\n\n\nImportancia de variables - modelo con imputación"
  }
]